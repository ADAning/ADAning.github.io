<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="Introduction: Graph Neural Network, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>Introduction: Graph Neural Network | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/17.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Introduction: Graph Neural Network</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/GNN/"><span class="chip bg-color">GNN</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2021-03-04</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-04-03</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 5.2k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 20 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li>图结构基础知识(数据结构相关内容, 自行查阅).</li></ul><p><strong>2021.04.06</strong>: 更新GraphSAGE的理解.</p></blockquote><h1 id="Introduction-Graph-Neural-Network"><a href="#Introduction-Graph-Neural-Network" class="headerlink" title="Introduction: Graph Neural Network"></a>Introduction: Graph Neural Network</h1><p>本文介绍的是GNN方面入门级别的知识, 其实这坑早就挖下了, 但是一直都没有机会补. 部分内容出自<a href="https://aistudio.baidu.com/aistudio/course/introduce/1956" target="_blank" rel="noopener">飞桨图神经网络7日打卡营</a>, 训练营的切入的角度避开了复杂的数学推导, 方便GNN入门.</p><blockquote><p>关于实现, 现在还没有统一的比较成熟的图学习框架, 无论是PyTorch还是TF, 都需要自己手动实现.</p><p>有两个图学习框架<a href="https://github.com/rusty1s/pytorch_geometric" target="_blank" rel="noopener">PyG</a> 和<a href="https://github.com/dmlc/dgl" target="_blank" rel="noopener">DGL</a>是大家用的比较多的, 但是都有一些问题, 目前来看PyG的人气比DGL要高得多. 还有百度飞桨的框架PGL, 感谢飞桨PGL在图学习开源上做出的贡献.</p></blockquote><p>文中所涉及的所有论文和图片出处在结尾都会提供.</p><h2 id="Graph-and-Graph-Learning"><a href="#Graph-and-Graph-Learning" class="headerlink" title="Graph and Graph Learning"></a>Graph and Graph Learning</h2><p>诸如图的有向, 无向, 邻接矩阵, 矩阵的度之类的<strong>基本概念</strong>就不再赘述, 如果你对图结构本身还不太熟悉的话, 去重温一下<strong>数据结构</strong>就好.</p><p>在现实生活中, 图结构有多种很相关的实例. 例如分子结构, 交通流量, 社交网络, <strong>知识图谱</strong>等… 非常多的复杂问题都能够被图所表示, 因为<strong>图本来就是一种表示能力极强的结构</strong>, 这使得许多利用简单结构不能被表示的问题得以表示. 也正是因为<strong>欧式数据</strong>和<strong>非欧数据</strong>在处理问题上的差异, 导致我们需要探索一种在非欧数据问题上生效的方法.</p><p>如果从图本身的角度来看, 单张图本身可以看做是茫茫众多图中的一个, 如果完成任务需要依赖于不同的图, 可以被称为是<strong>图级别任务</strong>,</p><p>如果从图结构的角度来看, 每张图中的<strong>节点</strong>和<strong>边</strong>都能够用作在不同的任务中. 节点或许可以代表问题中的某个<strong>实物</strong>, 边可以表示不同节点(实物)和节点之间的<strong>联系</strong>. 使用它们两个也就照应着<strong>节点级任务</strong>和<strong>边级别任务</strong>.</p><p>按照飞桨训练营中对图学习的划分, 图学习算法可以分为三大类:</p><ol><li><strong>图游走类算法</strong>(图嵌入算法): DeepWalk, Node2Vec等.</li><li><strong>图神经网络算法</strong>: GCN, GAT, GraphLSTM等.</li><li><strong>知识图谱嵌入算法</strong>: TransE, TransR, RotatE等.</li></ol><p>现在主流的知识图谱嵌入和图嵌入有一些区别, 所以单独列了一类. 因为现在的Knowledge Embedding方法大多采用<strong>三元组</strong>的形式来获取嵌入表示. 当然也有结合图的算法, 例如R - GCN等.</p><p>图嵌入和图神经网络互有交集, 但图嵌入更侧重于只得到节点的<strong>低维表示</strong>, 而图神经网络侧重于将任务<strong>端到端</strong>的解决:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial1.jpg" style="zoom:50%"><blockquote><p>关于GNN发展过程中在<strong>频域</strong>, <strong>空域</strong>上的一些内容在入门阶段很晦涩, 涉及到相当多的<strong>数学推导</strong>, 由于个人的基础不扎实在这里就不做误导了. 如果只是使用它, 不推荐关心这部分内容.</p><p>但如果是专门做GNN的研究, 这方面知识是非常有必要的. 并且需要掌握所涉及的推导过程.</p><p>给几个关于这方面的补充资料吧:</p><ul><li><a href="https://blog.csdn.net/yyl424525/article/details/100058264" target="_blank" rel="noopener">图卷积网络 GCN Graph Convolutional Network（谱域GCN）的理解和详细推导</a></li><li><a href="https://blog.csdn.net/qq_44015059/article/details/105341555" target="_blank" rel="noopener">基于频域GCN理论基础(拉普拉斯矩阵与傅里叶变换)</a></li></ul></blockquote><h2 id="Graph-Walking"><a href="#Graph-Walking" class="headerlink" title="Graph Walking"></a>Graph Walking</h2><p>图游走算法可以说是为<strong>图嵌入</strong>所服务的, 就好像Word Embedding对于NLP的地位一样, 为下游任务服务. 图嵌入可以得到一个节点在图中的表示(向量). 图游走就是通过某种游走算法将图转化为<strong>序列</strong>, 再使用类似NLP获取词嵌入的方式得到节点表示的方法.</p><h3 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h3><p>最早的游走思路是借鉴了NLP在处理词嵌入时所采用的<strong>Word2Vec</strong>, 在Word2Vec中, <strong>中心词语义可以由周围邻近的词语</strong>义来”决定”, Skip - Gram便是一种根据中心词预测上下文来获取中心词嵌入表示的方法:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/skipgram.png" style="zoom:50%"><p>人们观察到, 社交网络中的用户行为经常会受到邻近用户的行为影响. 在图结构中, 只需要将中心思想变为<strong>中心节点含义由周围的节点决定</strong>, 本质上还是不变的. 所以就有可能将Word2Vec迁移到图领域用于获取节点嵌入表示.</p><h3 id="DeepWalk"><a href="#DeepWalk" class="headerlink" title="DeepWalk"></a>DeepWalk</h3><p>DeepWalk非常简单的在图中做<strong>随机游走</strong>, 即在当前节点的邻近节点(包括<strong>自身</strong>)随机游走, 当游走到<strong>最大长度</strong>时停止. 所以它是一个<strong>可以重复遍历的DFS</strong>.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial2.jpg" style="zoom:67%"><p>在这里定义一般的随机游走公式, 在节点$v$ 处游走到下一个节点$x$ 的概率为:<br>$$<br>{P}\left(c_{i}=x \mid c_{i-1}=v\right)=\left\{\begin{array}{cc}<br>\frac{\pi_{vx}}{Z}, &amp; \text { if }(v, x) \in E \\<br>0, &amp; \text { otherwise }<br>\end{array}\right.<br>$$<br>其中$Z$ 为归一化因子, $\pi_{vx}$ 是在被归一化之前算法得出的关于$v$ 游走到$x$ 的某个依据值.</p><p>对于DeepWalk来说, 只要与节点$v$ 相邻的节点概率是相等的, 所以有:</p><p>$$<br>P\left(c_{i}=x \mid c_{i-1}=v\right)=\left\{\begin{array}{cc}<br>\frac{1}{|N(v)|}, &amp; \text { if }(v, x) \in E \\<br>0, &amp; \text { otherwise }<br>\end{array}\right.<br>$$</p><p>拿到了这个图的遍历序列, 就能将它作为一个序列输入到Word2Vec中, 就得到了节点的表示.</p><h3 id="Node2Vec"><a href="#Node2Vec" class="headerlink" title="Node2Vec"></a>Node2Vec</h3><p>对于DeepWalk来说, 随机游走显得有些过于漫无目的, 没有偏好. 而且在DeepWalk中, 只考虑了使用DFS游走的方式. 而在数据结构中可知, 图的游走方式是有<strong>DFS</strong>和<strong>BFS</strong>两种的:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial3.jpg" style="zoom:67%"><p>在Node2Vec中, 考虑了上述问题, 希望能够让游走的方式更加丰富一点. 只需要将图游走的一般公式做如下替换:<br>$$<br>\pi_{vx} =\alpha_{pq}(t, x) \cdot w_{vx}<br>$$<br>$v$为当前节点, $t$ 为上一个节点, $w_{vx}$为$v$ 和$x$ 之间的权值, 其中$\alpha_{pq}(t, x)$ 为:<br>$$<br>\alpha_{p q}(t, x)=\left\{\begin{array}{ll}<br>\frac{1}{p}, &amp; \text { if } d_{t x}=0 \\<br>1, &amp; \text { if } d_{t x}=1 \\<br>\frac{1}{q}, &amp; \text { if } d_{t x}=2<br>\end{array}\right.<br>$$<br>$d_{tx}$ 代表节点$t$ 到$x$ 的距离, 即当前节点$v$ 的一阶邻居. 而$p, q$ 则是两个参数, 它们能控制如何游走:</p><ul><li>$p$ 能控制有多大的概率”回头”, 即从当前节点$v$ 重新回到前一节点$t$, 如下图$v\rightarrow t$).</li><li>$q$ 控制游走策略倾向于DFS或是BFS:<ul><li>$q&gt;1$ 时倾向于BFS, 如下图$v\rightarrow x_1$.</li><li>$q&lt;1$ 时倾向于DFS, 如下图$v\rightarrow x_2$.</li></ul></li><li>$p=q=1$ 时, $\pi_{vx}=w_{vx}$.</li></ul><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial4.jpg" style="zoom:67%"><p>这样游走有如下好处:</p><ol><li>结合了图的<strong>权重</strong>对游走的影响.</li><li>能够让模型<strong>自己学习</strong>如何游走合适(不是仅仅执行DFS, 也在某些时候BFS).</li></ol><h2 id="Graph-Neural-Network"><a href="#Graph-Neural-Network" class="headerlink" title="Graph Neural Network"></a>Graph Neural Network</h2><h3 id="Graph-Convolutional-Network"><a href="#Graph-Convolutional-Network" class="headerlink" title="Graph Convolutional Network"></a><strong>G</strong>raph <strong>C</strong>onvolutional <strong>N</strong>etwork</h3><p><strong>图卷积网络</strong>(<strong>G</strong>raph <strong>C</strong>onvolutional <strong>N</strong>etwork, <strong>GCN</strong>)才彻彻底底的将卷积的概念从谱域扩展到了空域上. GCN将欧式结构上的卷积扩展到非欧结构上的卷积.</p><p>在CV中的卷积被定义为: <strong>将某个像素点周围的像素以不同权重叠加起来</strong>. 那么扩展到图结构中这种非欧结构中, 对应的像素应该变为<strong>节点</strong>, <strong>即将某个节点周围的邻居以不同权重叠加起来</strong>, 如下所示:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial5.jpg" style="zoom:33%"><p>就像普通的CNN一样, GCN也是以若干层堆叠提取特征的方式发挥作用:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial6.jpg" style="zoom:33%"><p>或是加上图池化与读出层做分类任务:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial7.jpg" style="zoom:33%"><p>其中, 每一层GCN所对应节点隐态的更新方式为:<br>$$<br>H^{(l+1)}=\sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})<br>$$<br>其中$\hat{A}$ 为图的自邻接矩阵(有节点自身的闭环, 即$\tilde{A} = A + I$), $D$ 为度矩阵, $H^{(l)}$ 为第$l$ 层GCN的节点表示. $W^{(l)}$ 很好理解, 第$l$ 层的线性变换矩阵, 也就是”神经网络”(DNN).</p><p>以下图为例(图中有节点到自身的<strong>闭环</strong>):</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial8.jpg" style="zoom:67%"><p>它所对应的邻接矩阵$A$, 度矩阵$D$ 分别为:<br>$$<br>\tilde{A}=\begin{bmatrix}\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}&amp;0&amp;0&amp;0&amp;0\\\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}&amp;0&amp;0&amp;0&amp;0\\\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}&amp;0&amp;0&amp;0\\0&amp;0&amp;\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}\\0&amp;0&amp;0&amp;\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}\\0&amp;0&amp;0&amp;\color{red}{1}&amp;\color{red}{1}&amp;\color{red}{1}&amp;0\\0&amp;0&amp;0&amp;\color{red}{1}&amp;\color{red}{1}&amp;0&amp;\color{red}{1}\end{bmatrix}<br>\tilde{D}=\begin{bmatrix}\color{red}{3}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\0&amp;\color{red}{3}&amp;0&amp;0&amp;0&amp;0&amp;0\\0&amp;0&amp;\color{red}{4}&amp;0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;\color{red}{5}&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;\color{red}{4}&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;\color{red}{3}&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;\color{red}{3}\end{bmatrix}\<br>$$</p><p>其中所需要用到的$\tilde{D}^{-\frac{1}{2}}$ 为下矩阵:</p><p>$$<br>\tilde{D}^{-\frac{1}{2}}=\begin{bmatrix}\color{red}{\frac{1}{\sqrt{3}}}&amp;0&amp;0&amp;0&amp;0&amp;0&amp;0\\0&amp;\color{red}{\frac{1}{\sqrt{3}}}&amp;0&amp;0&amp;0&amp;0&amp;0\\0&amp;0&amp;\color{red}{\frac{1}{\sqrt{4}}}&amp;0&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;\color{red}{\frac{1}{\sqrt{5}}}&amp;0&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;\color{red}{\frac{1}{\sqrt{4}}}&amp;0&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;\color{red}{\frac{1}{\sqrt{3}}}&amp;0\\0&amp;0&amp;0&amp;0&amp;0&amp;0&amp;\color{red}{\frac{1}{\sqrt{3}}}\end{bmatrix}<br>$$<br>为了方便理解更新方式, 我们先做如下方式的<strong>简化</strong>:<br>$$<br>\begin{aligned}<br>H^{(l+1)}&amp;=\sigma(\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}H^{(l)}W^{(l)})\\\ &amp;\Downarrow \\\ H^{(l+1)}&amp;=\sigma(\tilde{A}H^{(l)}W^{(l)})<br>\end{aligned}<br>$$<br>即<strong>先不考虑度对更新的影响</strong>. $\tilde{A}H^{(l)}$ 的含义是:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial9.jpg" style="zoom:67%"><p>$l+1$ 层的第0节点表示是$l$ 层第0, 1, 2 节点表示的和. 这和CNN非常相似, 能根据邻接矩阵来判断邻居, 然后将邻居信息求和. 在计算下一层节点表示的过程中, 隐含着一种机制(或是框架), <strong>消息传递</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial10.jpg" style="zoom:67%"><p>0号节点<strong>接收</strong>了来自0, 1, 2号节点的信息, 并<strong>更新</strong>了自己的信息. 消息传递的过程也就是这两步:</p><ol><li>边上的源节点向目标节点<strong>发送</strong>信息.</li><li>目标节点对接收到的特征进行<strong>聚合</strong>.</li></ol><p>既然已经能够完成特征更新的整个流程, 为什么要引入$\tilde{D}^{-\frac{1}{2}}$ 呢? 如果只使用邻接矩阵做加权, 周围人对你的评价可能并不是真实的:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial11.jpg" style="zoom:50%"><p>例如新垣结衣的周围的人非常多(<strong>度非常大</strong>), 她的特征可能会因为多人的评价而变得非常大, 从而对你的评价可能就不那么准确, 在训练时也容易导致梯度消失或梯度爆炸. 相反, 可能你的好友更加的了解你(<strong>度比较小</strong>), 对你的评价也更准确. 对所有节点一视同仁会导致度大的节点特征越来越大, 度小的节点越来越小.</p><p>因此, 我们可以使用<strong>度</strong>来衡量邻居信息的<strong>重要性</strong>, 这里的$\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$ 在做的事情实际上是用度矩阵对$A$ 做了<strong>Renormalization</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial12.jpg" style="zoom:50%"><p>度$d$ 越大, 信息就越少, $\frac{1}{\sqrt{d}}$ 就越小.</p><blockquote><p>这里采用<strong>Renormalization</strong>是有说法的, 想深入了解可以看<a href="https://www.zhihu.com/question/426784258/answer/1536731121" target="_blank" rel="noopener">GCN中的拉普拉斯矩阵如何归一化？</a>.</p><p>之所以没有采用”对称归一化”这个说法, 是因为矩阵并没有真正的得到归一化, 原论文中的表述也是”Renormalization”.</p></blockquote><p>下面来总结一下GCN的流程:</p><ol><li><p>使用$\tilde{D}^{-\frac{1}{2}}\tilde{A}\tilde{D}^{-\frac{1}{2}}$ 进行节点之间的<strong>特征传递</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial13.jpg" style="zoom:25%"></li><li><p>对每一个节点过一层<strong>DNN</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial14.jpg" style="zoom:25%"></li><li><p><strong>重复</strong>上面两步多次, 实现多层GCN, 并能获得每个节点的表示:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial15.jpg" style="zoom:25%"></li><li><p>根据取得的节点表示$H^{(l)}$将其用于<strong>下游任务</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial16.jpg" style="zoom:50%"></li></ol><h3 id="Graph-Attention-Network"><a href="#Graph-Attention-Network" class="headerlink" title="Graph Attention Network"></a>Graph Attention Network</h3><p>在GCN中的边权重是通过<strong>度</strong>来控制的, 这种度量仅与度有关, 而且不可学习权重的分配方式.</p><p>在深度学习背景下, 我们更希望能够模型能够<strong>自己学习</strong>如何分配权重. 在深度学习中, 关于学习权重分配的分配方式, 人们很自然而然的就想到了<strong>Attention</strong>, 它也确实非常适合去做这件事情. <strong>图注意力网络</strong>(<strong>G</strong>raph <strong>At</strong>tention Network, <strong>GAT</strong>)应运而生.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial17.jpg" style="zoom:50%"><p>GAT通过对调整当前节点$i$ 对其他节点$j$ 的权重来调整, 在这里只考虑节点$i$ 的<strong>一阶邻居</strong> $j \in \mathcal{N}_{i}$.<br>$$<br>e_{i j}=a\left(\mathbf{W} \vec{h}_{i}, \mathbf{W} \vec{h}_{j}\right)<br>$$<br>GAT中的Attention计算方式如下:<br>$$<br>\displaylines{<br>\alpha_{i j}=\operatorname{softmax}_{j}\left(e_{i j}\right)=\frac{\exp \left(e_{i j}\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(e_{i k}\right)}<br>\\\ \Downarrow \\<br>\alpha_{i j}=\frac{\exp \left(\operatorname{LeakyReLU}\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} | \mathbf{W} \vec{h}_{j}\right]\right)\right)}{\sum_{k \in \mathcal{N}_{i}} \exp \left(\text { LeakyReLU }\left(\overrightarrow{\mathbf{a}}^{T}\left[\mathbf{W} \vec{h}_{i} | \mathbf{W} \vec{h}_{k}\right]\right)\right)}<br>}<br>$$<br>其中$\overrightarrow{\mathbf{a}}$ 是一个权重向量, 也可以被视作是一个<strong>单层神经网络</strong>, $\mathbf{W}$ 为权重矩阵, 能够学习到输入特征$\overrightarrow{h}$ 中更高级的特征. GAT计算各节点的高阶特征, 后计算各节点对当前节点的重要程度, 并经过LeakyReLU激活, 最后用Softmax做归一化, 求得Attention权重:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial19.jpg" style="zoom:33%"><p>对特征的聚合方式如下:<br>$$<br>\vec{h}_{i}^{\prime}=\sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j} \mathbf{W} \vec{h}_{j}\right)<br>$$<br>$\sigma$ 是非线性的激活函数.</p><p>与Transformer一样, GAT也支持<strong>多头特征聚合</strong>:<br>$$<br>\vec{h}_{i}^{\prime}=\operatorname{\lVert}\limits_{k=1}^{K} \sigma\left(\sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)<br>$$<br>其中$||$ 代表Concatenation. 即将多个头的特征Concat起来. 当然也可以采用求平均的方式来适应不同的场景:<br>$$<br>\vec{h}_{i}^{\prime}=\sigma\left(\frac{1}{K} \sum_{k=1}^{K} \sum_{j \in \mathcal{N}_{i}} \alpha_{i j}^{k} \mathbf{W}^{k} \vec{h}_{j}\right)<br>$$<br>GAT总体来说如下所示:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial18.jpg" style="zoom:40%"><p>图中三种颜色的线代表有三个头, 学习到了不同的权重分配方式, 最后再通过某种聚合方式聚合获得$\overrightarrow{h_1^\prime}$.</p><p>因此, GAT不但将权重调整为与两个节点都相关的函数, 而且还是可学习的, 它同样遵守消息传递框架.</p><h3 id="Message-Passing-Neural-Network"><a href="#Message-Passing-Neural-Network" class="headerlink" title="Message Passing Neural Network"></a>Message Passing Neural Network</h3><p><strong>消息传递网络</strong>(<strong>M</strong>essage <strong>P</strong>assing <strong>N</strong>eural <strong>N</strong>etwork, <strong>MPNN</strong>)并非是某种具体的图神经网络, 而是对图神经网络更新权重方式的一种<strong>范式</strong>或是一种<strong>框架</strong>. 我在前面介绍GCN, GAT时曾多次提到这个词, 因为它们都是<strong>基于邻居聚合</strong>的模型, 都属于Spatial GNN, 大多数的空域GNN都是可以被消息传递网络实现的.</p><p>基于消息传递的 Graph Neural Network的通用公式如下:</p><p>$$<br>h_{l}^{(t)}(v)=\color{green}{f}\left(h_{l}^{(t-1)}, \color{red}{\mathcal{F}}\left\{\color{blue}{h_{l}^{(t-1)}(u) \mid u \in N(v)}\right\}\right)<br>$$</p><p>其中$h_{l}^{(t-1)}(u)$ 代表邻居的消息发送, $\mathcal{F}$ 代表聚合函数, 可以是<strong>Max</strong>, <strong>Mean</strong>, <strong>Sum</strong>等, $f$ 对应神经网络, 可以是MLP或者其他结构. 在GCN中, $\mathcal{F}$ 是基于度的加权求和, GAT中是基于Attention的加权求和.</p><h2 id="Graph-Sampling"><a href="#Graph-Sampling" class="headerlink" title="Graph Sampling"></a>Graph Sampling</h2><p>因为节点和节点间存在<strong>依存关系</strong>, 并不像欧式数据那样可以采用MiniBatch的方法训练, 所以在大规模图中, 一般没有办法将算法直接应用于整张图, 例如GCN, 每次更新需要对所有节点依次聚合更新. 故需要一种能够从图中采样, 获取有效<strong>子图</strong>的方法, 在子图上应用我们前面说过的算法, 这种方法就是<strong>图采样</strong>.</p><p>但子图采样并不是随机采样, 我们最起码要保证采样完后的图是<strong>连通</strong>的:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial20.jpg" style="zoom:33%"><h3 id="GraphSAGE"><a href="#GraphSAGE" class="headerlink" title="GraphSAGE"></a>GraphSAGE</h3><p><strong>Graph</strong> <strong>SA</strong>mple &amp; aggre<strong>G</strong>at<strong>E</strong>, <strong>GraphSAGE</strong> 是最简单的图采样算法. 它与GCN其实差别不大. 它分为邻居采样, 邻居聚合, 节点预测三个步骤.</p><p>假设有下面这么一张图, 我们需要求出0号节点的表示, 所以需要从0号节点开始采样:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial21.jpg" style="zoom:35%"><p>我们<strong>从内至外</strong>地<strong>采样</strong>0号节点的第N阶邻居, 假设一阶邻居随机采样到了2, 4, 5号节点, 然后采样二阶邻居8, 9, 11, 12, 13, 15:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial22.jpg" style="zoom:40%"><p>这样就抽出了一张子图, 然后可以<strong>由外至内</strong>地<strong>邻居聚合</strong>更新0号节点的表示:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial23.jpg" style="zoom:40%"><p>最后就可以通过采样获得的子图来做节点预测了.</p><p>邻居采样有两个优点:</p><ol><li>极大减少了训练计算量.</li><li>在<strong>推断</strong>时允许新的节点的加入, 增强了<strong>泛化</strong>能力.</li></ol><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial24.jpg" style="zoom:50%"><p>因为做了邻居采样, 所以更新未知节点的表示时<strong>不需要使用整张图的节点信息</strong>, 而是只使用由新加入节点后采样的子图节点信息, 所以说允许泛化到新的节点, 也就是所谓的Inductive能力.</p><blockquote><p>关于GraphSAGE在<strong>Inductive</strong>上的能力讨论可以看<a href="https://www.zhihu.com/question/409415383/answer/1361596817" target="_blank" rel="noopener">这里</a>, 我个人是比较赞同答主的说法. 算法能否Inductive和Transductive仅取决于节点输入是否是One Hot, 以及在更新节点表示时是否只依赖于局部子图.</p></blockquote><h3 id="PinSAGE"><a href="#PinSAGE" class="headerlink" title="PinSAGE"></a>PinSAGE</h3><p>仍然是之前的那副图, 我们希望能够更新0号节点的表示. PinSAGE通过<strong>多次随机游走</strong>, 按照路径中节点出现的<strong>频率</strong>, 将这些节点作为邻居. 假设PinSAGE已经做出了四次随机游走:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial25.jpg" style="zoom:40%"><p>根据四次游走中节点出现的频率排序, 5, 10, 11这三个节点频率较高, 让它们作为0号节点的虚拟邻居:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial26.jpg" style="zoom:33%"><p>所以说, PinSAGE所采样得到的子图不一定选取了真实的邻居节点, 这样做使得节点能够快速的获取到<strong>高阶邻居</strong>的信息, 有点类似于ResNet中的<strong>Residual Connection</strong>的作用, 避免了聚合过程中由于距离过远而损失信息的缺点.</p><h2 id="Neighborhood-Aggregation"><a href="#Neighborhood-Aggregation" class="headerlink" title="Neighborhood Aggregation"></a>Neighborhood Aggregation</h2><p>邻居聚合是在图采样之后做的操作, 不同的聚合方式可以达到不同效果. 经典的聚合函数有:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial27.jpg" style="zoom:40%"><p>评估聚合表达能力的指标是<strong>单射</strong>, 单射能保证对聚合以后的结果<strong>可区分</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial28.jpg" style="zoom:40%"><p>对于不同的子图, SUM也保留了单射能力:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial29.jpg" style="zoom:40%"><p>因此, 就有基于单射的GIN(<strong>G</strong>raph <strong>I</strong>somorphism <strong>N</strong>et)模型:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial30.jpg" style="zoom:40%"><p>它的聚合方式就是具有单射能力的<strong>SUM</strong>, 但是为了区分中心节点与邻居, 特意加上了$\mathcal{E}$ :</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gnntutorial31.jpg" style="zoom:40%"><p>当然, GCN, GAT这类的聚合函数都是相较于经典聚合函数更为复杂的.</p><h2 id="Recommended"><a href="#Recommended" class="headerlink" title="Recommended"></a>Recommended</h2><p>涉及到的原论文和图片出处:</p><ul><li>DeepWalk: <a href="https://dl.acm.org/doi/abs/10.1145/2623330.2623732" target="_blank" rel="noopener">DeepWalk: online learning of social representations</a></li><li>Node2Vec: <a href="https://dl.acm.org/doi/abs/10.1145/2939672.2939754" target="_blank" rel="noopener">node2vec: Scalable Feature Learning for Networks</a></li><li>GCN: <a href="https://arxiv.org/abs/1609.02907" target="_blank" rel="noopener">Semi-Supervised Classification with Graph Convolutional Networks</a></li><li>GAT: <a href="https://arxiv.org/abs/1710.10903" target="_blank" rel="noopener">Graph Attention Networks</a></li><li>MPNN: <a href="https://arxiv.org/abs/1704.01212" target="_blank" rel="noopener">Neural Message Passing for Quantum Chemistry</a></li><li>GraphSAGE: <a href="https://arxiv.org/abs/1706.02216" target="_blank" rel="noopener">Inductive Representation Learning on Large Graphs</a></li><li>PinSAGE: <a href="https://dl.acm.org/doi/abs/10.1145/3219819.3219890" target="_blank" rel="noopener">Graph Convolutional Neural Networks for Web-Scale Recommender Systems</a></li><li>GIN: <a href="https://arxiv.org/abs/1810.00826" target="_blank" rel="noopener">HOW POWERFUL ARE GRAPH NEURAL NETWORKS?</a></li><li>综述类论文: <a href="https://arxiv.org/abs/1901.00596" target="_blank" rel="noopener">A Comprehensive Survey on Graph Neural Networks</a></li></ul><p>除去文中提到的资料, 其他涉及到的参考资料:</p><ul><li><a href="https://wmathor.com/index.php/archives/1531/" target="_blank" rel="noopener">GNN详解</a>, <a href="https://wmathor.com/index.php/archives/1532/" target="_blank" rel="noopener">GCN详解</a>, <a href="https://wmathor.com/index.php/archives/1533/" target="_blank" rel="noopener">GraphSAGE &amp; PinSAGE详解</a></li><li><a href="http://web.stanford.edu/class/cs224w/" target="_blank" rel="noopener">CS224W: Machine Learning with Graphs</a></li><li><a href="https://www.bilibili.com/video/BV1G54y1971S" target="_blank" rel="noopener">台大李宏毅助教讲解GNN图神经网络</a></li><li><a href="https://aistudio.baidu.com/aistudio/education/group/info/1956" target="_blank" rel="noopener">图神经网络7日打卡营</a></li><li><a href="https://www.bilibili.com/video/BV19U4y1s7cv" target="_blank" rel="noopener">深入浅出GCN、GAT、GraphSage，MPNN等图神经网络模型【贪心学院】</a></li><li><a href="https://zhuanlan.zhihu.com/p/76001080" target="_blank" rel="noopener">GNN综述——从入门到入门</a></li><li><a href="https://blog.csdn.net/weixin_45901519/article/details/106492963" target="_blank" rel="noopener">图卷积神经网络笔记——第三章：空域图卷积介绍（1）</a></li><li><a href="https://wangsp.blog.csdn.net/article/details/100709692" target="_blank" rel="noopener">GCN—图卷积神经网络理解</a></li></ul><p>PyTorch代码:</p><ul><li>GCN: <a href="https://github.com/tkipf/pygcn" target="_blank" rel="noopener">Graph Convolutional Networks in PyTorch</a></li><li>GAT: <a href="https://github.com/Diego999/pyGAT" target="_blank" rel="noopener">Pytorch Graph Attention Network</a></li><li>GraphSage: <a href="https://github.com/twjiang/graphSAGE-pytorch" target="_blank" rel="noopener">A PyTorch implementation of GraphSAGE</a></li></ul></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/31958.html">https://ADAning.github.io/posts/31958.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/GNN/"><span class="chip bg-color">GNN</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/21282.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/11.jpg" class="responsive-img" alt="LightCAKE: A Lightweight Framework for Context-Aware Knowledge Graph Embedding"> <span class="card-title">LightCAKE: A Lightweight Framework for Context-Aware Knowledge Graph Embedding</span></div></a><div class="card-content article-content"><div class="summary block-with-text">2021.03.09: 修正关于引入逆三元组的影响. 2021.04.18: 更新一篇更早的类似论文GAKE. LightCAKE: A Lightweight Framework for Context-Aware Knowledge</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-03-08 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></span></div></div><div class="card-action article-tags"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/22934.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/8.jpg" class="responsive-img" alt="ConvBERT: Improving BERT with Span-based Dynamic Convolution"> <span class="card-title">ConvBERT: Improving BERT with Span-based Dynamic Convolution</span></div></a><div class="card-content article-content"><div class="summary block-with-text">ConvBERT: Improving BERT with Span-based Dynamic Convolution 本文前置知识: Light Weight Convolution: 详见基于轻量级卷积和动态卷积替代的注意力机制.</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-02-12 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/NLP/"><span class="chip bg-color">NLP</span> </a><a href="/tags/CNN/"><span class="chip bg-color">CNN</span> </a><a href="/tags/Attention/"><span class="chip bg-color">Attention</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">325.7k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>