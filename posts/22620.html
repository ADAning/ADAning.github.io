<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/0.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span> </a><a href="/tags/Vocoder/"><span class="chip bg-color">Vocoder</span> </a><a href="/tags/TTS/"><span class="chip bg-color">TTS</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2025-01-17</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2025-01-17</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 1.8k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 7 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li>HiFi - GAN: <a href="https://adaning.github.io/posts/43190.html">HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</a>.</li></ul></blockquote><h1 id="EVA-GAN-Enhanced-Various-Audio-Generation-via-Scalable-Generative-Adversarial-Networks"><a href="#EVA-GAN-Enhanced-Various-Audio-Generation-via-Scalable-Generative-Adversarial-Networks" class="headerlink" title="EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks"></a>EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks</h1><p>本文是论文<a href="https://arxiv.org/abs/2402.00892" target="_blank" rel="noopener">EVA-GAN: Enhanced Various Audio Generation via Scalable Generative Adversarial Networks</a> 的阅读笔记和个人理解. 论文来自<a href="https://github.com/leng-yue" target="_blank" rel="noopener">冷月(NVIDIA)</a>, 同时也是<a href="http://fish.audio" target="_blank" rel="noopener">Fish Audio</a>的创始人.</p><h2 id="EVA-GAN"><a href="#EVA-GAN" class="headerlink" title="EVA - GAN"></a>EVA - GAN</h2><p>EVA - GAN完成了GAN based Vocoder在数据, 模型规模上的Scaling, 它本质上是<a href="https://adaning.github.io/posts/43190.html">HiFi-GAN</a>的进化版.</p><h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>GAN - based Vocoder的目标是将<strong>梅尔频谱</strong>相同, 由GAN Loss, Mel Spectrum Loss, Feature Matching Loss三个部分组成.</p><p><strong>GAN Loss (Adversarial Loss)</strong>:<br>$$<br>\begin{aligned}<br>&amp;L_{a d v}(G)=\mathbb{E}\left[(D(G(s))-1)^2\right] \\<br>&amp;L_{a d v}(D)=\mathbb{E}\left[(D(x)-1)^2+(D(G(s)))^2\right]<br>\end{aligned}<br>$$</p><p>其中$x$ 为声波的Ground Truth, $s$ 为音频信号的梅尔谱, $D, G$ 分别为GAN的判别器和生成器.</p><p><strong>Mel Spectrum Loss</strong>:<br>$$<br>L_{m e l}(G)=\mathbb{E}\left[||\phi(x)-\phi(G(s))||_1\right]<br>$$</p><p>其中$\phi(\cdot)$ 为得到梅尔谱的函数.</p><p><strong>Feature Matching Loss</strong>:<br>$$<br>L_{f m}(G)=\mathbb{E}\left[\sum_{i=1}^T \frac{1}{N_i}\left||D^i(x)-D^i(G(s))\right||_1\right]<br>$$</p><p>$T$ 为Discriminator的总层数, $N_i$ 代表Discriminator的第$i$ 层.</p><h3 id="Data-Scaling"><a href="#Data-Scaling" class="headerlink" title="Data Scaling"></a>Data Scaling</h3><p>传统的Vocoder使用的数据是相对比较少的, 并且先前的数据质量也相对较差, 存在比如采样率只有24k, 缺乏多样性等诟病. 在BigVGAN中发现, 将数据规模进一步Scaling能取得相当大的提升, 所以作者在这优先考虑的就是Scaling Dataset.</p><p>为此, 作者从Youtube和网易云爬取了包括中文, 英语, 日语等多种语言且多种乐器的音乐共计1.6w小时, 构成数据集HiFi - 16000h.</p><p>此外, 为进一步增强语音表现, 作者从PlayerFM上收集了各类语言的音频共计2w小时, 构成数据集PlayerFM - 20000h.</p><p>在训练的时候, 除去歌声本身, Vocoder也被要求生成一些噪声或者其他物体的声音.</p><p>不过上述数据集需要在抱抱脸上获得许可才能访问数据集:</p><ul><li><a href="https://huggingface.co/datasets/fish-audio-private/hifi-16kh" target="_blank" rel="noopener">fish-audio-private/hifi-16kh · Datasets at Hugging Face</a></li><li><a href="https://huggingface.co/datasets/fish-audio-private/playerfm-20000h" target="_blank" rel="noopener">fish-audio-private/playerfm-20000h · Datasets at Hugging Face</a></li></ul><h3 id="Model-Scaling"><a href="#Model-Scaling" class="headerlink" title="Model Scaling"></a>Model Scaling</h3><p>在TTS上, 与<strong>BigVGAN</strong>中的发现一致, 较大的模型在中等规模的数据集上也好于小模型. 所以作者将EVA - GAN从16.3M直接Scaling到174.4M.</p><h4 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h4><p>从宏观角度来讲, EVA - GAN的Generator从模型角度做了两点改进:</p><ul><li>引入了<strong>ConvNeXt</strong>中的一维卷积模块.</li><li>将<strong>HiFi - GAN</strong>中的Leaky ReLU替换成了SiLU.</li></ul><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/eva-gan1.png" style="zoom:33%"><p>MPD沿用了<strong>HiFi - GAN中的MPD</strong>中的MRD.</p><h4 id="Context-Aware-Module"><a href="#Context-Aware-Module" class="headerlink" title="Context Aware Module"></a>Context Aware Module</h4><p>由于在Scaling的时候会消耗大量的资源, 所以作者认为采用<strong>ConvNeXt</strong> 中的一维卷积的模块Context Aware Module(CAM)能够降低计算压力, 并在性能上取得显著的改进. 作者称其为”The Free Lunch”.</p><h4 id="Renew-Training-Paradigm"><a href="#Renew-Training-Paradigm" class="headerlink" title="Renew Training Paradigm"></a>Renew Training Paradigm</h4><p>在<strong>BigVGAN</strong>中在模型各方面的表现与计算效率之间做出了妥协, EVA - GAN在这方面做出改进, 让更大的模型成功训练.</p><ul><li><strong>Larger Context Window</strong>: 从<a href="https://adaning.github.io/posts/43190.html">HiFi-GAN</a> 和<strong>BigVGAN</strong> 的小窗口(32 / 64帧) 提高到256帧, 这可以取得更好的效果, 也当然带来了更高的计算资源消耗. 所以剩下几点基本上都针对消耗问题做出了优化.</li><li><strong>SiLU in - place activation</strong>: 作者发现Leaky ReLU对加速收敛没有帮助, 直接将Generator和Discriminator中的激活函数替换为原地操作的SiLU减少了30%的GPU显存消耗.</li><li><strong>Gradient Checkpoint</strong>: 256帧的上下文窗口就算在A100上也吃不消, 所以作者用了Gradient Checkpoint, 降低了30%的计算效率, 但将显存消耗从46G砍到了16G.</li><li><strong>TensorFloat32</strong>: 虽然混合精度在LLM上训练很常见, 但作者的设备遇到了fp16训练不稳定的情况(梯度范数很大), 且在bf16上表现不佳. 由于A100支持TensorFloat32(tf32), 作者使用TensorFloat32进行训练.</li><li><strong>Loss Balancer</strong>: 在训练的时候由于有多项Loss的混合, 所以如何平衡它们成为了一个问题. 参考前人的工作, 作者引入了<a href="https://arxiv.org/abs/2210.13438" target="_blank" rel="noopener">Encodec</a>中的Balancer来解决Loss的平衡问题.</li><li><strong>Human-In-The-Loop Artifact Measurement</strong>: 作者团队开发了一个Human-In-The-Loop Artifact Measurement toolkit, 其中包含对SMOS的标注工具和CLI, 用于持续监控和评估生成音频的质量, 以确保符合人类感知.</li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的模型参数设置和实验设置请参考原论文. 应该本身是实验记录性质的缘故, 原文写的比较乱, 这里我也写的简单一些.</p><h3 id="Evaluation-Metrics"><a href="#Evaluation-Metrics" class="headerlink" title="Evaluation Metrics"></a>Evaluation Metrics</h3><p>作者采用了如下几种Metrics:</p><ul><li><strong>Multi - resolution STFT (M-STFT)</strong>: 用于测量多种分辨率下的频谱距离.</li><li><strong>Periodicity error &amp; Voiced / Unvoiced classification</strong>: GAN - based Vocoder中普遍存在浊音 / 清音分类上普遍存在可听错误时, 音频质量会比较低. 该指标能够衡量这种错误出现的频率, 从而提供一个判断音频质量的角度.</li><li><strong>Perceptual evaluation of speech quality (PESQ)</strong>: 广泛使用的语音质量的自动评估标准.</li><li><strong>Similarity Mean Opinion Score (SMOS)</strong>: 用于衡量合成语音与目标说话人之间的音色相似度.</li></ul><h3 id="LibriTTS"><a href="#LibriTTS" class="headerlink" title="LibriTTS"></a>LibriTTS</h3><p>在LibriTTS上, EVA - GAN表现如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/eva-gan2.png" style="zoom:33%"><p>与相对小的模型HiFi - GAN相比, EVA - GAN取得了显著优势.</p><p>与同等规模的BigVGAN相比, EVA - GAN也能有更亮眼的表现.</p><h3 id="DSD-100"><a href="#DSD-100" class="headerlink" title="DSD - 100"></a>DSD - 100</h3><p>作者从DSD - 100随机选择了五类中的10个Track的5秒音频做了合成测试, 各类片段的SMOS结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/eva-gan3.png" style="zoom:33%"><p>Scaling确实有效果. 不过不知道为什么EVA - GAN的big版本在鼓音频上的合成效果比较差.</p><h3 id="Ablation-Studies"><a href="#Ablation-Studies" class="headerlink" title="Ablation Studies"></a>Ablation Studies</h3><p>作者将各类消融实验结果分散在各个表中了, 直接说结论:</p><ul><li>更先进的训练方法和更大的数据集效果更好.</li><li>CAM在EVA - GAN中表现还不错.</li><li>固定数据量不变, 单纯增大模型, 可以带来更好的效果.</li></ul><p>HiFi - GAN和EVA - GAN各规模的对比:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/eva-gan4.png" style="zoom:33%"><p>EVA - GAN的big版本比base要大很多, 但推理时间只增长了一倍, 换来了不错的性能提升.</p><h3 id="Spectrogram-Visualizations"><a href="#Spectrogram-Visualizations" class="headerlink" title="Spectrogram Visualizations"></a>Spectrogram Visualizations</h3><p>作者将各类GAN - based Vocoder在歌声合成场景下横向对比, 重新对比波形转换成的[梅尔频谱](../Basic Knowledge/Audio Concept.md#梅尔频谱):</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/eva-gan5.png" style="zoom:50%"><p>从梅尔谱结果上可以看到, HiFi - GAN生成的谱子波形分辨率很低, EVA - GAN提高了生成的质量. 尤其是在高频区域, 包括EVA - GAN - base在内, 表现都不是很好, EVA - GAN - big才能有比较清晰的建模.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>EVA - GAN是一个在<strong>模型规模</strong>和<strong>数据规模</strong>都Scaling过后的<strong>HiFi - GAN</strong>, 在实验设计上参考了很多<strong>BigVGAN</strong>的东西. 还是能从这篇报告中找到很多和Vocoder的相关文献的. EVA - GAN的增强版本Firefly - GAN也被用在了<a href="https://arxiv.org/abs/2411.01156" target="_blank" rel="noopener">Fish-Speech</a>中.</p><p>从实验结果来看, 高频信息在Scaling(主要是数据更充足)后确实能够得到更充分的建模, 且差距也比较明显. 高频本身也是网络较难学到的信息.</p><p>在Model Scaling的同时也并没有特别的增加推理时长, 感觉还是算相对友好. 毕竟推理时长变长了一倍, 但Vocoder参数可不止涨了一倍, 可能要归功于CAM.</p><blockquote><p>要是数据集能进一步公开就更好了.</p></blockquote></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/22620.html">https://ADAning.github.io/posts/22620.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span> </a><a href="/tags/Vocoder/"><span class="chip bg-color">Vocoder</span> </a><a href="/tags/TTS/"><span class="chip bg-color">TTS</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/21614.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/15.jpg" class="responsive-img" alt="CLAP: Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation"> <span class="card-title">CLAP: Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation本文是论文Large-Sca</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2025-02-07 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/63265.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/21.jpg" class="responsive-img" alt="Whisper: Robust Speech Recognition via Large-Scale Weak Supervision"> <span class="card-title">Whisper: Robust Speech Recognition via Large-Scale Weak Supervision</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Robust Speech Recognition via Large-Scale Weak Supervision本文是论文Robust Speech Recognition via Large-Scale Weak Supervisio</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2025-01-14 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> DaNing</span></div></div><div class="card-action article-tags"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/ASR/"><span class="chip bg-color">ASR</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">406k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>