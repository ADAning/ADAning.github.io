<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="QIDN: Query-based Instance Discrimination Network for Relational Triple Extraction, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>QIDN: Query-based Instance Discrimination Network for Relational Triple Extraction | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/17.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">QIDN: Query-based Instance Discrimination Network for Relational Triple Extraction</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span> </a><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2023-02-10</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2025-03-23</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3.3k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 13 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="Query-based-Instance-Discrimination-Network-for-Relational-Triple-Extraction"><a href="#Query-based-Instance-Discrimination-Network-for-Relational-Triple-Extraction" class="headerlink" title="Query-based Instance Discrimination Network for Relational Triple Extraction"></a>Query-based Instance Discrimination Network for Relational Triple Extraction</h1><p>本文是论文<a href="https://arxiv.org/abs/2211.01797" target="_blank" rel="noopener">Query-based Instance Discrimination Network for Relational Triple Extraction</a> 的阅读笔记和个人理解, 论文来自<strong>EMNLP 2022</strong>.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>作者认为, 现有的方法在抽取三元组时要么是通过<strong>立体透视图</strong>的方法, 要么是学到每一种关系的独立分类器来完成Tagging:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn1.png" style="zoom:75%"><p>几乎之前的所有方法都可以归类到这类中, 这大类方法仍然导致有<strong>误差错误传播</strong>, <strong>关系冗余</strong>, 以及<strong>缺少三元组之间的高级连接</strong>的问题.</p><p>作者提出了一种对三元组<strong>Instance Level</strong>的表示方法, 通过<strong>Query Embedding</strong>对<strong>Token Embedding</strong>完成一步抽取, 从而规避上述问题:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn2.png" style="zoom:75%"><blockquote><p>图示中的星星代表Relation Type Embedding, 而圆圈代表Query Embedding, 不难看出作者的应该要尽可能让同关系下的Query Embedding环绕在Relation Embedding周围. 这种方法在空间中可以保留关系之间的语义信息, <strong>对比学习</strong>可以达到这种目的.</p><p>另外, 看到Query Embedding这个词的时候, 对CV略有了解的小伙伴可能会想到近年在CV中影响力很大的<strong>DETR</strong>: <a href="https://arxiv.org/abs/2005.12872" target="_blank" rel="noopener">End-to-End Object Detection with Transformers</a>, 事实上本文也是DETR在NLP中的应用. 如果对DETR还不了解, 建议花几分钟时间阅读一下DETR的架构(其实就是标准的Transformer)和基本思想, 非常简洁也非常简单. 如果你只知道<a href="https://adaning.github.io/posts/50175.html">SPN</a>而不知道DETR, 也可以不看DETR, 因为SPN和DETR几乎完全一致.</p></blockquote><h2 id="QIDN"><a href="#QIDN" class="headerlink" title="QIDN"></a>QIDN</h2><p>QIDN的概览模型图如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn3.png" style="zoom:25%"><p>在经过Sentence Encoder编码后, 结合Query在Decoder中完成Triple Prediction. 此外, 使用Instance Discriminator在空间中用<strong>对比学习约束</strong>预测头得到的三元组表示.</p><h3 id="Task-Formulation"><a href="#Task-Formulation" class="headerlink" title="Task Formulation"></a>Task Formulation</h3><p>对于输入句子$X=x_1, x_2, \ldots, x_n$, 实体集$\mathcal{E}$ 中的实体可以被表示为$(x_i, x_j, t_e)$, $x_i, x_j$ 分别为实体的左右边界Token. 而$t_e$ 代表预定义好的实体类型集合$\mathcal{Y}_e$ 中的实体类型.</p><p>对于关系集合$\mathcal{R}$, 每种关系被表示为$(e_1, e_2, t_r)$, $e_1, e_2 \in \mathcal{E}$ 分别为头实体和尾实体, $t_r$ 为预定义好的关系集合$\mathcal{Y}_r$ 中的关系类型. 除此外, 在$\mathcal{Y}_e, \mathcal{Y}_r$ 中还有$\varnothing$ 代表没有识别到任何关系或者任何实体.</p><h3 id="Sentence-Encoder"><a href="#Sentence-Encoder" class="headerlink" title="Sentence Encoder"></a>Sentence Encoder</h3><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn4.png" style="zoom:67%"><p>对于输入句子$X$, 作者用BERT获取它每个Token的上下文表示, 然后送入一个双层LSTM获得最终的句子表示$H \in \mathbb{R}^{n\times d}$, 其中$n, d$ 分别为句子长度和Hidden size.</p><h3 id="Triple-Prediction"><a href="#Triple-Prediction" class="headerlink" title="Triple Prediction"></a>Triple Prediction</h3><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn5.png" style="zoom:67%"><p>作者使用$M$ 个Instance Level Query $Q=\mathbb{R}^{M\times d}$来查询句子中所包含的所有三元组.</p><blockquote><p><strong>DETR最早被用于目标检测</strong>, 每个Query都对应了图像中的一个<strong>目标</strong>(Bounding Box和物体类别). 与之类似的, <strong>在QIDN中, 每个Query对应着一个关系三元组</strong>.</p></blockquote><p>由于RTE任务需要抽取出关系特定下的头尾实体, 这意味着每个Query Embedding不但能指出对应的头尾实体, 还有头尾实体间关系, 所以在这个模块中作者需要构建对实体和关系的两种Query.</p><h4 id="Transformer-based-Decoder"><a href="#Transformer-based-Decoder" class="headerlink" title="Transformer - based Decoder"></a>Transformer - based Decoder</h4><p>Decoder是由$L$ 层的Transformer Decoder的堆叠, 其中Attention计算方式如下:</p><p>$$<br>\text { Attention }(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^T}{\sqrt{d_k}}\right) V<br>$$</p><p>其中$Q, K, V$ 分别为Query, Key, Value矩阵, $1/\sqrt{d_k}$ 为缩放因子.</p><p>Transformer Decoder的堆叠可以记为:</p><p>$$<br>\operatorname{Decoder}(Q, H^\prime) = \operatorname{Attention}(Q, H^\prime, H^\prime)<br>$$</p><p>在DETR的架构中, Decoder端的Query便是<strong>Query Embedding</strong>, Key和Value则是原图信息.</p><p>在QIDN中, 作者没有直接使用Sentence Encoder中的$H$ 作为Decoder中需要的Key和Value, 而是构造了一种<strong>Span Level</strong>的表示来获得层次语义信息. 令$S=s_1, s_2, \ldots, s_{n_s}$ 为句子$X$ 中所有的Span, 对于任意一Span $s_i \in S$, 其Span表示$H_i^{span}$ 为$H$ 中的Span边界表示和长度Embedding的拼接:</p><p>$$<br>H_{\mathrm{i}}^{\text {span }}=\left[H_{\text {start }(\mathrm{i})} ; H_{\mathrm{end}(\mathrm{i})} ; \phi\left(s_{\mathrm{i}}\right)\right]<br>$$</p><p>$[;]$ 为拼接操作, $H_{\text {start }(\mathrm{i})} , H_{\mathrm{end}(\mathrm{i})}$ 分别为起始和结束Token的表示, $\phi(s_i)$ 为NER中Span based方法常用的长度Embedding, 可以加入一些Span的长度信息. 最终Span Level的表示为$H^{span} \in \mathbb{R}^{n_s \times d}$.</p><blockquote><p>我认为在这里选择Span作为单位构建表示, 可以获得大量的<strong>负样本</strong>, 有利于<strong>对比学习</strong>.</p></blockquote><p>前面提到过, 同一个Query需要同时能够抽取关系和实体, 因此作者将每个Query兵分两路, 变为Relation Query $Q_r$和Entity Query $Q_e$:</p><p>$$<br>\left[Q_r ; Q_e\right]=\operatorname{Decoder}\left(\left[Q W_r ; Q W_e\right], H^{\text {span }}\right)<br>$$</p><p>其中$W_r, W_e \in \mathbb{R}^{d \times d}$ 为可训练参数.</p><p>更直观一点的话, 作者将Decoder的结构放在附录里:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn6.png" style="zoom:25%"><blockquote><p>其实就是普通Transformer Decoder, 主要区别在于Query的生成拆分为了Entity Query和Relation Query两个branch, 并且在Cross Attention中采用的Key和Value是Span Level的.</p></blockquote><p>综上, 如果有了成对的$Q_r, Q_e$, 就可以用简单的预测头将每个$Q$ 所对应的三元组预测出来.</p><h4 id="Relation-Head"><a href="#Relation-Head" class="headerlink" title="Relation Head"></a>Relation Head</h4><p>对于Relation Query $Q_r$, 将其送入一个FFN中来预测第$i$ 个Query $Q_r^i$ 对应三元组的关系类型$c$ 的概率$P_{i c}^t$:</p><p>$$<br>P_{i c}^t=\frac{\exp \left(Q_r^i W_t^c+b_t^c\right)}{\sum_{c^{\prime}}^{\left|\mathcal{Y}_r\right|} \exp \left(Q_r^i W_t^{c^{\prime}}+b_t^{c^{\prime}}\right)}<br>$$</p><p>其中$W_t \in \mathbb{R}^{|\mathcal{Y}_r| \times d}, b_t \in \mathbb{R}^{|\mathcal{Y}_r|}$ 为可学习参数.</p><h4 id="Entity-Head"><a href="#Entity-Head" class="headerlink" title="Entity Head"></a>Entity Head</h4><p>为了预测三元组中实体的边界, 作者将Entity Query $Q_e$ 和Token表示$H$ 都经过FFN变换:</p><p>$$<br>\begin{aligned}<br>E_\delta=Q_e<br>W_{\delta}\\<br>H_s=H W_s<br>\end{aligned}<br>$$</p><p>其中$\delta \in \mathcal{C} =\set{l_{sub}, r_{sub}, l_{obj}, r_{obj}}$ 代表Subject或者Object的左右边界, $W_\delta, W_s \in \mathbb{R}^{d \times d}$ 为可训练参数.</p><p>接着用<strong>余弦相似度</strong>$S(\cdot)$ 来衡量Entity Query生成的新表示$E_\delta$ 和原文表示$H_s$ 之间的相似度得分:</p><p>$$<br>S\left(\mathbf{v}_i, \mathbf{v}_j\right)=\frac{\mathbf{v}_i}{\left\Vert\mathbf{v}_i\right\Vert} \cdot \frac{\mathbf{v}_j}{\left\Vert\mathbf{v}_j\right\Vert}<br>$$</p><p>根据得分, 做个Softmax就可以得到第$i$ 个Entity Query对应的边界Token是第$j$ 个Token的概率:</p><p>$$<br>P_{i j}^\delta=\frac{\exp S\left(E_\delta^i, H_s^j\right)}{\sum_{j^{\prime}}^n \exp S\left(E_\delta^i, H_s^{j^{\prime}}\right)}<br>$$</p><p>其中$n$ 为句子中Token的数量.</p><p>通过Relation Head, 可以得到Instance Query $Q$ 对应的三元组关系类型$c$, 通过Entity Head, 就可以用相似度得到三元组中Subject和Object的左右边界, 由此来确定Query对应的三元组.</p><h3 id="Instance-Discriminator"><a href="#Instance-Discriminator" class="headerlink" title="Instance Discriminator"></a>Instance Discriminator</h3><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn7.png" style="zoom:67%"><p>在Instance Discriminator中, 作者希望把预测头中得到的表示进一步聚合, 当做最初的三元组表示, 并在空间中使这些三元组表示满足某种<strong>约束</strong>, 来建立三元组之间的全局链接, 并且让它们具有类别语义信息.</p><h4 id="Aggregation"><a href="#Aggregation" class="headerlink" title="Aggregation"></a>Aggregation</h4><p>首先要用关系头的表示$Q_r$, 然后简单的把它们相加到一起, <strong>聚合</strong>成三元组初始表示$\mathbf{v}$:</p><p>$$<br>\mathbf{v}=Q_r W+\sum_{\delta \in \mathcal{C}} E_\delta<br>$$</p><blockquote><p>这里对$Q_r$ 做一次变换是为了和Entity Head对齐, 因为$E_\delta$ 已经是由$Q_e$ 做了一次变换得到的.</p></blockquote><h4 id="Training-Objective"><a href="#Training-Objective" class="headerlink" title="Training Objective"></a>Training Objective</h4><p>对于关系集$\mathcal{R} = \set{\mathbf{r}_1, \cdots, \mathbf{r}_{|\mathcal{Y}_r|}}$, 对每种关系都建立一个随机初始化的Relation Type Embedding, 作为关系的表示.</p><p>作者希望三元组实例和关系嵌入在空间中满足下述两个特点:</p><ol><li>对于三元组<strong>实例和实例</strong>之间, 应满足同关系内更近, 不同关系的更远.</li><li>对于三元组<strong>实例和关系</strong>之间, 应满足三元组和自身关系对应的关系嵌入更近.</li></ol><p><strong>对比学习</strong>就是做这个的, 所以作者使用InfoNCE来建模上述两个要求.</p><p>对于第一个特点, 同关系三元组更近, 不同关系三元组更远:</p><p>$$<br>\mathcal{L}_{\mathrm{ins}}=-\sum_c \sum_{i, j} \log \frac{\exp S\left(\mathbf{v}_i^c, \mathbf{v}_j^c\right)}{\sum_{c^{\prime}, j^{\prime}} \exp S\left(\mathbf{v}_i^c, \mathbf{v}_{j^{\prime}}^{c \prime}\right)}<br>$$</p><p>其中$(\mathbf{v}_i^c, \mathbf{v}_j^c)$ 代表同种关系类型$c$ 下的实例对.</p><p>与之类似的, 第二个特点要求三元组和自身对应的关系更近:</p><p>$$<br>\mathcal{L}_{\mathrm{cls}}=-\sum_{i, c} \log \frac{\exp S\left(\mathbf{v}_i^c, \mathbf{r}_c\right)}{\sum_{c^{\prime}} \exp S\left(\mathbf{v}_i^c, \mathbf{r}_{c^{\prime}}\right)}<br>$$</p><p>其中, $\mathbf{v}_i^c$ 是关系$c$ 的三元组实例, $\mathbf{r}_c \in \mathcal{R}$ 是关系$c$ 对应的关系嵌入.</p><p>这样就建模了关系之间的语义信息, 而不是让不同关系独立学习, 并且使得不同关系的三元组之间存在全局链接.</p><h3 id="Training-and-Inference"><a href="#Training-and-Inference" class="headerlink" title="Training and Inference"></a>Training and Inference</h3><h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><p>在训练时, 记三元组预测Loss $\mathcal{L}_{tri}$ 为每个Instance Query自身所对应的<strong>最优匹配三元组</strong>的关系类型预测交叉熵和头尾实体左右边界的交叉熵之和:</p><p>$$<br>\mathcal{L}_{\text {tri }}=-\sum_{i=1}^M\left(\log P_{\sigma(i)}^t+\sum_{\delta \in \mathcal{C}} \log P_{\sigma(i)}^\delta\right)<br>$$</p><p>$M$ 为Query的数量, $\sigma$ 为<strong>最优匹配</strong>的三元组.</p><blockquote><p>如果还不清楚”最优匹配”, 可以看DETR中的Loss部分, 也可以看<a href="https://adaning.github.io/posts/50175.html#Bipartite-Matching-Loss">SPN的二部图匹配Loss</a>部分.</p></blockquote><p>最终的Loss为前面提到的对比学习Loss和三元组预测Loss之和:</p><p>$$<br>\mathcal{L} = \mathcal{L}_{tri} + \mathcal{L}_{ins} + \mathcal{L}_{cls}<br>$$</p><h4 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h4><p>在推理时:</p><ul><li>三元组可以由Instance Query$\mathcal{Y}_i=\left(\mathcal{Y}_i^t, \mathcal{Y}_i^\delta\right), \delta \in \mathcal{C}$ 得到.</li><li>关系类型预测可以由$\mathcal{Y}_i^t=\arg \max _c\left(P_{i c}^t\right)$ 得到.</li><li>头尾实体的左右边界可以由$\mathcal{Y}_i^\delta=\arg \max _k\left(P_{i k}^\delta\right)$ 得到.</li><li>预测类型为$\varnothing$ 的三元组直接被滤去.</li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的参数设置请参照原论文.</p><h3 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h3><p>作者选用了RTE中常用的三个数据集NYT, WebNLG*, NYT*, 和ERE中常用的数据集ACE05和SciERC, 统计信息如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn8.png" style="zoom:67%"><p>在作者的论文中, 部分匹配数据集为是不带*的, 而精准匹配是带*的. 和RTE论文的习惯刚好相反. 也就是说, 作者写的是WebNLG, 后续实验结果实际上是WebNLG*, NYT和NYT*也要颠倒一下, 下同.</p><h3 id="Overall-Performance"><a href="#Overall-Performance" class="headerlink" title="Overall Performance"></a>Overall Performance</h3><p>QIDN在RTE三个数据集NYT, WebNLG*, NYT* 上结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn9.png" style="zoom:75%"><p>QIDN相较于作者给出的Baseline有非常大的进步, 这个性能其实也挺能打的.</p><p>在ERE上两个数据集ACE05和SciERC上结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn10.png" style="zoom:25%"><p>这里的RE的实验结果均为严格标准, 即要求实体类型, 关系类型, 实体边界均正确时的F1. QIDN也取得了SOTA, 相较于之前的一些Table Filling based模型比如<a href="https://adaning.github.io/posts/27457.html">UniRE</a>, <a href="https://adaning.github.io/posts/8137.html">PFN</a>都有明显的提升.</p><h3 id="Analysis-on-Complex-Scenarios"><a href="#Analysis-on-Complex-Scenarios" class="headerlink" title="Analysis on Complex Scenarios"></a>Analysis on Complex Scenarios</h3><p>QIDN在NYT*和WebNLG*复杂场景表现如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn11.png" style="zoom:75%"><p>根据Baseline来看, QIDN对于三元组数量比较多的情况似乎比较擅长, 有比较明显的提升, 对于一般三元组的情况抽取进步也比较大.</p><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p>作者尝试了以下设定:</p><ul><li>w/o $H_{span}$: 将Span Level表示替换为<strong>Token Level</strong>表示.</li><li>w/o $Q_e, Q_r$: 去掉对实体和关系Query的特化, 统一用<strong>同一种Query</strong>来代替.</li><li>w/o $\mathcal{L}_{ins}$: 去掉<strong>Instance Pair</strong>之间的对比学习Loss.</li><li>w/o $\mathcal{L}_{cls}$: 去掉<strong>Instance和Relation Embedding</strong>之间的对比学习Loss.</li><li>w/o $\mathcal{L}_{ins}, \mathcal{L}_{cls}$: 去掉<strong>所有对比学习</strong>Loss.</li></ul><p>实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn12.png" style="zoom:75%"><p>从中观察到, 影响比较大的是对比学习的两个Loss, 无论移除哪个都会产生较大的性能衰减. 将Query兵分两路也可以带来一些提升. Span Level的表示对WebNLG来说影响较大.</p><h3 id="Topology-of-Relations"><a href="#Topology-of-Relations" class="headerlink" title="Topology of Relations"></a>Topology of Relations</h3><p>在NYT上对Relation Embedding经过L2正则化后用PCA的可视化如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn13.png" style="zoom:33%"><p>语义相近的关系嵌入都比较靠近. 与person相关的几个关系, 语义差别较大, 距离也比较远.</p><h3 id="Error-Analysis"><a href="#Error-Analysis" class="headerlink" title="Error Analysis"></a>Error Analysis</h3><p>作者将错误按NER和RE任务划分:</p><ul><li>NER: ECE(Entity Classification Error), ELE(Entity Localtion Error).</li><li>RE: RCE(Relation Classification Error), PCE(Entity-Pair Classification Error), PLE(Entity-Pair Location Error).</li></ul><p>在ACE05和SciERC这两个数据集上测试集错误比例如下:</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/qidn14.png" alt=""></p><p>最高的是实体识别相关的ELE和PLE, 对关系分类RCE和PCE错误不明显, 证明了作者方法的有效性.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>QIDN用<strong>Query based</strong>方法, 从Instance Level的角度解决了RE任务. 将Instance Query拆分为<strong>Relation Query</strong>和<strong>Entity Query</strong>两个branch从而将Query对应的三元组抽取出来, 同时在空间中用<strong>对比学习约束</strong>三元组, 使得三元组之间存在全局关联, 并捕获了关系的语义信息.</p><p>说真的, 自上次SPN以来, 已经有很长时间没有看到Query based Method在联合抽取上的模型了. 可惜代码没有开源.</p><blockquote><p>我个人认为, 如果了解预训练模型<a href="http://arxiv.org/abs/2012.15022" target="_blank" rel="noopener">ERICA</a>, 会对理解QIDN的对比学习任务设计更有帮助. QIDN在对比学习的设计上其实与ERICA非常相似.</p></blockquote></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/33099.html">https://ADAning.github.io/posts/33099.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span> </a><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/8982.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/21.jpg" class="responsive-img" alt="大模型并行优化"> <span class="card-title">大模型并行优化</span></div></a><div class="card-content article-content"><div class="summary block-with-text">大模型并行优化为什么要并行优化?大就是好, 虽然丛2019年人们的认识普遍就是大就是好, 这个概念在当今依然没有被改变, 只是有了更深刻的认识. 所以, 为什么要并行? 虽然大就是好, 模型太大显存吃不消(空间). 虽然大就是好</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2023-06-01 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97/"><span class="chip bg-color">并行计算</span> </a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"><span class="chip bg-color">分布式</span> </a><a href="/tags/ZeRO/"><span class="chip bg-color">ZeRO</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/4431.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/22.jpg" class="responsive-img" alt="UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction"> <span class="card-title">UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction本文是论文UniRel: Unified Representation</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2023-01-03 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">420.2k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>