<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="DDPM: Denoising Diffusion Probabilistic Model, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>DDPM: Denoising Diffusion Probabilistic Model | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/4.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">DDPM: Denoising Diffusion Probabilistic Model</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/DDPM/"><span class="chip bg-color">DDPM</span> </a><a href="/tags/Diffusion/"><span class="chip bg-color">Diffusion</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2024-10-07</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2024-10-07</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 4.4k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 22 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="DDPM-Denoising-Diffusion-Probabilistic-Model"><a href="#DDPM-Denoising-Diffusion-Probabilistic-Model" class="headerlink" title="DDPM: Denoising Diffusion Probabilistic Model"></a>DDPM: Denoising Diffusion Probabilistic Model</h1><h2 id="DDPM-Overview"><a href="#DDPM-Overview" class="headerlink" title="DDPM Overview"></a>DDPM Overview</h2><ul><li>DDPM: <a href="https://arxiv.org/abs/2006.11239" target="_blank" rel="noopener">Denoising Diffusion Probabilistic Models</a>.</li></ul><p>扩散概率模型(Diffusion Probabilistic Model, 简称<strong>Diffusion Model</strong>)是一个用<strong>变分推断</strong>训练的<strong>参数化</strong>的<strong>马尔科夫链</strong>, 用于在有限时间内生成与数据匹配的样本.</p><p>只看一张图其实就能很好理解DDPM的大致思想:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ddpm1.png" style="zoom:67%"><p>如果直接对某个数据(样本)分布不断加<strong>可控的噪声扰动</strong>, 直到它对应的Representation成了<strong>高斯噪声</strong>, 将上述过程反转过来就可以是生成数据分布(样本)的过程.</p><p>虽然该分布不受限于任何种类的数据类型, 也不受限于任何的模态, 但本文中均以图像为例.</p><p>所以, Diffusion Model是一个由$T$ 个时间步<strong>逐渐</strong>将<strong>潜空间</strong>中的原样本$\mathbf{x}_0$ 生成(在这里也可以叫<strong>恢复</strong>)出来的Latent Variable Model $p_\theta\left(\mathbf{x}_0\right)=\int p_\theta\left(\mathbf{x}_{0: T}\right) d \mathbf{x}_{1: T}$. 这个过程是多次逐渐进行的, 积分符号可以表示这一过程.</p><p>其中$\mathbf{x}_1, \dots, \mathbf{x}_T$ 为与$\mathbf{x}_0 \sim q(\mathbf{x}_0)$ 维度相同的Latent.</p><blockquote><p>注: Diffusion Model里常称$\mathbf{x}_0$ 为干净的原图像, $\mathbf{x}_T$ 为完全加噪的图像, 即去噪时间步$T$ 实际上是相对于Forward Process来说的, 而不是Reverse Process.</p></blockquote><h2 id="Reverse-Process"><a href="#Reverse-Process" class="headerlink" title="Reverse Process"></a>Reverse Process</h2><p>从时间步$T$ 到0的过程, 即联合分布$p_\theta\left(\mathbf{x}_{0: T}\right)$ 被称为<strong>逆过程</strong>(<strong>Reverse Process</strong>), 它被定义为从时间步$T$ 时且与$\mathbf{x}_0$ 相关的标准正态分布$p\left(\mathbf{x}_T\right)=\mathcal{N}\left(\mathbf{x}_T ; \mathbf{0}, \mathbf{I}\right)$ 开始转移的马尔科夫链(一阶, 下同):</p><p>$$<br>p_\theta\left(\mathbf{x}_{0: T}\right)=p\left(\mathbf{x}_T\right) \prod_{t=1}^T p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)<br>$$</p><p>即Diffusion Model从与$\mathbf{x}_0$ 相关的标准正态噪声$p\left(\mathbf{x}_T\right)$ 中采样, 逐渐去噪后可得到原样本$\mathbf{x}_0$, 该过程是马尔科夫链, 时间步$t-1$ 的分布由时间步$t$ 决定:</p><p>$$<br>p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)=\mathcal{N}\left(\mathbf{x}_{t-1} ; \boldsymbol{\mu}_\theta\left(\mathbf{x}_t, t\right), \boldsymbol{\Sigma}_\theta\left(\mathbf{x}_t, t\right)\right)<br>$$</p><p>这个Reverse Process中的”Reverse”是相对于什么来说的呢?</p><h2 id="Forward-Process"><a href="#Forward-Process" class="headerlink" title="Forward Process"></a>Forward Process</h2><p>Diffusion Model区别于其他Latent Variable Model的特点是将近似后验$q\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right)$ 建模为一个由一系列变量$\beta_1, \dots, \beta_T$ 控制的<strong>逐渐添加高斯噪声的马尔科夫链</strong>, 即<strong>Forward Process(Diffusion Process)</strong>:</p><p>$$<br>q\left(\mathbf{x}_{1: T} \mid \mathbf{x}_0\right) =\prod_{t=1}^T q\left(\mathbf{x}_t \mid \mathbf{x}_{t-1}\right)<br>$$</p><p>$\beta_t$ 是由重参数学到, 或者是设定为一个常量超参, 在作者的论文中设定为常量超参, 且是<strong>逐渐递增</strong>的.</p><p>与Reverse Process对应的, 加噪过程也是马尔科夫链. 相对于Forward Process来说, $t$ 时刻的$\mathbf{x}_t$ 由$\mathbf{x}_{t-1}$ 和高斯噪声$\mathbf{\epsilon_{t-1}}$ 得到:</p><p>$$<br>\mathbf{x}_t =\sqrt{1-\beta_t} \mathbf{x}_{t-1}+\beta_t \mathbf{\epsilon}_{t-1}<br>$$</p><p>在噪声扰动的情况下, $\mathbf{x}_t$ 对应的后验概率分布为一个均值为$\sqrt{1-\beta_t} \mathbf{x}_{t-1}$, 方差为$\beta_t \mathbf{I}$ 的正态分布:</p><p>$$<br>q\left(\mathbf{x}_t \mid \mathbf{x}_{t-1}\right)=\mathcal{N}\left(\mathbf{x}_t ; \sqrt{1-\beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I}\right)<br>$$</p><p>从公式中不难发现, $\beta_t$ 越大, $\mathbf{x}_{t-1}$ 提供的均值就越小, 方差也会越来越大, $\mathbf{x}_t$ 与$\mathbf{x}_{t-1}$ 越不像. 由于$\beta_t$ 是自增的, 所以随着$t$ 的增大, 噪声强度也越来越大. 所以当我们与Reverse Process关联时, 去掉的噪声强度也是逐渐变小的.</p><p>而且, 当若干次加噪$T \rightarrow \infty$ 时, $q(\mathbf{x}_T | \mathbf{x}_{T-1})$ 会直接服从标准正态分布.</p><p>结合上面内容, 重温下这幅图:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ddpm2.png" style="zoom:67%"><ul><li>从$\mathbf{x}_T \rightarrow \mathbf{x}_0$ 的过程为Reverse Process, 即从噪声生成图像的过程.</li><li>从$\mathbf{x}_0 \rightarrow \mathbf{x}_T$ 的过程为Forward Process, 即从原图逐步添加噪声的过程.</li></ul><p>上面这个加噪过程如果一点一点按照时间步$T$ 来走是非常耗时的. 可以通过推导来直接从$\mathbf{x}_0$ 得到$t$ 时刻加噪后的$\mathrm{x}_t$.</p><p>令$\alpha_t = 1 - \beta_t$, $\bar{\alpha_t} = \prod_{s=1}^t \alpha_s$, 可以得到:</p><p>$$<br>\begin{aligned}<br>\mathbf{x}_t &amp; =\sqrt{\alpha_t} \mathbf{x}_{t-1}+\sqrt{1-\alpha_t} \mathbf{\epsilon}_{t-1} \\<br>&amp; =\sqrt{\alpha_t}\left(\sqrt{\alpha_{t-1}} \mathbf{x}_{t-2}+\sqrt{1-\alpha_{t-1}} \mathbf{\epsilon}_{t-2}\right)+\sqrt{1-\alpha_t} \mathbf{\epsilon}_{t-1} \\<br>&amp; =\sqrt{\alpha_t \alpha_{t-1}}\mathbf{x}_{t-2}+\sqrt{\sqrt{\alpha_t-\alpha_t \alpha_{t-1}}^2+{\sqrt{1-\alpha_t}}^2} \bar{\mathbf{\epsilon}}_{t-2} \quad(\bar{\mathbf{\epsilon}}_{t-2}\rightarrow 两个正态分布噪声合并) \\<br>&amp; =\sqrt{\alpha_t \alpha_{t-1}} \mathbf{x}_{t-2}+\sqrt{1-\alpha_t \alpha_{t-1}} \bar{\mathbf{\epsilon}}_{t-2} \\<br>&amp; =\cdots \\<br>&amp; =\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\mathbf{\alpha}}_t} \mathbf{\epsilon}<br>\end{aligned}<br>$$</p><p>因此:</p><p>$$<br>q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)=\mathcal{N}\left(\mathbf{x}_t ; \sqrt{\bar{\alpha}_t} \mathbf{x}_0,\left(1-\bar{\alpha}_t\right) \mathbf{I}\right)<br>$$</p><p>所以在时间步$t$ 加噪后的$\mathbf{x}_t$ 其实可以看成是原图$\mathbf{x}_0$ 和跟噪音$\mathbf{\epsilon}$ 之间的线性组合, 所以就可以直接一步采样直接得到$\mathbf{x}_t$.</p><h2 id="Reverse-Process-Again"><a href="#Reverse-Process-Again" class="headerlink" title="Reverse Process Again"></a>Reverse Process Again</h2><p>虽然我们前面介绍了Reverse Process, 但并没有说明怎么做. 让我们把思路重新回到Reverse Process来.</p><p>接上文, 既然我们获得了从$\mathbf{x}_t$ 一步到$\mathbf{x}_0$ 的关系, 那直接把它平推过去是不是可以从加噪后的图像$\mathbf{x}_T$ 直接得到加噪前原图像$\mathbf{x}_0$ 了:</p><p>$$<br>\mathbf{x}_0 = \frac{\mathbf{x}_t}{\sqrt{\bar{\alpha_t}}} - \sqrt{\frac{1-\bar{\alpha}}{\bar{\alpha}}}\mathbf{\epsilon}_\theta\left(\mathbf{x}_t, T\right)<br>$$</p><p>要是啥事都有这么简单就好了. $T$ 稍微小点的时候, 模型可能还能勉强预测一下, 因为此时噪声方差还不够大. 当$T$ 比较大的时候, 噪声方差变得很大, 模型很难通过<strong>一步</strong>把整个多次混合的噪声一次性全预测出来.</p><p>那一步不行, 拆分成<strong>多步</strong>一点一点往回退行不行? 这样大幅度降低了模型恢复的难度.</p><p>没准可以, 先试试. 首先把$\mathbf{x}_{t-1}$ 和$\mathbf{x}_t$ 之间的关系表示出来:</p><p>$$<br>\mathbf{x}_{t-1} = \frac{\mathbf{x}_t}{\sqrt{\alpha_t}} - \frac{\sqrt{1-\alpha_t}}{\sqrt{\alpha_t}} \mathbf{\epsilon}_{t-1}<br>$$</p><p>咱们能这么表示出来是因为Forward Process的$t$ 时刻已知$\mathbf{\epsilon}_{t-1}$, 但在Reverse Process中$\mathbf{\epsilon}_{t-1}$ 在$t$ 时刻是未知的, 所以需要把$\mathbf{\epsilon}_{t-1}$ 用网络$\mathbf{\epsilon}_\theta\left(\mathbf{x}_t, T\right)$ 预测出来.</p><p>如果取$T=1000$, 那训练的时候就要把训练集里面每个样本训练1000次? 显然不科学.</p><p>在Forward Process中我们知道$q\left(\mathbf{x}_t \mid \mathbf{x}_{t-1}\right)=\mathcal{N}\left(\mathbf{x}_t ; \sqrt{1-\beta_t} \mathbf{x}_{t-1}, \beta_t \mathbf{I}\right)$, 利用贝叶斯公式可以尝试推出$q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$:</p><p>$$<br>q(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \frac{q(\mathbf{x}_{t} \mid \mathbf{x}_{t-1}) \cdot q(\mathbf{x}_{t-1} \mid \mathbf{x}_0)}{q(\mathbf{x}_t \mid \mathbf{x}_0)}<br>$$</p><p>这里用到了一阶马尔科夫链的性质, $\mathbf{x}_0$ 与$\mathbf{x}_{t-1}$, $\mathbf{x}_t$ 都是独立的, 是否作为条件都不影响概率.</p><p>$q\left(\mathbf{x}_t \mid \mathbf{x}_{t-1}\right)$ 是我们定义的, $q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)$ 咱们前面也递推出来了, 下面就把正态分布带进去搞$q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$:</p><p>$$<br>\begin{aligned}<br>q(\mathbf{x}_{t-1}|\mathbf{x}_t) &amp;= \frac{q(\mathbf{x}_t | \mathbf{x}_{t-1}, \mathbf{x}_0)q(\mathbf{x}_{t-1}|\mathbf{x}_0)}{q(\mathbf{x}_{t}|\mathbf{x}_0)}\\<br>&amp;= \frac{\mathcal{N}(\mathbf{x}_{t} ; \sqrt{\alpha_t} \mathbf{x}_{t-1}, (1 - \alpha_t)\textbf{I})\mathcal{N}(\mathbf{x}_{t-1} ; \sqrt{\bar\alpha_{t-1}}\mathbf{x}_0, (1 - \bar\alpha_{t-1}) \textbf{I})}{\mathcal{N}(\mathbf{x}_{t} ; \sqrt{\bar\alpha_{t}}\mathbf{x}_0, (1 - \bar\alpha_{t})\textbf{I})}\\<br>&amp;\propto \text{exp}\left\{-\left[\frac{(\mathbf{x}_{t} - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{2(1 - \alpha_t)} + \frac{(\mathbf{x}_{t-1} - \sqrt{\bar\alpha_{t-1}} \mathbf{x}_0)^2}{2(1 - \bar\alpha_{t-1})} - \frac{(\mathbf{x}_{t} - \sqrt{\bar\alpha_t} \mathbf{x}_{0})^2}{2(1 - \bar\alpha_t)} \right]\right\}\\<br>&amp;= \text{exp}\left\{-\frac{1}{2}\left[\frac{(\mathbf{x}_{t} - \sqrt{\alpha_t} \mathbf{x}_{t-1})^2}{1 - \alpha_t} + \frac{(\mathbf{x}_{t-1} - \sqrt{\bar\alpha_{t-1}} \mathbf{x}_0)^2}{1 - \bar\alpha_{t-1}} - \frac{(\mathbf{x}_{t} - \sqrt{\bar\alpha_t} \mathbf{x}_{0})^2}{1 - \bar\alpha_t} \right]\right\}\\<br>&amp;= \text{exp}\left\{-\frac{1}{2}\left[\frac{(-2\sqrt{\alpha_t} \mathbf{x}_{t}\mathbf{x}_{t-1} + \alpha_t \mathbf{x}_{t-1}^2)}{1 - \alpha_t} + \frac{(\mathbf{x}_{t-1}^2 - 2\sqrt{\bar\alpha_{t-1}}\mathbf{x}_{t-1} \mathbf{x}_0)}{1 - \bar\alpha_{t-1}} + C(\mathbf{x}_t, \mathbf{x}_0)\right]\right\} \\<br>&amp;\propto \text{exp}\left\{-\frac{1}{2}\left[- \frac{2\sqrt{\alpha_t} \mathbf{x}_{t}\mathbf{x}_{t-1}}{1 - \alpha_t} + \frac{\alpha_t \mathbf{x}_{t-1}^2}{1 - \alpha_t} + \frac{\mathbf{x}_{t-1}^2}{1 - \bar\alpha_{t-1}} - \frac{2\sqrt{\bar\alpha_{t-1}}\mathbf{x}_{t-1} \mathbf{x}_0}{1 - \bar\alpha_{t-1}}\right]\right\}\\<br>&amp;= \text{exp}\left\{-\frac{1}{2}\left[(\frac{\alpha_t}{1 - \alpha_t} + \frac{1}{1 - \bar\alpha_{t-1}})\mathbf{x}_{t-1}^2 - 2\left(\frac{\sqrt{\alpha_t}\mathbf{x}_{t}}{1 - \alpha_t} + \frac{\sqrt{\bar\alpha_{t-1}}\mathbf{x}_0}{1 - \bar\alpha_{t-1}}\right)\mathbf{x}_{t-1}\right]\right\}\\<br>&amp;= \text{exp}\left\{-\frac{1}{2}\left[\frac{\alpha_t(1-\bar\alpha_{t-1}) + 1 - \alpha_t}{(1 - \alpha_t)(1 - \bar\alpha_{t-1})}\mathbf{x}_{t-1}^2 - 2\left(\frac{\sqrt{\alpha_t}\mathbf{x}_{t}}{1 - \alpha_t} + \frac{\sqrt{\bar\alpha_{t-1}}\mathbf{x}_0}{1 - \bar\alpha_{t-1}}\right)\mathbf{x}_{t-1}\right]\right\}\\<br>&amp;= \text{exp}\left\{-\frac{1}{2}\left[\frac{\alpha_t-\bar\alpha_{t} + 1 - \alpha_t}{(1 - \alpha_t)(1 - \bar\alpha_{t-1})}\mathbf{x}_{t-1}^2 - 2\left(\frac{\sqrt{\alpha_t}\mathbf{x}_{t}}{1 - \alpha_t} + \frac{\sqrt{\bar\alpha_{t-1}}\mathbf{x}_0}{1 - \bar\alpha_{t-1}}\right)\mathbf{x}_{t-1}\right]\right\}\\<br>&amp;= \text{exp}\left\{-\frac{1}{2}\left[\frac{1 -\bar\alpha_{t}}{(1 - \alpha_t)(1 - \bar\alpha_{t-1})}\mathbf{x}_{t-1}^2 - 2\left(\frac{\sqrt{\alpha_t}\mathbf{x}_{t}}{1 - \alpha_t} + \frac{\sqrt{\bar\alpha_{t-1}}\mathbf{x}_0}{1 - \bar\alpha_{t-1}}\right)\mathbf{x}_{t-1}\right]\right\}\\<br>&amp;= \text{exp}\left\{-\frac{1}{2}\left(\frac{1 -\bar\alpha_{t}}{(1 - \alpha_t)(1 - \bar\alpha_{t-1})}\right)\left[\mathbf{x}_{t-1}^2 - 2\frac{\left(\frac{\sqrt{\alpha_t}\mathbf{x}_{t}}{1 - \alpha_t} + \frac{\sqrt{\bar\alpha_{t-1}}\mathbf{x}_0}{1 - \bar\alpha_{t-1}}\right)}{\frac{1 -\bar\alpha_{t}}{(1 - \alpha_t)(1 - \bar\alpha_{t-1})}}\mathbf{x}_{t-1}\right]\right\}\\<br>&amp;= \text{exp}\left\{-\frac{1}{2}\left(\frac{1 -\bar\alpha_{t}}{(1 - \alpha_t)(1 - \bar\alpha_{t-1})}\right)\left[\mathbf{x}_{t-1}^2 - 2\frac{\left(\frac{\sqrt{\alpha_t}\mathbf{x}_{t}}{1 - \alpha_t} + \frac{\sqrt{\bar\alpha_{t-1}}\mathbf{x}_0}{1 - \bar\alpha_{t-1}}\right)(1 - \alpha_t)(1 - \bar\alpha_{t-1})}{1 -\bar\alpha_{t}}\mathbf{x}_{t-1}\right]\right\}\\<br>&amp;= \text{exp}\left\{-\frac{1}{2}\left(\frac{1}{\frac{(1 - \alpha_t)(1 - \bar\alpha_{t-1})}{1 -\bar\alpha_{t}}}\right)\left[\mathbf{x}_{t-1}^2 - 2\frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})\mathbf{x}_{t} + \sqrt{\bar\alpha_{t-1}}(1-\alpha_t)\mathbf{x}_0}{1 -\bar\alpha_{t}}\mathbf{x}_{t-1}\right]\right\}\\<br>&amp;\propto \mathcal{N}(\mathbf{x}_{t-1} ; \underbrace{\frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})\mathbf{x}_{t} + \sqrt{\bar\alpha_{t-1}}(1-\alpha_t)\mathbf{x}_0}{1 -\bar\alpha_{t}}}_{\tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right)}, \underbrace{\frac{(1 - \alpha_t)(1 - \bar\alpha_{t-1})}{1 -\bar\alpha_{t}}\textbf{I}}_{\mathbf{\sigma}^2_q(t)})<br>\end{aligned}<br>$$</p><p>好, 不管你有没有看完上面那坨推导, 历经千难万险, 得到最终形式:</p><p>$$<br>\begin{aligned}<br>q(\mathbf{x}_{t-1} \mid \mathbf{x}_t) &amp;= \mathcal{N}(\mathbf{x}_{t-1}; \tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right), \mathbf{\sigma}^2_q(t)) \\<br>\tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right) &amp;= \frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})}{1 -\bar\alpha_{t}}\mathbf{x}_{t} + \frac{\sqrt{\bar\alpha_{t-1}}(1-\alpha_t)}{1 -\bar\alpha_{t}}\mathbf{x}_0 \\<br>&amp;= \frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})}{1 -\bar\alpha_{t}}\mathbf{x}_{t} + \frac{\sqrt{\bar\alpha_{t-1}}\beta_t}{1 -\bar\alpha_{t}}\mathbf{x}_0 \\<br>\mathbf{\sigma}^2_q(t) &amp;= \frac{(1 - \alpha_t)(1 - \bar\alpha_{t-1})}{1 -\bar\alpha_{t}}\textbf{I} \\<br>&amp;= \frac{(1 - \bar\alpha_{t-1})\beta_t}{1 -\bar\alpha_{t}}\textbf{I}=\tilde{\beta}_t\textbf{I}<br>\end{aligned}<br>$$</p><p>我们发现$q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 也是一个正态分布, 而且它的均值和方差均可以通过$\mathbf{x}_0, \alpha_t, \beta_t$ 得到.</p><p>观察到$\tilde{\boldsymbol{\mu}}_t$ 中仍有$\mathbf{x}_0$, 将$\mathbf{x}_0 = \frac{\mathbf{x}_t}{\sqrt{\bar{\alpha_t}}} - \sqrt{\frac{1-\bar{\alpha}}{\bar{\alpha}}}\mathbf{\epsilon}_\theta\left(\mathbf{x}_t, t\right)$ 代入到$\tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \mathbf{x}_0\right)$ 中消去$\mathbf{x}_0$, 可以得到:</p><p>$$<br>\begin{aligned}<br>\boldsymbol{\mu}_\theta\left(\mathbf{x}_t, t\right) &amp;= \tilde{\boldsymbol{\mu}}_t\left(\mathbf{x}_t, \frac{1}{\sqrt{\bar{\alpha}_t}}\left(\mathbf{x}_t - \sqrt{1 - \bar{\alpha}_t}\mathbf{\epsilon}_\theta(\mathbf{x}_t, t)\right) \right) \\<br>&amp;= \frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})\mathbf{x}_{t} + \sqrt{\bar\alpha_{t-1}}(1-\alpha_t)\mathbf{x}_0}{1 -\bar\alpha_{t}}\\<br>&amp;= \frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})\mathbf{x}_{t} + \sqrt{\bar\alpha_{t-1}}(1-\alpha_t)\frac{\mathbf{x}_t - \sqrt{1 - \bar\alpha_t}\mathbf{\epsilon}_\theta(\mathbf{x}_t, t)}{\sqrt{\bar\alpha_t}}}{1 -\bar\alpha_{t}}\\<br>&amp;= \frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})\mathbf{x}_{t} + (1-\alpha_t)\frac{\mathbf{x}_t - \sqrt{1 - \bar\alpha_t}\mathbf{\epsilon}_\theta(\mathbf{x}_t, t)}{\sqrt{\alpha_t}}}{1 -\bar\alpha_{t}}\\<br>&amp;= \frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})\mathbf{x}_{t}}{1 - \bar\alpha_t} + \frac{(1-\alpha_t)\mathbf{x}_t}{(1-\bar\alpha_t)\sqrt{\alpha_t}} - \frac{(1 - \alpha_t)\sqrt{1 - \bar\alpha_t}\mathbf{\epsilon}_\theta(\mathbf{x}_t, t)}{(1-\bar\alpha_t)\sqrt{\alpha_t}}\\<br>&amp;= \left(\frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})}{1 - \bar\alpha_t} + \frac{1-\alpha_t}{(1-\bar\alpha_t)\sqrt{\alpha_t}}\right)\mathbf{x}_t - \frac{(1 - \alpha_t)\sqrt{1 - \bar\alpha_t}}{(1-\bar\alpha_t)\sqrt{\alpha_t}}\mathbf{\epsilon}_\theta(\mathbf{x}_t, t)\\<br>&amp;= \left(\frac{\alpha_t(1-\bar\alpha_{t-1})}{(1 - \bar\alpha_t)\sqrt{\alpha_t}} + \frac{1-\alpha_t}{(1-\bar\alpha_t)\sqrt{\alpha_t}}\right)\mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar\alpha_t}\sqrt{\alpha_t}}\mathbf{\epsilon}_\theta(\mathbf{x}_t, t)\\<br>&amp;= \frac{\alpha_t-\bar\alpha_{t} + 1-\alpha_t}{(1 - \bar\alpha_t)\sqrt{\alpha_t}}\mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar\alpha_t}\sqrt{\alpha_t}}\mathbf{\epsilon}_\theta(\mathbf{x}_t, t)\\<br>&amp;= \frac{1-\bar\alpha_t}{(1 - \bar\alpha_t)\sqrt{\alpha_t}}\mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar\alpha_t}\sqrt{\alpha_t}}\mathbf{\epsilon}_\theta(\mathbf{x}_t, t)\\<br>&amp;= \frac{1}{\sqrt{\alpha_t}}\mathbf{x}_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar\alpha_t}\sqrt{\alpha_t}}\mathbf{\epsilon}_\theta(\mathbf{x}_t, t)\\<br>&amp;=\frac{1}{\sqrt{\alpha_t}} \left(\mathbf{x}_t - \frac{\beta}{\sqrt{1-\bar\alpha_t}} \mathbf{\epsilon}_\theta(\mathbf{x}_t, t)\right)<br>\end{aligned}<br>$$</p><p>所以!!! 我们终于完成了从$\mathbf{x}_{t}$ 得到$\mathbf{x}_{t-1}$ 后验分布$q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 的构建:</p><p>$$<br>q(\mathbf{x}_{t-1} \mid \mathbf{x}_t) = \mathcal{N}\left(\mathbf{x}_{t-1}; \frac{1}{\sqrt{\alpha_t}} \left(\mathbf{x}_t - \frac{\beta}{\sqrt{1-\bar\alpha_t}} \mathbf{\epsilon}_\theta(\mathbf{x}_t, t)\right), \frac{(1 - \bar\alpha_{t-1})\beta_t}{1 -\bar\alpha_{t}}\textbf{I}\right)<br>$$</p><h2 id="Training-amp-Sampling"><a href="#Training-amp-Sampling" class="headerlink" title="Training &amp; Sampling"></a>Training &amp; Sampling</h2><p>其实训练的过程在上面的Forward和Reverse Process已经说过了. 直觉上用MSE Loss来模型去噪的功能就行了:</p><p>$$<br>L(\theta)=\mathbb{E}_{t, \mathbf{x}_0, \boldsymbol{\epsilon}}\left[\left|\left|\boldsymbol{\epsilon}-\boldsymbol{\epsilon}_\theta\left(\sqrt{\bar{\alpha}_t} \mathbf{x}_0+\sqrt{1-\bar{\alpha}_t} \boldsymbol{\epsilon}, t\right)\right|\right|^2\right]<br>$$</p><blockquote><p>真有直觉这么简单吗? 其实省略了很多Diffusion Model的理论推导, 本文在此不加叙述, 但在文末给出参考链接.</p></blockquote><p>在推理时, 注意! 由于$q(\mathbf{x}_{t-1} \mid \mathbf{x}_t)$ 仍然是概率分布, 所以$\mathbf{x}_{t-1}$ 映射到$\mathbf{x}_t$ 仍然是一个不确定的过程, 这里用<strong>重采样</strong>写出$\mathbf{x}_{t-1}$ 与$\mathbf{x}_t$ 的确定性关系:</p><p>$$<br>\mathbf{x}_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left(\mathbf{x}_t - \frac{\beta}{\sqrt{1-\bar\alpha_t}} \mathbf{\epsilon}_\theta(\mathbf{x}_t, t)\right) + \sigma_t \mathbf{z}<br>$$</p><p>$\mathbf{z}$ 从正态分布中采样得到.</p><p>对应的Training和Sampling(Inference)伪代码如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ddpm3.png" style="zoom:50%"><p>训练时, 对图像加噪, 并用MSE最小化添加的噪声与网络预测出的噪声之间的差距. 推理时, 先从标准正态分布中采样一个高斯噪声$\mathbf{x}_T$ , 再用模型逐步去噪直到得到$\mathbf{x}_0$.</p><p>推理时注意一个小细节, 在由$\mathbf{x}_1$ 得到$\mathbf{x}_0$ 时不加入方差, 因为已经到生成的最后一步了.</p><blockquote><p>不难发现, 需要采样的东西还挺多的. $t$ 是采样的来的, $\mathbf{\epsilon}$ 也是采样得到的, $\mathbf{x}_0$ 也是采样的, 这也就是为什么前面我们想通过$\mathbf{x}_t$ 一步到$\mathbf{x}_0$ 不太现实. 引入的随机性越大, 模型也就越容易在看不清方向的学习过程中迷惑, 导致收敛慢.</p></blockquote><p>其余的一些细节, $T$ 在原论文中取1000, $\beta_1$ 从1e-4线性增加到$\beta_T$ 2e-2, 即越往后添加的噪声扰动强度越大, 模型选的是带有Self Attention的U - Net.</p><h2 id="Recommended-Reference"><a href="#Recommended-Reference" class="headerlink" title="Recommended / Reference"></a>Recommended / Reference</h2><p>看完本文, 相信你还有很多疑问, 不过这也意味着你可能发现了一些问题:</p><ul><li>Q: 这玩意推理采样太慢是不是没什么应用价值?<br>A: 请看DDIM: <a href="https://arxiv.org/abs/2010.02502" target="_blank" rel="noopener">Denoising Diffusion Implicit Models</a>.</li><li>Q: 如果直接对图像加噪的话在生成高清图片时候是不是会因为计算量和计算时间直接裂开?<br>A: 请看LDM(Latent Diffusion Model, 对就是<strong>Stable Diffusion</strong>): <a href="http://arxiv.org/abs/2112.10752" target="_blank" rel="noopener">High-Resolution Image Synthesis with Latent Diffusion Models</a>.</li><li>Q: 生成时候要是能附加条件就好了.<br>A: 请看同上个问题的论文.</li><li>Q: 为啥非得预测噪声呢? 我要是直接预测原图行不行啊?<br>A: 请看DDPM的前身, 早在2015年的ICML就已经提出了真正意义上的Diffusion Model, 但是当时不太Work: <a href="https://arxiv.org/abs/1503.03585" target="_blank" rel="noopener">Deep Unsupervised Learning using Nonequilibrium Thermodynamics</a>.</li></ul><p>在此, 同时给出其他本文写作中参考的文章和推荐阅读内容:</p><ul><li>苏神系列文章: <a href="https://kexue.fm/archives/9119" target="_blank" rel="noopener">生成扩散模型漫谈（一）：DDPM = 拆楼 + 建楼 - 科学空间|Scientific Spaces</a>.</li><li>李宏毅教程: <a href="https://www.bilibili.com/video/BV14c411J7f2" target="_blank" rel="noopener">扩散模型 - Diffusion Model【李宏毅2023】</a>.</li><li>推导看这里: <a href="https://arxiv.org/abs/2208.11970" target="_blank" rel="noopener">Understanding Diffusion Models: A Unified Perspective</a>.</li><li>DDPM原论文: <a href="https://arxiv.org/abs/2006.11239" target="_blank" rel="noopener">Denoising Diffusion Probabilistic Models</a>.</li><li><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/" target="_blank" rel="noopener">What are Diffusion Models? | Lil’Log</a>.</li><li><a href="https://zhuanlan.zhihu.com/p/652814515" target="_blank" rel="noopener">Denoising Diffusion Probabilistic Models (DDPM) - 妖妖的文章 - 知乎</a>.</li></ul></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/58818.html">https://ADAning.github.io/posts/58818.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/DDPM/"><span class="chip bg-color">DDPM</span> </a><a href="/tags/Diffusion/"><span class="chip bg-color">Diffusion</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/8589.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/18.jpg" class="responsive-img" alt="DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism"> <span class="card-title">DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: DDPM: Denoising Diffusion Probabilistic Model. DiffSinger: Singing Voice Synthesis via Shallow Diffusion Me</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-10-18 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/DDPM/"><span class="chip bg-color">DDPM</span> </a><a href="/tags/Diffusion/"><span class="chip bg-color">Diffusion</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/62916.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/11.jpg" class="responsive-img" alt="Pytorch实现: VQ-VAE"> <span class="card-title">Pytorch实现: VQ-VAE</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: VQ基本知识: Introduction: Vector Quantization Vector Quantization. Pytorch实现: VQ - VAE本文是VQ - VAE的Pytorch版本实现, 并</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-07-28 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> DaNing</span></div></div><div class="card-action article-tags"><a href="/tags/VQ-VAE/"><span class="chip bg-color">VQ-VAE</span> </a><a href="/tags/Pytorch/"><span class="chip bg-color">Pytorch</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">390.5k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>