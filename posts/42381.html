<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="RFBFN: A Relation - First Blank Filling Network for Joint Relational Triple Extraction, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>RFBFN: A Relation - First Blank Filling Network for Joint Relational Triple Extraction | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/16.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">RFBFN: A Relation - First Blank Filling Network for Joint Relational Triple Extraction</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-07-09</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-07-09</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3.2k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 13 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li><strong>SPN</strong>: <a href="https://adaning.github.io/posts/50175.html">SPN: Joint Entity and Relation Extraction with Set Prediction Networks</a>.</li></ul></blockquote><h1 id="RFBFN-A-Relation-First-Blank-Filling-Network-for-Joint-Relational-Triple-Extraction"><a href="#RFBFN-A-Relation-First-Blank-Filling-Network-for-Joint-Relational-Triple-Extraction" class="headerlink" title="RFBFN: A Relation - First Blank Filling Network for Joint Relational Triple Extraction"></a>RFBFN: A Relation - First Blank Filling Network for Joint Relational Triple Extraction</h1><p>本文是论文<a href="https://aclanthology.org/2022.acl-srw.2" target="_blank" rel="noopener">RFBFN: A Relation-First Blank Filling Network for Joint Relational Triple Extraction</a>的阅读笔记和个人理解, 论文来自<strong>ACL 2022</strong>.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>现有的RTE工作要么忽略了关系的<strong>语义信息</strong>, 要么抽取<strong>Subject</strong>和<strong>Object</strong>带有<strong>先后顺序</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn1.png" style="zoom:25%"><p>针对上述两点, 作者希望提出一种兼顾关系间语义信息, 且不带有Subject和Object的预测顺序的模型.</p><h2 id="RFBFN"><a href="#RFBFN" class="headerlink" title="RFBFN"></a>RFBFN</h2><h3 id="Task-Definition"><a href="#Task-Definition" class="headerlink" title="Task Definition"></a>Task Definition</h3><p>输入一个包含<code>[CLS]</code> Token $x_{cls}$ 在内有$n$ 个Token的句子$X=(x_1, x_2, \dots, x_n)$, 任务目标为抽取出句子中所有可能的三元组$T(X) = (e_i, r_{ij}, e_j)$, $e_i, e_j$ 分别为代表Subject和Object的Token, $r_{ij} \in \mathcal{R}$ 为二者间的关系, $\mathcal{R}$ 为预先定义好的关系集.</p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>按序分为三部分:</p><ol><li><strong>Span - Level Encoder</strong>: 从输入文本中抽取出<strong>Span表示</strong>.</li><li><strong>Relation Detection Module</strong>: 预测句子中的<strong>潜在关系</strong>, 并过滤掉不相关的关系.</li><li><strong>Blank Filling Module</strong>: 用很多指明关系的模板作为输入, 预测该关系下对应的<strong>实体对</strong>.</li></ol><p>将关系抽取任务建模为<strong>完形填空</strong>任务, 可以兼顾考虑关系的<strong>语义信息</strong>, <strong>同时</strong>抽取出<strong>Subject</strong>和<strong>Object</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn2.png" style="zoom:28%"><p>模型概览图如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn3.png" style="zoom:29%"><h3 id="Span-Level-Encoder"><a href="#Span-Level-Encoder" class="headerlink" title="Span - Level Encoder"></a>Span - Level Encoder</h3><p>Span - Level Encoder通过BERT来抽取句子中的Span表示. 令$S=(s_1, s_2, \dots, s_{n_s})$ 为输入句子$X$ 中的所有Span, 则对于Span $s_i \in S$, 其表示$\mathbf{h}_i^e$ 定义为:</p><p>$$<br>\mathbf{h}_{\mathrm{i}}^{\mathrm{e}}=\left[\mathbf{x}_{\mathrm{START}(\mathrm{i})}^{\mathrm{e}} ; \mathbf{x}_{\operatorname{END}(\mathrm{i})}^{\mathrm{e}} ; \phi\left(\mathbf{x}_{\mathrm{i}}\right)\right]<br>$$</p><p>其中$\mathbf{x}_{\text{START(i)}}^e, \mathbf{x}_{\text{END(i)}}^e$ 为上下文感知的边界Token, $\phi(\mathbf{x}_i)$ 为跟Span长度相关的Embedding. 记Encoder输出的所有Span表示为$\mathbf{H}^e \in \mathbb{R}^{n_s \times d}$, $d$ 为Embedding维度.</p><p>然后分别将$\mathbf{H}^e$ 通过两个不同的FFN获得Span中的关系表示$\mathbf{H}_{\mathrm{e}}^{\mathrm{rel}}$ 和实体表示$\mathbf{H}_{\mathrm{e}}^{\mathrm{ent}}$:</p><p>$$<br>\begin{aligned}<br>&amp;\mathbf{H}_{\mathrm{e}}^{\mathrm{rel}}=\mathbf{W}_{r e l} \mathbf{H}^{e}+\mathbf{b}_{r e l} \\<br>&amp;\mathbf{H}_{\mathrm{e}}^{\mathrm{ent}}=\mathbf{W}_{e n t} \mathbf{H}^{e}+\mathbf{b}_{e n t}<br>\end{aligned}<br>$$</p><p>其中, $\mathbf{W}_{rel}, \mathbf{W}_{ent} \in \mathbb{R} ^{d \times d}, \mathbf{b}_{rel}, \mathbf{b}_{ent} \in \mathbb{R}^d$ 均为可学习参数.</p><h3 id="Relation-Detection-Module"><a href="#Relation-Detection-Module" class="headerlink" title="Relation Detection Module"></a>Relation Detection Module</h3><p>与之前大多数对关系的处理方式不同, 之前大多同时考虑所有关系, 引入了相当多的冗余计算.</p><p>作者先抽取句子中关系的候选集, 然后在这些候选关系的基础上再做Subject和Object的预测.</p><p>与<a href="https://adaning.github.io/posts/50175.html">SPN</a>类似的, RFBFN使用<strong>Non - Autoregressive Decoder</strong>(<strong>NAD</strong>)并将关系作为二元分类问题抽取出来.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn4.png" style="zoom:65%"><h4 id="Potential-Relation-Extractor"><a href="#Potential-Relation-Extractor" class="headerlink" title="Potential Relation Extractor"></a>Potential Relation Extractor</h4><p>具体的, NAD被输入多个可学习的Query Embedding $\mathbf{Q} \in \mathbb{R}^{\mathrm{n}_q \times d}$, 其中$n_q$ 为句子中最大可能的关系数量. NAD涉及到的信息流如节初图所示.</p><p>用先前计算好的关系侧Span表示$\mathbf{H}^{\text{rel}}_{\text{e}}$ 作为NAD的输入, NAD的输出为$\mathbf{H}^{\mathrm{r}} \in \mathbb{R}^{\mathrm{n_q} \times \mathrm d}$. 第$i$ 个输出$\mathbf{h}_{\mathrm{i}}^{\mathrm{r}}$ 所对应的关系类型概率$\mathbf{p}_{\mathrm{i}}^{\mathrm{r}}$ 由线性层后Softmax得到:</p><p>$$<br>\mathbf{p}_{\mathrm{i}}^{\mathrm{r}}=\operatorname{Softmax}\left(\mathbf{W}_{\mathrm{r}} \mathbf{h}_{\mathrm{i}}^{\mathrm{r}}+\mathbf{b}_{\mathrm{r}}\right)<br>$$</p><p>其中$\mathbf{W}_r \in \mathbb{R}^{|\mathcal{R}| \times d}, \mathbf{b}_r \in \mathbf{R}^{|\mathcal{R}|}$ 为可学习参数, $|\mathcal{R}|$ 为关系类型的总数. 因为存在Decoder输出的先后顺序问题, 和SPN一样的使用了<strong>二部图匹配</strong>损失.</p><h4 id="Candidate-Relation-Judgement"><a href="#Candidate-Relation-Judgement" class="headerlink" title="Candidate Relation Judgement"></a>Candidate Relation Judgement</h4><p>在预测完句子中潜在的关系子集后, 需要<strong>过滤掉无关关系</strong>以有效生成模板.</p><p>Candidate Relation Judgement以NAD的输出表征$\mathbf{H}^\mathrm{r}$ 和<code>[CLS]</code> 的Embedding作为输入, 以一个Mask向量$\mathbf{M}$ (其中的值都是布尔值)作为输出, 以确定该类型关系是否在该句子中成立:</p><p>$$<br>\mathbf{M}=\sigma\left(\mathbf{W}_{\mathrm{s}}\left[\mathbf{H}^{\mathrm{r}} ; \mathbf{x}_{\mathrm{cls}}^{\mathrm{e}}\right]+\mathbf{b}_{\mathrm{s}}\right)<br>$$</p><p>其中$\mathbf{W}_s, \mathbf{b}_s$ 为可学习参数, $\sigma$ 为Sigmoid激活函数. $\mathbf{M}$ 中的值越大, 该句子中包含该关系的置信度就越大.</p><blockquote><p>在Potential Relation Extractor中, 由于使用的是Softmax, 所以每个Query Embedding一定都有一个对应的关系, 但对于这个句子并不一定真的成立, Candidate Relation Judgement的作用就是判断每个关系是否在该句子中成立.</p></blockquote><h3 id="Blank-Filling-Module"><a href="#Blank-Filling-Module" class="headerlink" title="Blank Filling Module"></a>Blank Filling Module</h3><p>实体对抽取被作者建模为识别上下文中的Span并填入模板的空中. 作者为每个候选关系类型建立待填充的模板(缺失处用<code>[MASK]</code>表示), 当实体被识别时需要填入Subject和Object的对应槽位.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn5.png" style="zoom:67%"><h4 id="Relation-Template-Generation"><a href="#Relation-Template-Generation" class="headerlink" title="Relation Template Generation"></a>Relation Template Generation</h4><p>每种关系的模板由关系的<strong>语义信息</strong>和Subject, Object<strong>槽位</strong>组成.</p><p>例如关系<code>leaderName</code> 对应着模板<code>[MASK] is the leader of [MASK]</code>. 作者认为该关系模板蕴含着关系的语义信息, 对RTE很重要, 具体模板的构成形式如下:</p><p>$$<br>T_{r}=\left(m_{1}^{r}, t_{1}^{r}, t_{2}^{r}, \ldots, t_{n_{t}}^{r}, m_{2}^{r}\right)<br>$$</p><p>其中$m_1^r$ 代表Subject的空槽, $m_2^r$ 代表Object的空槽, $t_1^r, t_2^r, \dots, t_{n_t}^r$ 为关系$r$ 的Token. 每种关系模板被<strong>复制</strong>$k$ 次, 之间用<code>[SEP]</code> 拼接. 其中$k$ 比句子中预设好的三元组数量稍微大一点的数, 这样能抽取出同种关系下的多个实体对.</p><blockquote><p>将Relation Template复制多次和多个Query Embedding从形式上来说是一样的.</p></blockquote><h4 id="Entity-Pair-Extractor"><a href="#Entity-Pair-Extractor" class="headerlink" title="Entity Pair Extractor"></a>Entity Pair Extractor</h4><p>对于给定的关系模板和Span表示$\bar{\mathbf{H}}=\left[\mathbf{H}_{\text{e}}^{\text{ent}} ; \mathbf{x}^{\text{e}}_{\text{cls}}\right]$, Entity Pair Extractor的作用在于抽取模板中对应的实体对. 作者同样使用和关系抽取时一样的<strong>NAD</strong>作为特征抽取器. NAD涉及到的信息流如节初图所示.</p><p>在每层Transformer Decoder Layer中, 多头自注意力建模了<strong>空槽</strong>和<strong>语义</strong>关系的关联, 多头跨注意力建立了<strong>Span信息</strong>和<strong>模板</strong>之间的关联.</p><p>经过NAD处理后, 空槽表示为$\mathbf{H}_{\text{r}}^{\text{blk}} \in \mathbb{R} ^ {2\text{k} \times \text{d}}$, Span对每种关系$r$ 下的第$i$ 个槽位的表示由下式获得:</p><p>$$<br>\mathbf{h}_{\mathrm{i}, \mathrm{r}}^{\mathrm{b}}=\tanh \left(\mathbf{W}_{\mathrm{b}}^{1} \bar{\mathbf{H}}+\mathbf{W}_{\mathrm{b}}^{2} \mathbf{h}_{\mathrm{i}, \mathrm{r}}^{\mathrm{blk}}+\mathbf{b}_{\mathrm{b}}\right)<br>$$</p><p>其中$\mathbf{W}_\text{b}^1, \mathbf{W}_\text{b}^2 \in \mathbb{R} ^{\text{d} \times \text{d}}, \mathbf{b}_{\text b} \in \mathbb{R} ^ \text b$ 为可学习参数. 对于多余出来的不需要填入实体的槽位, 答案被设置为<code>[CLS]</code>.</p><p>最后用Softmax来获得句子中应该填入槽位的实体的概率:<br>$$<br>\mathbf{p}_{\mathrm{i}, \mathrm{r}}^{\mathrm{b}}=\operatorname{Softmax}\left(\mathbf{u}_{\mathrm{b}}^{\mathrm{T}} \cdot \mathbf{h}_{\mathrm{i}, \mathrm{r}}^{\mathrm{b}}\right)<br>$$<br>其中$\mathbf{u}_b \in \mathbb{R}^d$ 为可学习参数, 作者使用基于Span的方法抽取实体对, 所以实体可以在不使用指针网络或序列标注时被同时抽取.</p><blockquote><p>其实本质仍然是指针网络, 只不过从Token Level换成了Span Level.</p></blockquote><h3 id="Joint-Training"><a href="#Joint-Training" class="headerlink" title="Joint Training"></a>Joint Training</h3><p>作者的模型分为<strong>关系检测</strong>和<strong>实体对抽取</strong>两个任务. 作者以多任务学习联合训练该模型, 即<strong>共享Encoder</strong>.</p><p>预测实体对时, 作者根据实体在文本中的出现的顺序排序, 然后用交叉熵计算实体对抽取的损失:</p><p>$$<br>\mathcal{L}_{e n t}=-\sum_{r=1}^{n_{d}} \sum_{i=1}^{2 k} \log \mathbf{p}_{\mathrm{i}, \mathrm{r}}^{\mathrm{b}}\left(\mathrm{y}_{\mathrm{i}, \mathrm{r}}^{\mathrm{b}}\right)<br>$$</p><p>其中$\mathrm{y}^{\mathrm{b}}_{\mathrm{i,r}}$ 为实体Span的Ground Truth, $n_d$ 为检测到的关系数.</p><p>但是对于关系就不一样了, 同样由于使用NAD, 在句子中检测出的关系是不应该具有顺序特性的, 所以使用与SPN相同的<strong>二部图匹配损失</strong>, 穷举出所有预测出的关系顺序, 找到一种与Ground Truth相匹配的最小Cost顺序$\pi^\ast$:<br>$$<br>\pi^{\ast}=\underset{\pi \in \Pi\left(\mathrm{n}_{\mathrm{q}}\right)}{\operatorname{argmin}}\left(-\sum_{\mathrm{i}=1}^{\mathrm{I}_{\mathrm{q}}} \mathrm{I}\left(\mathrm{y}_{\mathrm{i}}^{\mathrm{r}}\right) \cdot \mathbf{p}_{\pi(\mathrm{i})}^{\mathrm{r}}\left(\mathrm{y}_{\mathrm{i}}^{\mathrm{r}}\right)\right)<br>$$</p><p>其中$\Pi\left(\mathrm{n}_{\mathrm{q}}\right)$ 为全排列策略空间, $\mathrm{y}_\mathrm{i}^\mathrm r$ 为关系的Ground Truth, $I(y_r^i)$ 为指示函数, 若$\mathrm{y_i^r} \neq \varnothing, \mathrm{I(y_i^r)}=1$, 否则为0. 关系侧的Loss定义为最优排序下的交叉熵:<br>$$<br>\mathcal{L}_{r e l}=-\sum_{\mathrm{i}=1}^{\mathrm{n}_{\mathrm{q}}} \log \mathbf{p}_{\pi^{*}(\mathrm{i})}^{\mathrm{r}}\left(\mathrm{y}_{\mathrm{i}}^{\mathrm{r}}\right)<br>$$</p><blockquote><p>二部图匹配损失详见<a href="https://adaning.github.io/posts/50175.html#toc-heading-8">SPN</a>.</p></blockquote><p>最后对两个任务的Loss做个加权:<br>$$<br>\mathcal{L}=\lambda \mathcal{L}_{e n t}+(1-\lambda) \mathcal{L}_{r e l}<br>$$</p><p>实验中作者将$\lambda$ 设为0.5, 即视两个任务同等重要, 且二者学习难度相同.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的实验参数请参照原论文.</p><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>作者选用两个常用数据集NYT和WebNLG的精准匹配和部分匹配版本做为实验数据集, 统计数据如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn6.png" style="zoom:33%"><h3 id="Main-Results"><a href="#Main-Results" class="headerlink" title="Main Results"></a>Main Results</h3><p>在上述数据集上主要实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn7.png" style="zoom:40%"><p>看起来RFBFN的Precision和Recall都比其他模型更要均衡一些, 所以相对应的F1也偏高一点.</p><p>在不用预训练模型的时候比PRGC结果要好, 主要的提升来自于Recall, 我认为主要原因其一是RFBFN采用了Span Level的方式而非PRGC中Token Level的方式抽取实体, 可能会有一些提升, 再者是Fill in the Blanks的方式可能更契合BERT原来的预训练任务.</p><h3 id="Detailed-Results-on-Complex-Scenarios"><a href="#Detailed-Results-on-Complex-Scenarios" class="headerlink" title="Detailed Results on Complex Scenarios"></a>Detailed Results on Complex Scenarios</h3><p>在NYT, WebNLG部分匹配上按照不同类型区分的F1 Score如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn8.png" style="zoom:40%"><p>RFBFN几乎全面优于Baseline模型.</p><h3 id="Results-on-Different-Subtasks"><a href="#Results-on-Different-Subtasks" class="headerlink" title="Results on Different Subtasks"></a>Results on Different Subtasks</h3><p>在NYT, WebNLG部分匹配上各个子任务的实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn9.png" style="zoom:40%"><p>在NYT*上性能被实体识别拖了后腿, 但在WebNLG*上相反, 作者将其归因于后者的关系种类众多.</p><h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><h4 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h4><p>在WebNLG*消融实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn10.png" style="zoom:40%"><p>它们分别对应着如下改动:</p><ul><li><strong>- Relation Detection Module</strong>: 直接移除Relation Detection Module, 假设句子中所有关系都成立, 喂给Entity Pair Extractor. 因为WebNLG* 关系太多了, 作者只选了正样本和30%的负样本.</li><li><strong>- Candidate Relation Judgement</strong>: 直接移除Candidate Relation Judgement, 即忽略Relation Detection Module里面抽取出的错误关系.</li><li><strong>- Relation Template Generation</strong>: 把Relation Template换成Relation Embedding.</li><li><strong>- NA Entity Pair Extractor</strong>: 替换NAD里面的Unmasked Self Attention为Casual Mask, 即按序生成Subject和Object.</li><li><strong>- Joint Training</strong>: 不再共享Encoder, 使用两个独立的Encoder做训练.</li></ul><p>影响最大的是Relation Detection Module和NA Entity Pair Extractor. Entity Pair Extractor更倾向于从正确的关系模板中抽取实体, 所以喂进去负样本时表现下降很严重(体现在Precision上), 让Non - Autoregressive变成Autoregressive去生成Subject和Object也显示出了不同时抽取带来的不一致性.</p><p>关于Relation Template Generation的影响, 作者特地做了个Case Study:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn11.png" style="zoom:33%"><p>使用Relation Embedding的模型不能正确理解关系的语义信息, 相反Relation Template可以.</p><h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p>假设一句子中的三元组Ground Truth为<code>(Brom, club, Arnhem)</code> 和 <code>(Brom, club, Graafschap)</code>, 输入Entity Pair Extractor的关系类型为<code>club</code>, Entity Pair Extractor中的Attention Score Heatmap如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rfbfn12.png" style="zoom:33%"><p>能够看到不同的槽位可以把Attention放到对应关系下的实体上.</p><blockquote><p>按理说最后两个<code>[MASK]</code>应该把注意力放到<code>[CLS]</code>上才对, 因为Label中设定多余的槽位答案为<code>[CLS]</code>.</p><p>当然也可能有一种解释, <code>[CLS]</code> 本身就是反映句子语义的, 所以在这里注意力分散是因为<code>[CLS]</code> 与句子本身的语义相似, 所以对无论是Attend到<code>[CLS]</code> 还是分散到其他地方都是合理的.</p></blockquote><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>我认为RFBFN算是<strong>SPN</strong>的一种改进, 是一个类似与PRGC的<strong>Pipeline</strong>模型, 先抽取<strong>关系</strong>, 然后根据关系构造出<strong>模板</strong>, 通过<strong>完形填空</strong>的方式抽取出<strong>实体</strong>. 它将SPN里的<strong>NADecoder Layer</strong>同时应用到了<strong>关系侧</strong>和<strong>实体侧</strong>.</p><p>由于使用NAD, 多次采用<strong>穷举</strong>的方法解决每个步骤的抽取问题: 穷举Span, 穷举Relation(指Query Embedding), 穷举Entity Pair(指复制模板多次).</p><p>虽然最后取得了优越的性能, 但说实话看着工程量和计算量都挺大的, 尤其是Span的引入占大头, 算是拿时间换性能吧.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/42381.html">https://ADAning.github.io/posts/42381.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/34610.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/2.jpg" class="responsive-img" alt="Pytorch学习: Pytorch Lightning"> <span class="card-title">Pytorch学习: Pytorch Lightning</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Pytorch学习: Pytorch LightningPytorch Lightning是在Pytorch基础上封装的框架, 号称”Pytorch里的Keras”, 如官网所述, 它具有灵活, 解耦, 易于复现, 自动化, 扩展性好等优点</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-08-14 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E7%BC%96%E7%A8%8B/"><span class="chip bg-color">编程</span> </a><a href="/tags/pytorch/"><span class="chip bg-color">pytorch</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/50175.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/20.jpg" class="responsive-img" alt="SPN: Joint Entity and Relation Extraction with Set Prediction Networks"> <span class="card-title">SPN: Joint Entity and Relation Extraction with Set Prediction Networks</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Joint Entity and Relation Extraction with Set Prediction Networks本文是论文Joint Entity and Relation Extraction with Set Pred</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-06-22 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">406k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>