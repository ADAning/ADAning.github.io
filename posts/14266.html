<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="UniLM: Unified Language Model Pre-training for Natural Language Understanding and Generation, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>UniLM: Unified Language Model Pre-training for Natural Language Understanding and Generation | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/19.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">UniLM: Unified Language Model Pre-training for Natural Language Understanding and Generation</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/NLP/"><span class="chip bg-color">NLP</span> </a><a href="/tags/BERT/"><span class="chip bg-color">BERT</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2021-06-18</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-03-27</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 1.9k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 7 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li>BERT: 详见<a href="https://adaning.github.io/posts/3996.html">ELMo, GPT, BERT</a>.</li></ul></blockquote><h1 id="UniLM-Unified-Language-Model-Pre-training-for-Natural-Language-Understanding-and-Generation"><a href="#UniLM-Unified-Language-Model-Pre-training-for-Natural-Language-Understanding-and-Generation" class="headerlink" title="UniLM: Unified Language Model Pre-training for Natural Language Understanding and Generation"></a>UniLM: Unified Language Model Pre-training for Natural Language Understanding and Generation</h1><p>本文是论文<a href="https://arxiv.org/abs/1905.03197" target="_blank" rel="noopener">Unified Language Model Pre-training for Natural Language Understanding and Generation</a>的阅读笔记和个人理解.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>作者认为, 当前流行的语言模型有三大类, 分别是以<strong>单向</strong>(左向右或右向左)的语言模型ELMo, GPT, 以<strong>双向</strong>为代表的语言模型BERT, 以及由各类Encoder和Decoder组合使用的<strong>Seq2Seq</strong>类模型:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm1.jpg" style="zoom:50%"><p>单向, 双向, Seq2Seq类的模型的优缺点各不相同, 所擅长的下游任务也不同, 对语言的编码方式更是不同:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm2.jpg" style="zoom:50%"><p>尽管这三类模型各有千秋, 但从来没有人尝试把上述三类模型<strong>统一</strong>到同一个模型中:</p><p>因此, 作者提出<strong>UniLM</strong>(<strong>Uni</strong>fied pre-trained <strong>L</strong>anguage <strong>M</strong>odel), 将上述三大类模型统一到同一个语言模型中, 共享同一组参数.</p><h2 id="UniLM"><a href="#UniLM" class="headerlink" title="UniLM"></a>UniLM</h2><h3 id="Input-Representation"><a href="#Input-Representation" class="headerlink" title="Input Representation"></a>Input Representation</h3><p>对于输入的序列$x$, 无论是作为单向语言模型的文本段, 还是对于双向语言模型训练时所使用的文本对, 都在输入文本段前添加起始Token<code>[SOS]</code>, 添加在文本段结束时添加结束Token<code>[EOS]</code>.</p><p>此外, <code>[EOS]</code> 不光作为NLU任务中的边界标记, 还作为NLG任务中的生成结束标记.</p><p>分词时采用WordPiece.</p><h3 id="Backbone-Network-Multi-Layer-Transformer"><a href="#Backbone-Network-Multi-Layer-Transformer" class="headerlink" title="Backbone Network: Multi - Layer Transformer"></a>Backbone Network: Multi - Layer Transformer</h3><blockquote><p>本部分即Transformer Encoder.</p></blockquote><p>对输入的Token表示$\left\{\mathbf{x}_{i}\right\}_{i=1}^{|x|}$, 输入第0层Transformer中获得初始上下文表示$\mathbf{H}^{0}=\left[\mathbf{x}_{1}, \cdots, \mathbf{x}_{|x|}\right]$, 经过$L$层Transformer堆叠$\mathbf{H}^{l}=\text { Transformer }_{l}\left(\mathbf{H}^{l-1}\right), l \in[1, L]$, 获得最终表示$\mathbf{H}^{l}=\left[\mathbf{h}_{1}^{l}, \cdots, \mathbf{h}_{|x|}^{l}\right]$.</p><p>每层Transformer层中的自注意力头输出$\mathbf{A}_l$ 可以被表示为:</p><p>$$<br>\begin{aligned}<br>\mathbf{Q} &amp;=\mathbf{H}^{l-1} \mathbf{W}_{l}^{Q}, \quad \mathbf{K}=\mathbf{H}^{l-1} \mathbf{W}_{l}^{K}, \quad \mathbf{V}=\mathbf{H}^{l-1} \mathbf{W}_{l}^{V} \\<br>\mathbf{M}_{i j} &amp;=\left\{\begin{array}{ll}<br>0, &amp; \text { allow to attend } \\<br>-\infty, &amp; \text { prevent from attending }<br>\end{array}\right.\\<br>\mathbf{A}_{l} &amp;=\operatorname{softmax}\left(\frac{\mathbf{Q} \mathbf{K}^{\top}}{\sqrt{d_{k}}}+\mathbf{M}\right) \mathbf{V}_{l}<br>\end{aligned}<br>$$</p><p>其中, $\mathbf{W}_l^Q, \mathbf{W}_l^K, \mathbf{W}_l^V$ 为线性投影矩阵, $\mathbf{M}$ 为Mask矩阵, 决定Token能够给予哪些部分注意力.</p><p>UniLM使用不同的Mask矩阵$\mathbf{M}$ 来决定模型在接下来的运算中能对哪些Token给予注意力. 所以UniLM能直接通过更改$\mathbf{M}$ 在使用同一组参数的条件下改变模型的运行模式, 非常灵活.</p><h3 id="Pre-Training-Objectives"><a href="#Pre-Training-Objectives" class="headerlink" title="Pre - Training Objectives"></a>Pre - Training Objectives</h3><p>在上一节说过, 双向语言模型, 单向语言模型, 亦或许是Seq2Seq架构下的语言模型, 都能够通过修改Self - Attention Mask的形式实现:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm3.jpg" style="zoom:50%"><p>UniLM仍然采用BERT类似的<strong>完形填空</strong>式作为目标, 采用<strong>最小化交叉熵</strong>的方式来优化模型参数.</p><p>在预训练, 作者介绍了单向, 双向, Seq2Seq三类目标在UniLM中的实现方式(其实加上NSP是四类, 但NSP仅在双向语言模型目标中使用):</p><ul><li><p><strong>Unidirectional LM</strong> - (上图中间): 对于单向语言目标, 不对输入分段, 只输入文本段$\text{S}_1$. 在左到右或右到左的单一方向是时序可见的, 因此只需要将$\mathbf{M}$ 的上三角或下三角设置为$-\infty$, 其余位置置零即可.</p></li><li><p><strong>Bidirectional LM</strong>- (上图顶端): 对于双向语言目标, 使用了NSP任务, 输入文本段$\text{S}_1, \text{S}_2$, 与BERT训练方式保持一致. Token之间是全部互相可见的, 因此$\mathbf{M}=\mathbf{0}$.</p></li><li><p><strong>Sequence-to-Sequence LM</strong> - (上图底部): 对于Seq2Seq目标, 输入源序列$\text{S}_1$ 和目标序列$\text{S}_2$, 并在 Encoder对应的$\text{S}_1$ 应该是双向可见的, 故$\mathbf{M}$ 的左侧为$\mathbf{0}$. 在Decoder对应的$\text{S}_2$, 上下文只应该单向可见, 即$\mathbf{M}$ 右侧$\text{S}_2$ 的上三角为$-\infty$, 其余为$\mathbf{0}$.</p><p>例如, 在预训练阶段, 对于Seq2Seq任务的输入$\text{S}_1=[t_1, t_2]$, 输出$\text{S}_2=[t_3, t_4, t_5]$, 将以<code>[SOS]</code>, $t_1$, $t_2$, <code>[EOS]</code>, $t_3$, $t_4$, $t_5$, <code>[EOS]</code> 的形式输入到模型中. $t_2$ 只能看见<code>[SOS]</code>, $t_1$, $t_2$, <code>[EOS]</code>, 而$t_4$ 可以看到<code>[SOS]</code>, $t_1$, $t_2$, <code>[EOS]</code>, $t_3$, $t_4$.</p><blockquote><p>在打Mask时, 如果Mask掉的部分为$\text{S}_1$ 的Token, 则有助于模型学到双向Encoder, 若Mask掉的部分为$\text{S}_2$ 的Token, 则有助于让模型学到单向Decoder. 另外, 由于<code>[EOS]</code> 是可以被Mask掉的, 在预测时可以教会模型何时该结束生成.</p><p>仔细一想其实挺巧妙的, 因为这样并不需要明确的在模型中划分出Encoder和Decoder的位置. 也就意味着整个模型的所有区域都有可能被当做是Encoder或者Decoder.</p></blockquote></li></ul><p>在UniLM实际训练过程中, 总的Loss为三者的<strong>加和</strong>. 并且对各类训练目标分配时间是<strong>均匀</strong>的, 即有$\frac{1}{3}$ 时间采用双向语言训练目标, $\frac{1}{3}$ 时间采用Seq2Seq训练目标, 从左到右和从右到左的单向语言训练目标各有$\frac{1}{6}$ 时间 . 因为只是对Mask做出了调整, 因此<strong>与BERT完全兼容</strong>, UniLM参数直接使用BERT - LARGE初始化.</p><blockquote><p>这三种类型的训练难度可能不同, 这里将它们平均考虑应该是出于探索, 不带来过多的麻烦.</p></blockquote><h3 id="Fine-Tuning-on-Downstream-NLU-and-NLG-Tasks"><a href="#Fine-Tuning-on-Downstream-NLU-and-NLG-Tasks" class="headerlink" title="Fine - Tuning on Downstream NLU and NLG Tasks"></a>Fine - Tuning on Downstream NLU and NLG Tasks</h3><ul><li>对NLU任务, 采用<code>[SOS]</code> 处的输出作为整个输入的表示, 记为$\mathbf{h}_1^L$, 可以由此计算文本在分类任务上的概率$\operatorname{softmax}\left(\mathbf{h}_{1}^{L} \mathbf{W}^{C}\right)$, $C$ 为类别数, 最大化类别标签的概率即可, 该部分与BERT一致.</li><li>对NLG任务, 令输入的源序列$\text{S}_1$, 目标序列$\text{S}_2$, 以<code>[SOS]</code>, $\text{S}_1$, <code>[EOS]</code>, $\text{S}_2$, <code>[EOS]</code> 的形式输入. 训练目标为最大化在给定上下文条件下, 被Mask部分原来内容的概率. 但在精调阶段, 只对$\text{S}_2$ 中的内容打Mask.</li></ul><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的实验参数设置请参考原论文.</p><h3 id="Abstractive-Summarization"><a href="#Abstractive-Summarization" class="headerlink" title="Abstractive Summarization"></a>Abstractive Summarization</h3><p>在CNN / DailyMail上的抽取式摘要和生成式摘要结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm4.jpg" style="zoom:50%"><p>Gigaword上生成式摘要结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm5.jpg" style="zoom:50%"><p>UniLM要比Baseline有小幅提升, 并几乎全面领先.</p><h3 id="Question-Answering-QA"><a href="#Question-Answering-QA" class="headerlink" title="Question Answering (QA)"></a>Question Answering (QA)</h3><h4 id="Extractive-QA"><a href="#Extractive-QA" class="headerlink" title="Extractive QA"></a>Extractive QA</h4><p>抽取式QA的在SQuAD上的结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm6.jpg" style="zoom:50%"><p>在CoQA上结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm7.jpg" style="zoom:50%"><h4 id="Generative-QA"><a href="#Generative-QA" class="headerlink" title="Generative QA"></a>Generative QA</h4><p>生成式QA在CoQA上结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm8.jpg" style="zoom:50%"><p>相较于指针生成网络, 在生成式QA上有非常明显的进步.</p><h3 id="Question-Generation"><a href="#Question-Generation" class="headerlink" title="Question Generation"></a>Question Generation</h3><p>SQuAD上问题生成结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm9.jpg" style="zoom:50%"><p>作者还使用UniLM所生成的问题让QA中的模型结果涨了四个点:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm10.jpg" style="zoom:50%"><p>据作者所述, 这应该是一种<strong>数据增强</strong>方法, 用生成的500w个可回答的问题, 以及经过更改后不可回答的400w个问题, 反喂给QA的UniLM微调少量Epoch, 结果有提升.</p><h3 id="Response-Generation"><a href="#Response-Generation" class="headerlink" title="Response Generation"></a>Response Generation</h3><p>对话生成结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm11.jpg" style="zoom:50%"><p>与Baseline相比, 若假设数据集所采取的评价指标是有效的, UniLM已经超过人类表现, 甚至更加精简.</p><h3 id="GLUE-Benchmark"><a href="#GLUE-Benchmark" class="headerlink" title="GLUE Benchmark"></a>GLUE Benchmark</h3><p>在GLUE上的结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unilm12.jpg" style="zoom:50%"><p>UniLM达到了新SOTA.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>同是出自MSRA的论文, UniLM与<a href="https://adaning.github.io/posts/46395.html">MASS</a>所尝试的思路是完全相反的.</p><p>如果说MASS是将BERT搬到了Seq2Seq上, 那么UniLM则是将Seq2Seq搬入了BERT体系, 用Mask来实现Seq2Seq的思路还是挺巧妙的, 个人感觉UniLM比MASS要有趣一些. 从结果上来看, UniLM将各类任务推向了新SOTA.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/14266.html">https://ADAning.github.io/posts/14266.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/NLP/"><span class="chip bg-color">NLP</span> </a><a href="/tags/BERT/"><span class="chip bg-color">BERT</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/60711.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/3.jpg" class="responsive-img" alt="ALBERT: A Lite BERT for Self-supervised Learning of Language Representations"> <span class="card-title">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: BERT: 详见ELMo, GPT, BERT. ALBERT: A Lite BERT for Self-supervised Learning of Language Representations本文是论文AL</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-06-29 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/NLP/"><span class="chip bg-color">NLP</span> </a><a href="/tags/BERT/"><span class="chip bg-color">BERT</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/46395.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/1.jpg" class="responsive-img" alt="MASS: Masked Sequence to Sequence Pre - training for Language Generation"> <span class="card-title">MASS: Masked Sequence to Sequence Pre - training for Language Generation</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识; BERT: 详见ELMo, GPT, BERT. Transformer: 详见Transformer精讲. MASS: Masked Sequence to Sequence Pre-training for La</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-06-08 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/NLP/"><span class="chip bg-color">NLP</span> </a><a href="/tags/BERT/"><span class="chip bg-color">BERT</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">361.6k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>