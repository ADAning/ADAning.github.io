<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/14.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2025-08-07</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2025-08-10</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.3k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 9 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li>Flow Matching: <a href="https://adaning.github.io/posts/19143.html">Flow Matching: Flow Matching for Generative Modeling</a>.</li><li>TCSinger: <a href="https://adaning.github.io/posts/32823.html">TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control</a>.</li></ul></blockquote><h1 id="TCSinger-2-Customizable-Multilingual-Zero-shot-Singing-Voice-Synthesis"><a href="#TCSinger-2-Customizable-Multilingual-Zero-shot-Singing-Voice-Synthesis" class="headerlink" title="TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis"></a>TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis</h1><ul><li>论文: <a href="https://arxiv.org/abs/2505.14910" target="_blank" rel="noopener">TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis</a>, <strong>ACL 2025 Findings</strong>, Zhou Zhao组.</li><li>代码: <a href="https://github.com/AaronZ345/TCSinger2" target="_blank" rel="noopener">GitHub - AaronZ345/TCSinger2: PyTorch Implementation of TCSinger 2(ACL 2025): Customizable Multilingual Zero-shot Singing Voice Synthesis</a>.</li><li>Demo: <a href="https://aaronz345.github.io/TCSinger2Demo/" target="_blank" rel="noopener">TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis | Demo page of TCSinger 2</a>.</li></ul><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>现有的SVS模型在Zero-Shot上存在以下问题:</p><ol><li>对有标注的<strong>边界信息</strong>(音素, 音符)存在<strong>过度依赖</strong>问题, 导致它们在Zero-Shot场景下缺乏鲁棒性或表现不佳.</li><li>现有的SVS模型缺乏通过<strong>Prompt</strong>来对多层次风格的<strong>有效控制能力</strong>.</li></ol><p>为解决上述问题, 作者提出了<a href="https://adaning.github.io/posts/32823.html">TCSinger</a>的续作TCSinger2.</p><h2 id="TCSinger-2"><a href="#TCSinger-2" class="headerlink" title="TCSinger 2"></a>TCSinger 2</h2><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>TCSinger2整体框架如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2.png" style="zoom:33%"><p>左边看架构分为几个部分:</p><ul><li><strong>BBC Encoder</strong>: 引入<strong>边界模糊</strong>来克服边界标注不精确的问题.</li><li><strong>Custom Audio Encoder</strong>: 为了引入更多种形式的Prompt来完成多层次风格表示, 必须要有一个Aligned Encoder.</li><li><strong>Flow-based Custom Transformer</strong>: 增强个性化</li><li><strong>Audio Decoder</strong>: 完成Latent到Mel的转化.</li></ul><p>整体流程为, BBC Encoder用Note和Lyrics预测Duration. Custom Audio Encoder编码Prompt Mel, Noise. 然后给到Flow-based Custom Transformer一起做生成. 最后用Audio Decoder把Latent解码成Mel.</p><h3 id="BBC-Encoder"><a href="#BBC-Encoder" class="headerlink" title="BBC Encoder"></a>BBC Encoder</h3><p>BBC Encoder(<strong>B</strong>lurred <strong>B</strong>oundary <strong>C</strong>ontent Encoder)的功能是对边界内容进行<strong>模糊编码</strong>.</p><p>BBC Encoder的存在很大一部分原因受限于现在的SVS数据集标注<strong>不精确</strong>(包括GTSinger, M4Singer等数据集), 所以加BBC提升模型<strong>鲁棒性</strong>. 因为很多数据集是<strong>MFA + 人工校对</strong>的, 相较于其他的领域, 受限于版权等问题, 量又不可能堆的非常大. 一个模糊的表示能让模型适应这些错误.</p><p>BBC Encoder的结构如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_1.png" style="zoom:50%"><p>非常常见的结构, 分别对Lyric $l$ 和Note $n$ 进行编码, 然后预测Duration, 然后再做Length Regulation. 最后用一个Blurred Boundary Adapter来完成Blurring Boundary Content.</p><p>具体的, Blurred Boundary Adapter通过<strong>打Mask</strong>的方式来将边界模糊. 对于一个给定的Frame-Level Sequence $[z_{c1}, z_{c1}, z_{c1}, z_{c1}, \dots, z_{cn}, ]$ (每个Note $n$ 具有一定Duration), 在每个Phoneme和Note <strong>Boundary</strong>上随机打$m$ 个Mask, 得到$z_c = \left[z_{c 1}, \varnothing, z_{c 2}, z_{c 2}, \varnothing, \ldots, z_{c n}\right]$.</p><p>作者设置$m=8$ , 并且不对长度非常短的数据应用Content Blurring. 这样子能使监督信号, 鲁棒性, 压缩率, 采样率几个因素达到权衡.</p><h3 id="Custom-Audio-Encoder"><a href="#Custom-Audio-Encoder" class="headerlink" title="Custom Audio Encoder"></a>Custom Audio Encoder</h3><p>Custom Audio Encoder完成了Singing, Speech, Text三者的表示对齐, 这样TCSinger2就能执行多样化Prompt支持下的各类工作.</p><p>基于<strong>Singing</strong> Prompt $p_{si}$, <strong>Speech</strong> Prompt $p_{sp}$, 含有Content $C$ 的<strong>Textual</strong> Prompt $p_{te}$, 可以构成一个三元组$(z_{psi}, z_{psp}, z_{ptc})$. 对齐它们三者, 定义Contrastive Loss:</p><p>$$<br>\mathcal{L}_{p_{s i}^i, p_{s p}^i}=\log \frac{\exp \left(\operatorname{sim}\left(z_{s i}{ }^i, z_{s p}{ }^i\right) / \tau\right)}{\sum_{j=1}^N \exp \left(\operatorname{sim}\left(z_{s i}{ }^i, z_{s p}{ }^j\right) / \tau\right)}<br>+\log \frac{\exp \left(\operatorname{sim}\left(z_{s p}{ }^i, z_{s i}{ }^i\right) / \tau\right)}{\sum_{j=1}^N \exp \left(\operatorname{sim}\left(z_{s p}{ }^i, z_{s i}{ }^j\right) / \tau\right)}<br>$$</p><p>$\text{sim}(\cdot)$ 为余弦相似度.</p><p>当然, 光对歌声和语音的$p_{si}$ 和$p_{sp}$ 做Contrastive Loss肯定是不够的. 还要分别让歌声和语音与文本端的对齐, 即$p^i_{sp}$ 与$p^i_{te}$, $p^i_{si}$ 与$p^i_{te}$ 的对齐. 所以总的Loss为:</p><p>$$<br>L_{contras}=-\frac{1}{6N}\sum\limits_{i=1}^N(\mathcal{L}_{p_{si}, p_{sp}} + \mathcal{L}_{p^i_{sp}, p^i_{te}} + \mathcal{L}_{p^i_{si}, p^i_{te}})<br>$$</p><p>此外, 为了保证$z_{psi}$ 具有对歌声建模的完整性, 还需要对$z_{psi}$ 进行重构. 所以还需要重构损失 $L_{rec}$.</p><p>Audio Decoder用L2 Loss $\mathcal{L}_{\text{recon}}$和LSGAN-style的Discriminator Loss $\mathcal{L}_{\text{adv}}$ 进行训练.</p><p>上述过程如下图所示:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_2.png" style="zoom:50%"><h3 id="Flow-based-Custom-Transformer"><a href="#Flow-based-Custom-Transformer" class="headerlink" title="Flow-based Custom Transformer"></a>Flow-based Custom Transformer</h3><p>歌唱是一个高度复杂且风格多变的技能, 建模起来具有难度. 作者将Custom-MOE和<br><a href="https://adaning.github.io/posts/19143.html">FM(Flow Matching)</a>结合到一起, 提出Flow-based Custom Transformer, 整体结构如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_3.png" style="zoom:50%"><p>流程上来看, 就是FM的整体框架, 但是把FFN换成了Cus-MOE. Text Prompt从Cus-MOE和Noisy Audio Embedding两端注入.</p><blockquote><p>Norm采用了RMSNorm和<strong>DiT</strong>里的AdaLN. Frame-Level Feature用了RoPE.</p></blockquote><h4 id="Flow-based-Transformer"><a href="#Flow-based-Transformer" class="headerlink" title="Flow-based Transformer"></a>Flow-based Transformer</h4><p>训练期间, 将高斯噪声$\epsilon$ 与Audio Encoder的输出$\hat{m_{gt}}$ 线性组合来获得$t$ 时刻的表示$x_t$. 然后将BBC Encoder获得的<strong>Content Embedding</strong>和$x_t$ 拼接, 送入Flow-based Transformer解码.</p><blockquote><p>与现在的主流<strong>LDM</strong>(Flux, <strong>Stable Diffusion3</strong>)等一样, FM是在Latent里面做的.</p></blockquote><p>可选的, 如果有从Custom Audio Encoder中获得的Audio Prompt Embedding $z_{pa}$, $z_{psi}$, $z_{psp}$ 都可以一起拼接.</p><p>当在用Text Prompt控制风格的时候, 应该将Text Prompt编码为$z_{pt}$, 代替$z_{pa}$ 完成拼接后序的解码.</p><p>对于每个时间步$t$, 用FM目标来训练Flow-based Transformer:</p><p>$$<br>\mathcal{L}_{\text {flow }}=\mathbb{E}_{t, p_t\left(x_t\right)}\left||v_t\left(x_t, t \mid C ; \theta\right)-\left(\hat{m_{g t}}-\epsilon\right)\right||^2<br>$$</p><p>$p_t(x_t)$ 代表$t$ 时刻$x_t$ 的分布. 另外, 根据<strong>StyleSinger</strong>的结论, 作者使用第一个Block的输出来预测F0.</p><h4 id="Cus-MOE"><a href="#Cus-MOE" class="headerlink" title="Cus-MOE"></a>Cus-MOE</h4><p>Cus-MOE的比较简单:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_4.png" style="zoom:50%"><p>Cus-MOE有两个Expert Groups, 即<strong>Lingual-MOE</strong>与<strong>Stylistic-MOE</strong>:</p><ul><li><strong>Lingual-MOE</strong>: 根据歌词的语言来选择语言专家, 每个专家负责不同的语系.</li><li><strong>Stylistic-MOE</strong>: 根据Audio Prompt或者Textual Prompt的条件, 选择细粒度不同风格的咋婚假, 每个专家负责的唱法不同.</li></ul><p>路由策略采用dense-to-sparse Gumbel-Softmax. 令$h$ 为hidden states, $g(h)_i$ 为专家$i$ 的Routing Score. 为防止负载不均, 采用Load-Balancing Loss:</p><p>$$<br>\mathcal{L}_{\text {balance }}=\alpha N \sum_{i=1}^N\left(\frac{1}{B} \sum_{h \in B} g(h)_i\right)<br>$$</p><p>$B$ 为Batch Size, $N$ 为专家数量, $\alpha$ 控制正则化强度.</p><h3 id="Training-and-Inference-Procedures"><a href="#Training-and-Inference-Procedures" class="headerlink" title="Training and Inference Procedures"></a>Training and Inference Procedures</h3><h4 id="Training-Procedures"><a href="#Training-Procedures" class="headerlink" title="Training Procedures"></a>Training Procedures</h4><p>预训练期间, Custom Audio Encoder / Decoder的Loss如下:</p><ol><li>Contrastive Loss $L_{contras}$.</li><li>重建L2损失 $L_{rec}$.</li><li>LS-GAN-styled的Discriminator Loss $L_{adv}$.</li></ol><p>TCSinger2的最终训练损失主要分为以下几项:</p><ol><li>$L_{dur}$: BBC Encoder里对数尺度的Phoneme-Level MSE.</li><li>$L_{pitch}$: 对数尺度的音高MSE.</li><li>$L_{balance}$: Cus-MOE中每个专家的负载.</li><li>$L_{flow}$: Flow-based Transformer的FM Loss.</li></ol><h4 id="Inference-Procedures"><a href="#Inference-Procedures" class="headerlink" title="Inference Procedures"></a>Inference Procedures</h4><p>TCSinger2在不同的Prompt下会执行不同的任务:</p><ul><li>对于没见过的Singing Prompt, 无论是跨语言还是同语言, 都可以执行Zero-Shot Style Transfer.</li><li>对于不同语言的歌词和Singing Prompt, 执行的是Cross-Lingual Style Transfer.</li><li>如果给定自然语言形式的Textual Prompt, 可以执行Multi-Level Style Control.</li><li>如果给定Speech Prompt, 可以执行Speech-to-Singing(STS) Style Transfer.</li></ul><p>训练时候采用<strong>CFG</strong>, 以0.2的概率直接丢弃输入的Prompt. 推理时, 将输出的向量场改为:</p><p>$$<br>v_{c f g}(x, t \mid C, P ; \theta)=\gamma v_t(x, t \mid C, P ; \theta)+(1-\gamma) v_t(x, \mid C, \varnothing ; \theta)<br>$$</p><p>$\gamma$ 为平衡创造性和可控性的CFG Scale Factor, 作者设为3.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的实验设置和超参设置请参考原论文. 作者使用8卡4090训练, Vocoder为预训练<a href="https://adaning.github.io/posts/43190.html">HiFi-GAN</a>.</p><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>数据集和TCSinger的一代大差不差, 不同在于多引入了Opencpop和一部分扩充数据:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_5.png" style="zoom:50%"><p>对于缺乏风格标签的数据, 还聘请了有音乐背景的专家进行指导完成手动标注. 并将这部分标签用GPT-4o生成Textual Prompt.</p><h3 id="Main-Results"><a href="#Main-Results" class="headerlink" title="Main Results"></a>Main Results</h3><h4 id="Style-Transfer"><a href="#Style-Transfer" class="headerlink" title="Style Transfer"></a>Style Transfer</h4><p>Cross Lingual Style Transfer效果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_6.png" style="zoom:50%"><p>TC2效果还是明显要好过其他Baseline的. 在平行语料的FFE上有了比较大的改进, 说明F0比以前要准确.</p><h4 id="Style-Control"><a href="#Style-Control" class="headerlink" title="Style Control"></a>Style Control</h4><p>作者在其他模型里加了Cross-Attention来处理Textual Prompt. 实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_7.png" style="zoom:50%"><p>平行语料的MOS-Q已经快接近Vocoder的GT了.</p><p>作者也对不同的唱法做了可视化:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_8.png" style="zoom:50%"><p>TC2能针对不同的风格有效控制.</p><h4 id="Speech-to-Singing"><a href="#Speech-to-Singing" class="headerlink" title="Speech-to-Singing"></a>Speech-to-Singing</h4><p>Zero-shot的STS表现如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_9.png" style="zoom:50%"><p>看起来TC2比TC要强很多.</p><blockquote><p>STS这个任务其实是能否完成客制化的关键. 因此看下游应用能不能有效就要看Zero-Shot STS的表现.</p></blockquote><h4 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h4><p>Style Transfer和Style Control上的消融实验如下, CAE代表Custom Audio Encoder:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tcsinger 2_10.png" style="zoom:50%"><ul><li>BBC Encoder发挥了比较大的作用, 直接移去差异很明显, 能有效缓解边界标注质量差的问题.</li><li>Custom Audio Encoder的Align去掉掉点也比较明显, 但相较于其他模块, 对CMOS-Q影响似乎不够大. 说明各类Prompt的对齐对歌手的相似度和控制影响要大一些.</li><li>Cus-MOE去掉的话掉点也挺多的, 尤其是Style Control, 在目前规模的数据下, Cus-MOE对Style Transfer和Style Control还是挺有帮助的.</li></ul><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>虽然是<a href="https://adaning.github.io/posts/32823.html">TCSinger</a>的续作, 但实际上路线和之前完全不一样了. 只能说它们做的都是多语言, 可控的Zero-Shot SVS吧. 整体思路用Latent Flow做生成.</p><p>感觉缝的内容也比较多, 从这上面来看明显在<strong>相对小规模的数据约束</strong>下, Zero-Shot SVS做起来比较困难. 由于版权, 成本等原因限制, SVS这个领域严重缺乏数据, 直接大大大的思路很可惜不能直接套过来.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/46935.html">https://ADAning.github.io/posts/46935.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="far fa-dot-circle"></i>&nbsp;本篇</div><div class="card"><a href="/posts/46935.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/14.jpg" class="responsive-img" alt="TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis"> <span class="card-title">TCSinger 2: Customizable Multilingual Zero-shot Singing Voice Synthesis</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: Flow Matching: Flow Matching: Flow Matching for Generative Modeling. TCSinger: TCSinger: Zero-Shot Singing Voi</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2025-08-07 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/32823.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/8.jpg" class="responsive-img" alt="TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control"> <span class="card-title">TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control</span></div></a><div class="card-content article-content"><div class="summary block-with-text">TCSinger: Zero-Shot Singing Voice Synthesis with Style Transfer and Multi-Level Style Control 论文: TCSinger: Zero-Shot Si</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2025-07-01 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">435.3k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>