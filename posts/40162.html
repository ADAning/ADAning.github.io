<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="基于轻量级卷积和动态卷积替代的注意力机制, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>基于轻量级卷积和动态卷积替代的注意力机制 | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/10.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">基于轻量级卷积和动态卷积替代的注意力机制</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/CNN/"><span class="chip bg-color">CNN</span> </a><a href="/tags/Attention/"><span class="chip bg-color">Attention</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-12-05</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-03-27</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.6k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 9 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li>Depthwise Convolution: 详见<a href="https://adaning.github.io/posts/13629.html">深度可分离卷积与分组卷积</a>.</li><li>Attention: 详见<a href="https://adaning.github.io/posts/40071.html">Seq2Seq和Attention</a>.</li><li>Transformer: 详见<a href="https://adaning.github.io/posts/6744.html">Transformer精讲</a>.</li></ul></blockquote><p>本文是论文<a href="http://arxiv.org/abs/1901.10430" target="_blank" rel="noopener">PAY LESS ATTENTION WITH LIGHTWEIGHT AND DYNAMIC CONVOLUTIONS</a>的阅读笔记和个人理解. 因为本文的图片均来自于原论文或Reference中的文章, 我觉得列出的几篇文章都很好, 图片特别有助于讲解. 论文中还有大量我不了解的知识, 再有相关的东西再进行补充.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>Self - Attention虽然解决了长距离依赖问题, 但因为计算量大, 必须对文本长度进行限制. 牵扯到计算效率的问题, 自然而然的就想到高效而体积小的<strong>卷积</strong>. 作者希望用轻量级卷积实现类似Self - Attention的效果.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv7.jpg" style="zoom:67%"><p>左侧为Self - Attention的权重生成方式, 右侧为Dynamic Convolution的权重生成方式.</p><p>作者希望能通过仅通过每个时刻的输入就能生成注意力权重, 而非像Self - Attention一样依赖全局输入生成.</p><h2 id="Depthwise-Convolution-and-Convolution-1D"><a href="#Depthwise-Convolution-and-Convolution-1D" class="headerlink" title="Depthwise Convolution and Convolution 1D"></a>Depthwise Convolution and Convolution 1D</h2><p>Lightweight Convolution的核心是<strong>单个维度上的深度卷积</strong>(Depthwise Convolution).</p><h3 id="Convolution-in-1-Dimension"><a href="#Convolution-in-1-Dimension" class="headerlink" title="Convolution in 1 Dimension"></a>Convolution in 1 Dimension</h3><p>无论在多少Dimension的卷积中, Channel维对应的是输入数据相独立的”<strong>厚度</strong>“这个维度, 它必须能保留输入单元的原始信息, 以保证不同输入元素之间的交互.</p><p>例如Conv2d在CV中, 为了保留二维图片的<strong>平面位置信息</strong>, Channel维对应的是Depth维, 而Conv1d在NLP中, 为了保留一维序列的<strong>先后顺序信息</strong>, <strong>Channel维所对应的是词向量的Hidden维</strong>. 这里先入为主,</p><blockquote><p>我开始是Channel维没找对, 卡了很长时间, 希望大家在看的时候从这个角度先入为主.</p></blockquote><h3 id="Depthwise-Convolution"><a href="#Depthwise-Convolution" class="headerlink" title="Depthwise Convolution"></a>Depthwise Convolution</h3><p>深度卷积是一种对每个Channel分别卷积的卷积方式:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/dsconv3.jpg" style="zoom:33%"><p>假设你已经具备了深度卷积的基础, 其数学表达如下:<br>$$<br>O_{i, c}=\operatorname{DepthwiseConv}\left(X, W_{c,:}, i, c\right)=\sum_{j=1}^{k} W_{c, j} \cdot X_{\left(i+j-\left\lceil\frac{k+1}{2}\right\rceil\right), c}<br>$$<br>其中$c$ 代表Channel, $k$ 为卷积核宽度, $i$ 为特征图中Token的位置. 那么$W_{c, :}$ 就代表指定Channel $c$ 的卷积核权重.</p><p>现在我们对已经嵌入好的序列输入做卷积. 如果我们使用的是<strong>标准卷积</strong>, 那么每次卷积的部分都必须<strong>贯穿Channel维</strong>, 即对每个Channel使用不同的参数:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv1.jpg" style="zoom:50%"><p>因为不同Channel上不共享相同的权重, 所以此时卷积核的参数量为$d_{in} \cdot d_{out} \cdot k$.</p><p>如果使用<strong>深度卷积</strong>, 那么每次卷积就只在每个Channel上单独进行:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv2.jpg" style="zoom:50%"><p>如果$d_{in} = d_{out}=d$, 即<strong>维持卷积前后的Channel数不变</strong>, 这样参数一下就从$d^2k$ 降到了$dk$, 因为我们不用再做贯穿整个Channel的运算了.</p><p>如果我们拿深度卷积的式子举个例子, 当$i=2, c=5, k=3$ 时(即图中所对应的绿色卷积过程), 那么在特征图上第2行第5列的输出$O_{2, 5}$ 则为$O_{2, 5} =W_{5, 1:3}X_{1:3, 5}$.</p><blockquote><p>我开始不能理解为什么参数能下降$d$ 倍, 后来发现我一直都忽视了”<strong>代替Self - Attention</strong>“这个目的, 在Self - Attention前后, Channel是不变的, 即$d_{in}=d_{out}$. 因此作者说法无误.</p></blockquote><h2 id="Lightweight-Convolution"><a href="#Lightweight-Convolution" class="headerlink" title="Lightweight Convolution"></a>Lightweight Convolution</h2><p>轻量级卷积在深度卷积的基础上进一步改进, 它引入了<strong>多头共享权重</strong>机制, 使得参数进一步减少.</p><h3 id="Weight-sharing"><a href="#Weight-sharing" class="headerlink" title="Weight sharing"></a>Weight sharing</h3><p>为了进一步减少参数量, 作者将Channel维拆成$H$ 个头, 在同一个头覆盖的区域内<strong>仅使用一个头</strong>(或者说在同一个头内的每个Channel维上的卷积核参数相同):</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv3.jpg" style="zoom:50%"><p>例如上图中, 橙色区域的两个Channel共享同一个卷积核.</p><p>经过权重共享, 每个头所占有的Channel数为$\frac{d}{H}$, 这样参数量就缩小为了原来的$\frac{d}{H}$ 倍. 若有$H$ 个头, 参数量进一步从$d \cdot k$ 缩减到$H \cdot k$.</p><p>轻量级卷积的数学表达如下:</p><p>$$<br>\operatorname{LightConv}\left(X, W_{\lceil\frac{c H}{d}\rceil,:}, i, c\right)=\operatorname{ DepthwiseConv }\left(X, \operatorname{softmax}\left(W_{\lceil\frac{c H}{d}\rceil,:}\right), i, c\right)<br>$$</p><p>其中$\lceil\frac{c H}{d}\rceil$ 指的是$c$ 属于哪个头, $\frac{c}{d}$ 指的是Channel $c$ 在Channel维总深度$d$ 中所处的位置百分比. 因为一共就有$H$ 个头, 所以每个头占总Channel的$\frac{1}{H}$. 那么$\lceil\frac{c}{d} \div \frac{1}{H}\rceil$ 就能算出$c$ 的位置前面到底有几个头, 向上取整就是$c$ 所属的头位置.</p><p>输入时对卷积核Softmax归一化详见下一小节.</p><h3 id="Softmax-Normalization"><a href="#Softmax-Normalization" class="headerlink" title="Softmax Normalization"></a>Softmax Normalization</h3><p>我们最初的目标是通过卷积来代替自注意力机制, 所以仅仅通过卷积得到还不足够, 我们必须将其归一化形成<strong>权重</strong>, 才能够符合注意力权重的标准. 由于权重是对不同时间步分配的, 所以在卷积核大小$k$ 对卷积核<strong>内部进行</strong>权重归一化:</p><p>$$<br>\operatorname{softmax}(W)_{h, j}=\frac{\exp W_{h, j}}{\sum_{j^{\prime}=1}^{k} \exp W_{h, j^{\prime}}}<br>$$</p><p>其中$W \in \mathbb{R}^{H \times k}$, 为多头卷积核的权重矩阵. 通过Softmax归一化, 同一个卷积核中的参数只能得到<strong>固定</strong>的注意力权重, 因为我们目前仅仅是对卷积核权重这个固定参数上归一化, 而没有结合当前时刻的输入信息.</p><h3 id="Gated-Linear-Units"><a href="#Gated-Linear-Units" class="headerlink" title="Gated Linear Units"></a>Gated Linear Units</h3><p>GLU是一种应用在CNN上的一种<strong>门控机制</strong>, 于<a href="http://proceedings.mlr.press/v70/dauphin17a" target="_blank" rel="noopener">Language Modeling with Gated Convolutional Networks</a>中提出, 该结构能够提升CNN抽取高层抽象特征的能力, 其核心思想如下:</p><p>$$<br>h_{l}(\mathbf{X})=(\mathbf{X} \ast \mathbf{W}+\mathbf{b}) \otimes \sigma(\mathbf{X} \ast \mathbf{V}+\mathbf{c})<br>$$</p><p>其中$\ast$ 代表卷积操作, $\mathbf{X}$ 代表输入矩阵, $\mathbf{W}, \mathbf{V}$ 代表两卷积核, $\mathbf{b}, \mathbf{c}$ 代表两卷积偏置, $\otimes$ 代表逐元素点乘.</p><p>在GLU中, 最基本的Block被定义为:<br>$$<br>\operatorname{GLU}(X) = X + \operatorname{CNN}(X) \otimes \operatorname{CNN}(X)<br>$$<br>残差连接和门控CNN就组成了最小的GLU单元.</p><blockquote><p>推荐阅读<a href="https://leimao.github.io/blog/Gated-Linear-Units/" target="_blank" rel="noopener">Gated Linear Units (GLU) and Gated CNN</a>.</p></blockquote><h3 id="Module"><a href="#Module" class="headerlink" title="Module"></a>Module</h3><p>轻量级卷积模块由<strong>Linear</strong>, <strong>GLU</strong>, <strong>LConv</strong>, <strong>Linear</strong>依次组成. 第一个Linear先将Token的Embedding维度从$d$ 投影映射到$2d$, 接着通过一个门控来调控输入的信息量, 再通过轻量级卷积, 最后再接一个Linear将维度调整回$d$:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv8.jpg" style="zoom:33%"><p>左图为Transformer中使用的点击缩放注意力, 右图为作者目前提出的轻量级卷积模块, 输入维度和输出维度是一致的.</p><h2 id="Dynamic-Convolution"><a href="#Dynamic-Convolution" class="headerlink" title="Dynamic Convolution"></a>Dynamic Convolution</h2><p>目前的轻量级卷积在不同时间步的权重都是<strong>固定</strong>的, 根本没有达到动态生成权重的效果, 基于轻量级卷积, 作者进一步提出<strong>动态卷积</strong>, 动态卷积对每个位置的权重都是<strong>动态</strong>的.</p><p>$$<br>\begin{aligned}<br>\operatorname{DynamicConv}(X, i, c)&amp;=\operatorname{LightConv}\left(X, f(X_{i})_{h,:}, i, c\right) \\<br>&amp;=\operatorname{ DepthwiseConv }\left(X, \operatorname{softmax}\left(f(X_{i})_{h,:}\right), i, c\right)<br>\end{aligned}<br>$$</p><p>其中$f$ 是一个简单的可学习的线性变换$W^Q$, 例如$f(X_{i})=\sum_{c=1}^{d} W_{h, j, c}^{Q} X_{i, c}$. 它能将当前时刻的$d$ 维的输入转化成$H\times k$ 维的注意力权重.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv4.jpg" style="zoom:50%"><p>简而言之, 就是利用某个时刻(实际上是Token)的全部Channel信息为当前时刻窗口内所有头的卷积核参数赋予权重, 而当前时刻Token的内容就相当于Self - Attention中的<strong>Query</strong>.</p><blockquote><p>注意力权重的生成只取决于<strong>当前时刻的输入</strong>, 而与前时刻和后时刻输入无关, 这是一个严重缺陷.</p></blockquote><p>下图依次为点积缩放注意力, 轻量级卷积模块, 动态卷积模块.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv6.jpg" style="zoom:33%"><p>动态卷积模块与轻量级卷积相比, 只是多增加了一个动态分配权重的Linear层.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>作者在机器翻译, 语言建模, 文本摘要任务上将Transformer中的自注意力机制换成轻量级卷积或动态卷积测试本方法的性能. 在Encoder中, 将自注意力模块替换, 在Decoder中将Masked自注意力模块替换.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv5.jpg" style="zoom:50%"><p>针对<strong>具体任务</strong>作者进行了不同的调整, 详细配置请参照原论文.</p><p>作者提出, 参数量近似的情况下对比性能. 所以并没有采用6层的Block堆叠, 而是使用了7层. 这七层中, 卷积核大小依次为3, 7, 15, 31, 31, 31, 31.</p><blockquote><p>高层卷积核窗口设置的比较大, 我猜还是因为高层特征抽取中卷积的<strong>局部性限制</strong>问题. 在BERT的Attention可视化对高层能观察到, 除了一些特定层能很明显的体现出注意力差异, 其他高层基本上是均摊注意力权重, 所以卷积核需要更大范围的捕捉上下文特征相关性.</p></blockquote><h3 id="Machine-Translation"><a href="#Machine-Translation" class="headerlink" title="Machine Translation"></a>Machine Translation</h3><p>作者分别在newstest2014上测试了BLEU准确率:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv9.jpg" style="zoom:33%"> <img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv10.jpg" style="zoom:33%"><p>动态卷积与原生Transformer在参数量相同的情况下有较大提升.</p><h3 id="Model-Ablation"><a href="#Model-Ablation" class="headerlink" title="Model Ablation"></a>Model Ablation</h3><p>消融实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv11.jpg" style="zoom:33%"><p>感觉小Trick颇多, 权重共享在提高句子推断速度上有较大贡献. 在性能提升上每种Trick的贡献都差不多.</p><h3 id="Language-Modeling"><a href="#Language-Modeling" class="headerlink" title="Language Modeling"></a>Language Modeling</h3><p>在Google Billion Word上以困惑度为指标结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv12.jpg" style="zoom:33%"><p>动态卷积的参数比自注意力还稍多, 在测试集上取得了略胜自注意力一丢丢的成绩…</p><h3 id="Abstractive-Summarization"><a href="#Abstractive-Summarization" class="headerlink" title="Abstractive Summarization"></a>Abstractive Summarization</h3><p>作者在CNN - DailyMail中的文本摘要实验结果:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lightweightconv13.jpg" style="zoom:33%"><p>轻量级卷积略胜一筹, 但其实也还是没节省多少参数.</p><p>从实验结果来看, 轻量级卷积在相同参数的情况下给出了一定的性能提升, 但并没有比较更少参数和其他模型的对比. 此外, 实验中的结果跟具体任务下的<strong>参数微调</strong>绝对是分不开的.</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://qiita.com/koreyou/items/328fa92a1d3a7e680376" target="_blank" rel="noopener">論文紹介: Pay Less Attention with Lightweight and Dynamic Convolutions</a></li><li><a href="https://zhuanlan.zhihu.com/p/60482693" target="_blank" rel="noopener">Pay less attention with light-weight &amp;dynamic CNN</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=Mzg4MTEyMDk4Mg==&mid=2247484363&idx=1&sn=513a3f43902fc676f0e82f7136a94047&chksm=cf6b8072f81c096461d774eea90708121be418c53489b57e1951486b61f0c935bd69e948d482&mpshare=1&scene=1&srcid=1126GOjiRcL3TMhItmW6o196&sharer_sharetime=1606391708291&sharer_shareid=fd56e6671880039dc74b6cae5739dbd6&key=9520b16d9caa09008014ec82a8170b261af98843c13ece553a632234270e3c33bb2e29b1363f68b0b27df64710bdeadc29771bfb85bf331dff2c338dc3adb8a1794ae07bc06ea53a6088117fea040ab7da42919076085bc9bc06bb605be58f8aed3db8ef8b05c566bf1212d529e7685c07ef59850f6e244f20a2e229ba6b1b29&ascene=1&uin=MzExMTYwMjkzNw%3D%3D&devicetype=Windows+10+x64&version=6300002f&lang=zh_CN&exportkey=A%2B4JQqyuu2BEHy%2Fe%2B%2BFCG00%3D&pass_ticket=cOZYWOTfohJ2mVibAtIZzeO5jFOFGWxvNcr1jum%2BAYkYBwgP0NMOV0reW3wv3lkV&wx_header=0" target="_blank" rel="noopener">ICLR 2019 | 采用轻量化及动态卷积替代注意力机制</a></li></ul></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/40162.html">https://ADAning.github.io/posts/40162.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/CNN/"><span class="chip bg-color">CNN</span> </a><a href="/tags/Attention/"><span class="chip bg-color">Attention</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/2954.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="R-MeN: A Relational Memory-based Embedding Model"> <span class="card-title">R-MeN: A Relational Memory-based Embedding Model</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: Self - Attention: 详见Transformer精讲. 2020.12.14: 修正错误. A Relational Memory-based Embedding Model for Triple Cl</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-12-10 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></span></div></div><div class="card-action article-tags"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/Attention/"><span class="chip bg-color">Attention</span> </a><a href="/tags/%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">记忆网络</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/18273.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/14.jpg" class="responsive-img" alt="KG-BERT: BERT for Knowledge Graph Completion"> <span class="card-title">KG-BERT: BERT for Knowledge Graph Completion</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: BERT: 详见ELMo, GPT, BERT. 本文是论文KG-BERT: BERT for Knowledge Graph Completion的阅读笔记和个人理解. Basic Idea在先前的KGE方法中,</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-11-28 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></span></div></div><div class="card-action article-tags"><a href="/tags/BERT/"><span class="chip bg-color">BERT</span> </a><a href="/tags/KGE/"><span class="chip bg-color">KGE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">309k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>