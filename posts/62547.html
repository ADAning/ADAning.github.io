<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="Generative Adversarial Zero-Shot Relational Learning for KGs, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>Generative Adversarial Zero-Shot Relational Learning for KGs | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/medias/featureimages/2.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Generative Adversarial Zero-Shot Relational Learning for KGs</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/GAN/"><span class="chip bg-color">GAN</span> </a><a href="/tags/ZSL/"><span class="chip bg-color">ZSL</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-12-11</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-03-27</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 4.2k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 17 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="Generative-Adversarial-Zero-Shot-Relational-Learning-for-Knowledge-Graphs"><a href="#Generative-Adversarial-Zero-Shot-Relational-Learning-for-Knowledge-Graphs" class="headerlink" title="Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs"></a>Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs</h1><p>本文是论文<a href="https://arxiv.org/abs/2001.02332" target="_blank" rel="noopener">Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs</a>的阅读笔记和个人理解. 本论文涉及到大量关于GAN的内容, 我对GAN还不是很熟悉, 在论文中具体的内容也不展开讲了, 我会放在推荐阅读中. 其中涉及到的地方如果有错误欢迎指出.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>作者指出, 即使是现在的大规模知识图谱, 仍然有可能无法满足日益增长的<strong>扩展</strong>需求.</p><p>对于新加入的关系, 经典的KGE算法无法应对新加入的关系. 而获取人为标注的数据是非常困难的, 因此作者希望能通过<strong>Zero - Shot Learning</strong>来缓解数据缺失的问题. 更具体点, 从关系的<strong>文本</strong>中学习它们的语义特征, 来增强在没有见过任何样本的情况下对没见过的关系的认知能力.</p><p>作者提出了一种KGE<strong>范式</strong>, 能够把<strong>任意</strong>的KGE方法应用于此.</p><h2 id="Convert-into-Knowledge-Transfer-Problem"><a href="#Convert-into-Knowledge-Transfer-Problem" class="headerlink" title="Convert into Knowledge Transfer Problem"></a>Convert into Knowledge Transfer Problem</h2><p>作者将Zero Shot Learning转化为一个<strong>知识迁移</strong>问题, 作者将关注如何只用文本描述生成没见过的关系嵌入, 这样, 只要经过训练, 模型能对任意关系在不进行Fine Tune的情况下生成嵌入. 通过关系嵌入, 能够对没有见过的关系通过<strong>余弦相似度</strong>简单的识别.</p><p>最首要的问题就是将文本语义空间的信息<strong>迁移</strong>到KG语义空间, 对此作者采用GAN来做知识迁移, 作者提出的架构如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg1.jpg" style="zoom:33%"><p>对于模型已经见过的文本, 训练一个生成器(Generator), 能够从文本中生成相应的<strong>Fake</strong> Relation Embedding, 再针对该关系中所涉及到的头尾实体使用某种方法编码成<strong>Real</strong> Relation Embedding. 将真与假的Relation Embedding<strong>交替</strong>输入判别器(Discriminator), 让它来判断Relation Embedding到底是真的还是假的.</p><p>当Generator生成的数据能够<strong>以假乱真</strong>时, 生成器所生成的Relation Embedding就能直接<strong>近似</strong>的当做是未见过的关系的Relation Embedding, 在Link Prediction任务中, 便能轻松应对未见过的关系.</p><h2 id="Zero-Shot-Learning-in-KG"><a href="#Zero-Shot-Learning-in-KG" class="headerlink" title="Zero - Shot Learning in KG"></a>Zero - Shot Learning in KG</h2><p>有必要稍微说一下Zero - Shot Learning在Link Prediction的设定.</p><p>对于一个查询关系三元组$\left\{\left(e_{1}, r, e_{2}\right)\right\}$, 给定头实体和关系元组$(e_1, r)$, 假设其应该对应的候选尾实体$e_2^\prime \in C_{\left(e_{1}, r\right)}$, 其真正的尾实体是$e_2$. 模型应该能将真正尾实体$e_2$ 排在最高, 而其余候选集合的实体$e_2^{\prime}$ 应该排在后面.</p><p>在Zero - Shot Learning的设置下, 还应该有见过的关系集$R_{s}=\left\{r_{s}\right\}$ 和没有见过的关系集$R_{u}=\left\{r_{u}\right\}$, 显然$R_{s} \cap R_{u}=\emptyset$.</p><p>对于训练集, 所有关系都是<strong>见过</strong>的, 即:<br>$$<br>D_{s}=\left\{\left(e_{1}, r_{s}, e_{2}, C_{\left(e_{1}, r_{s}\right)}\right) \mid e_{1} \in E, r_{s} \in R_{s}, e_{2} \in E\right\}<br>$$<br>在测试集中, 所有关系都是<strong>没有见过</strong>的, 即:<br>$$<br>D_{u}=\left\{\left(e_{1}, r_{u}, e_{2}, C_{\left(e_{1}, r_{u}\right)}\right) \mid e_{1} \in E, r_{u} \in R_{u}, e_{2} \in E\right\}<br>$$<br>出于可行性, 作者将所有实体设置为闭集, 即测试集中出现的所有<strong>实体</strong>均在训练集中<strong>见过</strong>.</p><h2 id="Model-for-Zero-Shot-KG-Relational-Learning"><a href="#Model-for-Zero-Shot-KG-Relational-Learning" class="headerlink" title="Model for Zero-Shot KG Relational Learning"></a>Model for Zero-Shot KG Relational Learning</h2><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg3.jpg" style="zoom:33%"><p>该图在后文中讲解关于GAN的部分会再次出现.</p><p>作者提出的方法中, 核心问题是如何设计一种<strong>条件生成模型</strong>, 去学习从文本中生成高质量的关系嵌入. 在作者的框架中, 主要设计了三个组件:</p><ul><li><strong>Feature Encoder</strong>: 仅通过实体生成真实的Relation Embedding.</li><li><strong>Generator</strong>: 在文本表示下生成合理的Relation Embedding.</li><li><strong>Discriminator</strong>: 判断数据的来源真假, 并识别<strong>关系类别</strong>.</li></ul><h3 id="Feature-Encoder"><a href="#Feature-Encoder" class="headerlink" title="Feature Encoder"></a>Feature Encoder</h3><p>对于没见过的关系, 普通KGE方法是无法取得其Embedding的.</p><p>Feature Encoder使用的Embedding可以是任意KGE模型得来的Embedding, 这也就是为什么作者说这是一种Zero - Shot的使用范式, 能够应用于任何的KGE方法.</p><p>Feature Encoder应该是在GAN训练前<strong>预先训练好</strong>的, 训练生成器和判别器时, 其参数应该不变.</p><h4 id="Network-Architecture"><a href="#Network-Architecture" class="headerlink" title="Network Architecture"></a>Network Architecture</h4><p>出于大规模KG的复杂度, 考虑到实验的可行性, 对于每个实体对中的$e$, 作者只考虑到它们的一阶邻居$\mathcal{N}_{e}$:<br>$$<br>\mathcal{N}_{e}=\left\{\left(r^{n}, e^{n}\right) \mid\left(e, r^{n}, e^{n}\right) \in \mathcal{G}\right\}<br>$$<br><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg2.jpg" style="zoom:25%"></p><p>假设在原来的KGE模型中, 给出的邻居关系和实体Look Up Table Embedding分别为$v_{r^{n}}, v_{e^{n}}$, 其嵌入维度为$d$, 那么该实体$e$ 一阶邻居的所有信息$u_e$ 能被表示为:<br>$$<br>\begin{array}{l}<br>f_{1}\left(v_{r^{n}}, v_{e^{n}}\right)=W_{1}\left(v_{r^{n}} \oplus v_{e^{n}}\right)+b_{1} \\<br>u_{e}=\sigma\left(\frac{1}{\left|\mathcal{N}_{e}\right|} \sum_{\left(r^{n}, e^{n}\right) \in \mathcal{N}_{e}} f_{1}\left(v_{r^{n}}, v_{e^{n}}\right)\right)<br>\end{array}<br>$$<br>其中的$\sigma$ 是$\operatorname{tanh}$. $\oplus$ 代表Concat操作. 出于可行性, 作者<strong>限制</strong>了邻居的采样个数.</p><blockquote><p>将该实体对应在图中, 这个操作其实本质上就是<strong>图聚合</strong>.</p></blockquote><p>对于实体对$(e_1, e_2)$ 中的两个实体本身也需要被编码, 只考虑用前馈神经网络简单的进行编码即可:<br>$$<br>\begin{array}{l}<br>f_{2}\left(v_{e}\right)=W_{2}\left(v_{e}\right)+b_{2} \\<br>u_{e p}=\sigma\left(f_{2}\left(v_{e_{1}}\right) \oplus f_{2}\left(v_{e_{2}}\right)\right)<br>\end{array}<br>$$<br>最后将计算出的实体对编码和实体对中实体的邻居编码Concat起来, 得到$e_1, e_2$ 之间的关系表示$x_{(e_1, e_2)}$:<br>$$<br>x_{\left(e_{1}, e_{2}\right)}=u_{e_{1}} \oplus u_{e p} \oplus u_{e_{2}}<br>$$<br>上述过程中$W_1 \in R^{d \times 2d}, W_2 \in R^{d \times d}, b_1,b_2 \in R^d$ 均为可以学习的参数.</p><h4 id="Pretrained-Strategy"><a href="#Pretrained-Strategy" class="headerlink" title="Pretrained Strategy"></a>Pretrained Strategy</h4><p>作者指出, 预训练的关键是学习到了簇状结构数据的分布, 一般具有簇内的高相似度和簇外的低相似度. 对于每个关系$r_s$, 在每个Training Step中, 采样以下三种三元组:</p><ul><li>$\left\{e_{1}^{\star}, r_{s}, e_{2}^{\star}\right\}$: 直接<strong>无差别</strong>的随机从KG中选择与$r_s$ 相关的三元组, 称为<strong>参考三元组</strong>.</li><li>$\left\{e_{1}^{+}, r_{s}, e_{2}^{+}\right\}$: 从训练集中, 采样包含关系$r_s$ 的<strong>正例三元组</strong>.</li><li>$\left\{e_{1}^{+}, r_{s}, e_{2}^{-}\right\}$: 从其余的训练集中, 做替换尾实体的<strong>负采样</strong>, 称为<strong>负例三元组</strong>.</li></ul><p>通过Feature Encoder能生成参考三元组的真实关系表示$x_{(e_1^{\star}, e_2^{\star})}$, 然后分别计算参考三元组与正例负例三元组之间的<strong>余弦相似度</strong>:<br>$$<br>\begin{aligned}<br>score^+_\omega &amp;=\operatorname{cosine}(x_{(e_1^{\star}, e_2^{\star})}, x_{(e_1^{+}, e_2^{+})}) \\<br>score^-_\omega &amp;=\operatorname{cosine}(x_{(e_1^{\star}, e_2^{\star})}, x_{(e_1^{+}, e_2^{-})})<br>\end{aligned}<br>$$<br>那么最终目标就是<strong>最大化间隔</strong>:<br>$$<br>L_{\omega}=\max \left(0, \gamma+\operatorname{score}_{\omega}^{+}-\operatorname{score}_{\omega}^{-}\right)<br>$$</p><p>其中$\gamma$ 是间隔, $\omega$ 是模型中涉及到的所有可学习参数. 通过计算余弦相似度, Feature Encoder能尽可能的将实体之间的关系<strong>聚类</strong>, 从而生成到作者所说的<strong>簇状</strong>结构数据.</p><h3 id="Generative-Adversarial-Model"><a href="#Generative-Adversarial-Model" class="headerlink" title="Generative Adversarial Model"></a>Generative Adversarial Model</h3><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg3.jpg" style="zoom:50%"><h4 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h4><p>生成器的作用是从<strong>嘈杂</strong>的文本$T_r$ 中生成伪造的Relation Embedding. 但因为文本中经常伴随着非常多的停止词之类的<strong>无意义词语</strong>, 所以作者简单的<strong>去除停止词和标点</strong>, 并使用<strong>TF - IDF</strong>来分配词语的权重. 词向量直接使用<strong>Word2Vec</strong>将词语转化为稠密向量. 在Sentence Level Modeling上, 作者使用无视语序的<strong>词袋模型</strong>对句子建模.</p><blockquote><p>至于为什么作者没有在词向量上使用BERT, 在后文的实验中作者做了探究.</p></blockquote><p>Generator在生成数据时, 一般都需要加入一些<strong>噪声</strong>. 在这里, 作者加入高斯随机噪声$z \in R^Z$, $z$ 是从高斯分布$N(0, 1)$ 中采样的来的向量.</p><p>作者将高斯噪声$z$ 和TF - IDF后的句向量Concat起来, 经过两个FC层和一个Layer Norm, 最后得到生成器$G$ 通过文本生成的Relation Embedding $\tilde{x}_{r}$, 即$\tilde{x}_{r} \leftarrow G_{\theta}\left(T_{r}, z\right)$, 其中$\theta$ 是参数.</p><p>对于GAN的训练方面, 为了避免<strong>模型崩溃</strong>并<strong>增强多样性</strong>(在推荐阅读中, 有解释GAN训练上出现的常见问题), 作者使用了WGAN中的Wasserstein Loss.</p><p>作者继续添加了分类损失, 其形式与Feature Encoder中使用的最大化间隔损失类似, 计算它分别与正例(在GAN训练时正例指$\tilde{x}_{r}$)和负例三元组之间的相似度, 但作者将<strong>簇中心</strong>$x_c^r$ 作为真实的关系表示:<br>$$<br>x_{c}^{r}=\frac{1}{N_{r}} \sum_{i=1}^{N_{r}} x_{\left(e_{1}, e_{2}\right)}^{i}<br>$$<br>其中$N_r$ 为涉及到关系$r_s$ 所有的三元组个数.</p><p>那么分类损失可以被写成:<br>$$<br>\begin{aligned}<br>score^+_\omega &amp;=\operatorname{cosine}(x_{c}^r, \tilde x_r) \\<br>score^-_\omega &amp;=\operatorname{cosine}(x_{c}^r, x_{(e_1^{+}, e_2^{-})}) \\<br>L_{cls}\left(G_{\theta}\left(T_{r}, z\right)\right)&amp;=\max \left(0, \gamma+\operatorname{score}_{\omega}^{+}-\operatorname{score}_{\omega}^{-}\right)<br>\end{aligned}<br>$$<br>最后, 作者还添加了Visual Pivot Regularization, 用于增加类内的区别.</p><p>生成器的损失函数如下:</p><p>$$<br>L_{G_{\theta}}=-\mathbb{E}_{z \sim p_{z}}\left[D_{\phi}\left(G_{\theta}\left(T_{r}, z\right)\right)\right] +L_{c l s}\left(G_{\theta}\left(T_{r}, z\right)\right)+L_{P}<br>$$<br>第一项是Wasserstein Loss, 第二项是Classification Loss, 第三项是Visual Pivot Regularization.</p><h4 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h4><p>判别器的作用是用于识别输入是否是伪造的. 生成器的结构比较简单, 只由一层使用Leaky ReLU的FC层, 接上Layer Norm组成, 最后结果分别用于判别真假和对关系分类, 损失函数如下:</p><p>$$<br>L_{D_{\phi}}=\mathbb{E}_{z \sim p_{z}}\left[D_{\phi}\left(G_{\theta}\left(T_{r}, z\right)\right)\right]-\mathbb{E}_{x \sim p_{\text {data}}}\left[D_{\phi}(x)\right]<br>+\frac{1}{2} L_{c l s}\left(G_{\theta}\left(T_{r}, z\right)\right)+\frac{1}{2} L_{c l s}(x)+L_{G P}<br>$$<br>第一二项仍然来自于Wasserstein Loss, 第三四项来源于分类, 分别对应着生成器的假数据$\tilde{x}_{r}$ 和Feature Encoder生成的真实数据$x_{(e_1, e_2)}$, 最后一项是梯度惩罚项.</p><blockquote><p>GAN相关的细节还不太懂, 不瞎解释了.</p></blockquote><h4 id="GAN-Training-Process"><a href="#GAN-Training-Process" class="headerlink" title="GAN Training Process"></a>GAN Training Process</h4><p>在讲解完生成器和判别器后, 作者将GAN训练流程总结如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg4.jpg" style="zoom:50%"><p>在GAN中, 通常采用多次更新判别器参数后只更新一次生成器的策略.</p><h3 id="Predicting-Unseen-Relations"><a href="#Predicting-Unseen-Relations" class="headerlink" title="Predicting Unseen Relations"></a>Predicting Unseen Relations</h3><p>在训练完GAN后, 生成器对于一个没有见过的关系描述文本$T_{r_u}$ 应该能给出合理的Relation Embedding, 即$\tilde{x}_{r_u} \leftarrow G_{\theta}\left(T_{r_u}, z\right)$. 在已知$(e_1, r_u)$ 的情况下, 我们应该根据生成器所生成的$\tilde{x}_{r_u}$ 与Feature Encoder产生的$x_{(e_1, e_2)}$ 的余弦相似度来评估计排名:<br>$$<br>\operatorname{score}_{\left(e_{1}, r_{u}, e_{2}\right)}=\operatorname{cosine}\left(\tilde{x}_{r_u}, x_{(e_1, e_2)}\right)<br>$$<br>但生成器会为生成的数据添加<strong>噪声</strong>, 为了尽可能弱化随机造成的影响, 作者采用生成多组数据最后取平均的方法计算得分:</p><p>$$<br>\operatorname{score}_{\left(e_{1}, r_{u}, e_{2}\right)}=\frac{1}{N_{\text {test}}} \sum_{i=1}^{N_{\text {test}}} \text {score}_{\left(e_{1}, r_{u}, e_{2}\right)}^{i}<br>$$</p><p>即生成任意数量$N_{test}$ 的Relation Embedding$\left\{\tilde{x}_{r_{u}}^{i}\right\}_{i=1,2, \dots, N_{\text {test}}}$, 最后取平均余弦相似度作为真正的得分.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>在本节中, 详细的参数设置请参考原论文.</p><h3 id="DataSet"><a href="#DataSet" class="headerlink" title="DataSet"></a>DataSet</h3><p>作者发现没有可用的ZS数据集, 所以作者自己根据需要制作了两个数据集:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg5.jpg" style="zoom:50%"><p>作者选取数据集的标准是, 满足<strong>大规模</strong>, 并含有<strong>关系文本描述</strong>.</p><h3 id="Baselines"><a href="#Baselines" class="headerlink" title="Baselines"></a>Baselines</h3><p>在非常普遍使用的KGE方法中, 它们基本<strong>不具备</strong>Zero - Shot的能力, 因为对于没有见过的关系, 在它们所存储的Embedding矩阵中是查询不到的, 所以作者用与Generator类似的方法为它们添加了Zero - Shot的能力: 使用一个与Generator类似的神经网络结构, 而不是直接为未知的关系生成随机的Relation Embedding. 在这个条件下, 模型能够直接根据文本信息生成未见过关系的Embedding, 然后继续结合它们原来的目标函数来调整Entity Embedding和与Generator类似的结构的参数.</p><p>例如, 在TransE中, Entity Embedding和Relation Embedding都是使用一个Look Up Table存储的:<br>$$<br>f_{\text {Trans} E}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})=\left|v_{h}+v_{r}-v_{t}\right|_{1 / 2}<br>$$<br>在经过改造后, 它们的Relation Embedding不再通过Look Up Table给出, 而是通过类似生成器的结构$g$ 从文本$T_r$ 中生成:<br>$$<br>v_{r}=g\left(T_{r}\right)<br>$$<br>在对实体排名时, 也是按照它们原本的打分函数进行排名.</p><p>对于DisMult, ComplEx亦是如此. RESCAL都没有替换Relation Embedding的位置, 所以就不对它进行比较了.</p><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>作者将改进后的Zero - Shot模型在自己制作的数据集NELL - ZS和Wiki - ZS上测试了它们Link Prediction的能力, 结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg6.jpg" style="zoom:33%"><p>其中ZSGAN代表使用了GAN训练框架, 即在之前的基础上加入了判别器, 并引入GAN相关的训练损失.下划线代表该结果在ZSGAN中是最棒的.</p><p>能从结果中观察到, 所有使用ZSGAN的模型都比未使用GAN的Baseline效果要好, 并且在这些模型中, DisMult体现出更好的能力.</p><h3 id="Analysis-of-Textual-Representations"><a href="#Analysis-of-Textual-Representations" class="headerlink" title="Analysis of Textual Representations"></a>Analysis of Textual Representations</h3><h4 id="Text-Descriptions-Analysis"><a href="#Text-Descriptions-Analysis" class="headerlink" title="Text Descriptions Analysis"></a>Text Descriptions Analysis</h4><p>作者将自制的两个数据集中的关系文本描述词频统计了出来:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg7.jpg" style="zoom:50%"><p>NELL - ZS的文本长度明显没有Wiki - ZS高.</p><p>在经过TF - IDF过滤后, 作者统计了TF - IDF &gt; 0.3的词语个数:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg8.jpg" style="zoom:50%"><p>在使用了TF - IDF后, 大多数重要的词语都落在$[2, 5]$ 区间内, 说明TF - IDF能够比较有效的降噪.</p><h4 id="Word-Representations"><a href="#Word-Representations" class="headerlink" title="Word Representations"></a>Word Representations</h4><p>作者其实尝试过现在非常流行的词向量表示BERT(Transformer Encoder):</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg10.jpg" style="zoom:50%"><p>但实际上效果不理想, 作者认为其中与以下原因有关:</p><ol><li>BERT引入了更多的<strong>句子级噪声</strong>, 在这个任务上似乎句子中的信息是无效的.</li><li>BERT产生的Word Embedding<strong>维度过高</strong>, 不利于GAN的训练.</li></ol><blockquote><p>我认为跟BERT的打开方式有一定的关联, Self - Attention本身就会根据句子中的其他内容来调整自身的表达, 跟TF - IDF的功能有一部分重复的地方.</p></blockquote><h3 id="Quality-of-Generated-Data"><a href="#Quality-of-Generated-Data" class="headerlink" title="Quality of Generated Data"></a>Quality of Generated Data</h3><p>作者为了评估生成器所生成的Relation Embedding的质量, 作者计算Feature Encoder生成的簇中心$x_r^c$ 和生成器生成的关系嵌入$\tilde x_r$ 之间的<strong>余弦相似度</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/ganzslforkg9.jpg" style="zoom:50%"><p>能看到, 生成器所生成的关系嵌入的余弦相似度基本与模型的MRR和Hits@10表现成正比.</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>作者尝试过类似CNN, LSTM对Sentence建模的方法, 但都失败了. 作者认为这些方法都引入了更多的参数, 从而不利于GAN的学习, 会导致GAN的过拟合. 所以对句子建模只是使用简单的使用词袋模型, 结合TF - IDF. 此外, 现在作者方法中的实体均为闭集, 将来会考虑到实体在开集中的处理.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>本文非常巧妙的想到用GAN结合KGE处理在未见过的关系上的问题. 作者通过使用Feature Encoder来构造真实的数据分布, 并通过一个简单的生成器来伪造数据, 当生成器能够很好的骗过判别器后, 直接使用生成器生成的Relation Embedding近似当做真实的Relation Embedding.</p><p>作者声称, 这是在KG领域的首个Zero - Shot关系学习方法.</p><p>抛开作者提出的方法本身不谈, 就作者在论文中提到关于GAN的内容来说, 有很大一部分是关于GAN的<strong>训练Trick</strong>. GAN虽然是一个非常好的idea. 但<strong>GAN的训练</strong>可能是一个很大的问题, 这点在实验结果中也多次提到, 在模型中引入的其他部分都有可能会对GAN的训练产生很大影响, 导致训练的不稳定.</p><h2 id="Recommended"><a href="#Recommended" class="headerlink" title="Recommended"></a>Recommended</h2><p>关于本文的:</p><ul><li><a href="https://www.bilibili.com/video/av541082248/" target="_blank" rel="noopener">AAAI2020丨知识图的生成性对抗式零样本关系学习</a></li><li><a href="https://zhuanlan.zhihu.com/p/112908641" target="_blank" rel="noopener">《基于对抗生成的Zero-Shot知识图谱关系学习》阅读笔记</a></li></ul><p>关于文中涉及到的GAN:</p><ul><li><a href="https://zhuanlan.zhihu.com/p/25071913" target="_blank" rel="noopener">令人拍案叫绝的Wasserstein GAN</a></li><li><a href="https://zhuanlan.zhihu.com/p/68120231" target="_blank" rel="noopener">提高GAN训练稳定性的9大tricks</a></li><li><a href="https://zhuanlan.zhihu.com/p/84617531" target="_blank" rel="noopener">Wasserstein距离学习笔记</a></li><li><a href="https://zhuanlan.zhihu.com/p/33752313" target="_blank" rel="noopener">通俗理解生成对抗网络GAN</a></li></ul></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/62547.html">https://ADAning.github.io/posts/62547.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/GAN/"><span class="chip bg-color">GAN</span> </a><a href="/tags/ZSL/"><span class="chip bg-color">ZSL</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/57546.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/medias/featureimages/7.jpg" class="responsive-img" alt="Can We Predict New Facts with Open Knowledge Graph Embeddings?"> <span class="card-title">Can We Predict New Facts with Open Knowledge Graph Embeddings?</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Can We Predict New Facts with Open Knowledge Graph Embeddings? A Benchmark for Open Link Prediction本文是论文Can We Predict N</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-12-13 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></span></div></div><div class="card-action article-tags"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/OKG/"><span class="chip bg-color">OKG</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/2954.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/medias/featureimages/0.jpg" class="responsive-img" alt="R-MeN: A Relational Memory-based Embedding Model"> <span class="card-title">R-MeN: A Relational Memory-based Embedding Model</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: Self - Attention: 详见Transformer精讲. 2020.12.14: 修正错误. A Relational Memory-based Embedding Model for Triple Cl</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-12-10 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></span></div></div><div class="card-action article-tags"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/Attention/"><span class="chip bg-color">Attention</span> </a><a href="/tags/%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">记忆网络</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">308.9k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io@master/libs/instantpage/instantpage.js" type="module"></script></body></html>