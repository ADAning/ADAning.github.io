<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="机器学习之XGBoost, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>机器学习之XGBoost | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/1.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">机器学习之XGBoost</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"><span class="chip bg-color">决策树</span> </a><a href="/tags/XGB/"><span class="chip bg-color">XGB</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">机器学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-08-16</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-03-27</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.8k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 12 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h1><p><code>XGBoost</code>是<code>Extreme Gradient Boosting</code>的缩写, 作者是陈天奇大神. XGB因为其高准确率, 易于使用而在各类数据科学竞赛譬如Kaggle, 天池等十分流行. XGB与GBDT十分相似, 可以将XGB视为是GBDT的一个优化形式. 事实上, 如果不考虑工程实现和解决问题上的一些差异, XGB与GBDT比较大的不同就是目标函数的定义.</p><h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><h3 id="模型和参数"><a href="#模型和参数" class="headerlink" title="模型和参数"></a>模型和参数</h3><p>对于最为常见而简单的线性模型来说, 其预测值为:<br>$$<br>\hat{y}_i = \sum_j \theta_j x_{ij}<br>$$<br>对不同的任务和模型来说, $\theta$ 有着不同的含义. 这个$\theta$ 是模型中不确定的部分, 我们需要通过反复学习来调整它使得它趋近于最优.</p><h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>对于一般的任务来说, 在训练时就是要找到一个最优参数$\theta$ 使得预测的效果最好. 定义一个目标函数来衡量与训练数据的拟合程度.<br>$$<br>\text{obj}(\theta) = L(\theta) + \Omega(\theta)<br>$$<br>其中$L$ 是训练损失函数, $\Omega$ 是正则项. 一般来说损失函数有多种选择, 例如大多数梯度提升算法的MSE:<br>$$<br>L(\theta) = \sum_i (y_i-\hat{y}_i)^2<br>$$<br>或者Logistics损失:<br>$$<br>L(\theta) = \sum_i[ y_i\ln (1+e^{-\hat{y}_i}) + (1-y_i)\ln (1+e^{\hat{y}_i})]<br>$$<br>正则项的作用是通过约束模型的复杂度而避免过拟合, 一个模型过于复杂时, 它的泛化能力会被约束, 当预测新的没见过的数据时能力会大打折扣. 换言之, 一个好的模型会在方差和偏差之间达到平衡.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/xgb正则项.png" style="zoom:67%"><p>L1正则:<br>$$<br>\Omega(w)=\sum_i^W|w_i|<br>$$<br>L2正则:<br>$$<br>\Omega(w)=\sum_i^Ww_i^2<br>$$</p><h2 id="回归树-CART"><a href="#回归树-CART" class="headerlink" title="回归树 CART"></a>回归树 CART</h2><p>CART(Classification And Regression Tree)是XGB的基学习器. 在XGB官网上给出了一个讲解CART回归树的例子, 利用CART来预测谁会玩电脑游戏.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/xgbcart.png" style="zoom:50%"><p>CART利用输入的特征来划分输入样本, 并在每个叶子节点上都有一个预测权重, 这与分类决策树有些不同.</p><p>树每次进行划分, 实际上是将搜索空间进行分割:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/xgbcart示例.png" style="zoom:33%"><p>通常, 一棵树的预测能力不够强大, 所以需要将多棵树集成起来.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/xgbtwocart.png" style="zoom:50%"><p>将这两棵树的得分都加起来, 发现小男孩的得分是最高的. 事实上这两棵树在做互补的工作. 假设我们有$K$ 棵树, 分类函数为$f$, $\mathcal {F}$ 是包含所有回归树的函数空间, 那么对于第$i$ 类最终的预测值$\hat{y_i}$为:<br>$$<br>\hat{y}_i = \sum_{k=1}^K f_k(x_i), f_k \in \mathcal{F}<br>$$<br>最终的目标函数就变成了:<br>$$<br>\text{obj}(\theta) = \sum_i^n l(y_i, \hat{y}_i) + \sum_{k=1}^K \Omega(f_k)<br>$$<br>我们必须要求出来的其实就是$f_k$, 一旦有了这个函数, 就能得知树的结构和叶子节点所对应的权值.</p><p>回归树的优势:</p><ul><li>应用广泛，比如 GBM 和随机森林等。几乎一半的数据挖掘比赛获胜者都是靠树的集成方法取胜的</li><li>你不需要将特征标准化，因为做不做输入特征缩放结果是一样的.</li><li>能够学习到更多特征之间的高阶关系.</li><li>具有可扩放行(scalable)，应用于工业界.</li></ul><h2 id="树的提升"><a href="#树的提升" class="headerlink" title="树的提升"></a>树的提升</h2><p>前面已经介绍完了基学习器, 接下来该说说如何训练它们了. 对于时间步$t$, 目标函数就变成了:<br>$$<br>\text{obj} = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t)}) + \sum_{i=1}^t\Omega(f_i)<br>$$</p><h3 id="增量训练"><a href="#增量训练" class="headerlink" title="增量训练"></a>增量训练</h3><p>在XGB中, 作者指出学习树的结构比传统优化问题要困难得多, 并且一次性的学习到所有树结构很难, 所以在这里采用了<strong>一次向上加一棵树</strong>的策略:<br>$$<br>\begin{split}\hat{y}_i^{(0)} &amp;= 0\\<br>\hat{y}_i^{(1)} &amp;= f_1(x_i) = \hat{y}_i^{(0)} + f_1(x_i)\\<br>\hat{y}_i^{(2)} &amp;= f_1(x_i) + f_2(x_i)= \hat{y}_i^{(1)} + f_2(x_i)\\<br>&amp;\dots\\<br>\hat{y}_i^{(t)} &amp;= \sum_{k=1}^t f_k(x_i)= \hat{y}_i^{(t-1)} + f_t(x_i)\end{split}<br>$$<br>这实际上使得XGB每次都去拟合<strong>残差</strong>, 也就是预测值和真实值之间的差.</p><p>在每次训练都要优化目标函数:<br>$$<br>\begin{split}\text{obj}^{(t)} &amp; = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t)}) + \sum_{i=1}^t\Omega(f_i) \\<br>&amp; =\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)+\Omega\left(f_{t}\right)+\text { constant }\end{split}<br>$$<br>假设MSE为损失函数, 代入目标函数式:<br>$$<br>\begin{split}\text{obj}^{(t)} &amp; = \sum_{i=1}^n \left(y_i - (\hat{y}_i^{(t-1)} + f_t(x_i))\right)^2 + \sum_{i=1}^t\Omega(f_i) \\<br>&amp; = \sum_{i=1}^n [2(\hat{y}_i^{(t-1)} - y_i)f_t(x_i) + f_t(x_i)^2] + \Omega(f_t) + \mathrm{constant}\end{split}<br>$$<br>这里的$\hat{y}_i^{(t-1)} - y_i$就是上一轮的残差. 这里MSE体现出非常好的数学性质, 它既含有$f_t(x_i)$ 的一次项, 也含有二次项, 这对求出新树结构非常有帮助. 但是对于其他损失函数不一定能够获得这么好的数学性质, 因此一般都是通过泰勒展开来获得这个一次项和二次项. 不知你还记得不记得二阶泰勒展开:<br>$$<br>f(x+\Delta x) \approx f(x)+f^{\prime}(x) \Delta x+\frac{1}{2} f^{\prime \prime}(x) \Delta x^{2}<br>$$<br>因为我们每过一个时间步$t$ 拟合的都是残差, 所以我们可以把新加入的$f_t(x_i)$ 看做是$\Delta x$, $\hat{y}_{i}^{(t-1)}$ 看做是$x$, 就能将损失函数展开:<br>$$<br>l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)=l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)<br>$$<br>其中的$g_i$ 和$h_i$ 分别是$f_t(x_i)$ 的一阶偏导和二阶偏导:<br>$$<br>\begin{split}g_i &amp;= \frac{\partial l(y_i, \hat{y}_i^{(t-1)})}{\partial{\hat{y}_i^{(t-1)}}}\\<br>h_i &amp;= \frac{\partial l(y_i, \hat{y}_i^{(t-1)})}{\partial^2{\hat{y}_i^{(t-1)}}} \end{split}<br>$$<br>注: 这步能够展的原因是$y_i$ 是一个常数, 其实$l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)$ 只是一个与$\hat{y}_{i}^{(t-1)}$ 和$f_t(x_i)$ 相关的函数.</p><p>目标函数就变成了:<br>$$<br>\begin{split}<br>\text{obj}^{(t)} &amp; = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t)}) + \sum_{i=1}^t\Omega(f_i) \\<br>&amp; =\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)+\Omega\left(f_{t}\right)+\text { constant } \\<br>&amp; = \sum_{i=1}^n [l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t) + \mathrm{constant}<br>\end{split}<br>$$<br>对于每个新的时间步$t$, 上一个时间步$t-1$所对应的损失$l(y_i, \hat{y}_i^{(t-1)})$是一个常数, 去掉目标函数中所有与优化无关的常数部分:<br>$$<br>\sum_{i=1}^n [g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t)<br>$$</p><h3 id="模型复杂度"><a href="#模型复杂度" class="headerlink" title="模型复杂度"></a>模型复杂度</h3><p>XGB在正则项这里对树模型的生长加以约束. 对于树模型, $T$ 为叶子节点的总数, 设$w$ 为叶子节点的权重序列, 是一个$T$ 维的向量, $q$ 为树的结构, 那么$q(x)$ 就能表示样本$x$ 落在叶子中的位置, $w_{q(x)}$ 就是叶子中样本$x$ 所对应的权重. $d$ 为输入实例的维数.<br>$$<br>f_t(x) = w_{q(x)}, w \in R^T, q:R^d\rightarrow \{1,2,\cdots,T\}<br>$$<br>例如:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/xgb复杂度.png" style="zoom:33%"><p>在XGB中, 定义正则项如下:<br>$$<br>\Omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2<br>$$<br>第一项为叶子节点的数目, 第二项为叶子节点权重的L2范数. 那么在上面那个例子中, 正则项$\Omega$ 为:<br>$$<br>\Omega = 3\gamma + \frac{1}{2}\lambda(4+0.01+1)<br>$$<br>假设用$I_j = \{i|q(x_i)=j\}$ 来表示叶子节点$j$ 的样本集, 其中包含叶子$j$ 的所有样本$x_i$. 将其从$i$ 表示转化为用$j$ 表示的形式:<br>$$<br>\begin{split}<br>\text{obj}^{(t)} &amp; \approx \sum_{i=1}^{n}\left[g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right) \\<br>&amp;=\sum_{i=1}^{n}\left[g_{i} w_{q\left(x_{i}\right)}+\frac{1}{2} h_{i} w_{q\left(x_{i}\right)}^{2}\right]+\gamma T+\gamma \frac{1}{2} \sum_{j=1}^{T} w_{j}^{2} \\<br>&amp;=\sum_{j=1}^{T}\left[\left(\sum_{i \in I_{j}} g_{i}\right) w_{j}+\frac{1}{2}\left(\sum_{i \in I_{j}} h_{i}+\gamma\right) w_{j}^{2}\right]+\gamma T\end{split}<br>$$<br>并定义$G_j = \sum_{i\in I_j} g_i ,\quad H_j = \sum_{i\in I_j} h_i$, 则原目标函数又可以写为:<br>$$<br>\text{obj}^{(t)} = \sum^T_{j=1} [G_jw_j + \frac{1}{2} (H_j+\lambda) w_j^2] +\gamma T<br>$$<br>树的结构如果是已经固定的, $G_j$ 和 $H_j$ 就是可以计算的了. 此时目标函数就是一个关于$w_j$ 的一元二次方程, 直接利用最值公式得解:<br>$$<br>\begin{split}w_j^\ast &amp;= -\frac{G_j}{H_j+\lambda}\\<br>\text{obj}^\ast &amp;= -\frac{1}{2} \sum_{j=1}^T \frac{G_j^2}{H_j+\lambda} + \gamma T\end{split}<br>$$<br>下面是一个计算$\text{obj}$ 的例子:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/xgbstruct_score.png" style="zoom:67%"><p>分数越小, 结构就越好.</p><h3 id="学习树结构"><a href="#学习树结构" class="headerlink" title="学习树结构"></a>学习树结构</h3><p>优化工作已经基本做完了, 但是还没有提到如何确定一棵树的结构. XGB使用了和CART回归树一样的想法, 遍历所有特征的所有特征划分点, 但使用的目标函数不一样. 利用贪心算法, 不断地枚举不同树的结构, 然后利用打分函数来寻找出一个最优结构的树, 接着加入到模型中, 不断重复. 叶子分裂也是依赖于分裂前后的$\text{obj}$ 而决定的. 分裂后需要检测这次分裂是否会给损失函数带来增益:<br>$$<br>\begin{split}<br>Gain &amp;= \text{obj}_{L+R} - (\text{obj}_L + \text{obj}_R) \\<br>&amp; = [-\frac{1}{2} \frac{(G_L+G_R)^2}{H_L+H_R+\lambda}+\gamma] - [-\frac{1}{2} (\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda})+ 2\gamma ] \\<br>&amp;=\frac{1}{2} \left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}\right] - \gamma<br>\end{split}<br>$$<br>分裂前后的信息$Gain$ 是如何理解的? $Gain$ 实际上是<strong>分裂后的信息减去了分裂包含的信息</strong>, 也就是目标函数$Obj$ 的相反数. 不分裂则视$L+R$ 为一个整体. 所以才有了$Gain$ 中的第三项.</p><p>如果分裂后$Gain&gt;0$ , 说明这次分裂能够使得目标函数下降. 如果$Gain&lt;0$, 说明分裂不能使得目标函数下降, 这次分裂失败了.</p><p>找到最优分枝点的有效方法其实就是<strong>在排序后的实例上从左到右线性地扫描</strong>, 这样就足以决定按此特征的最佳分割. 以年龄作为特征为例:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/xgb扫描.png" style="zoom:67%"><p>只要求出每一边的$G$ 和$H$ 的和, 然后计算$Gain$, 就能找到分枝点.</p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>XGB用Python就可以非常简单的使用.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> xgboost <span class="token keyword">as</span> xgb
<span class="token comment" spellcheck="true"># read in data</span>
dtrain <span class="token operator">=</span> xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span><span class="token string">'demo/data/agaricus.txt.train'</span><span class="token punctuation">)</span>
dtest <span class="token operator">=</span> xgb<span class="token punctuation">.</span>DMatrix<span class="token punctuation">(</span><span class="token string">'demo/data/agaricus.txt.test'</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># specify parameters via map</span>
param <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'max_depth'</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'eta'</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'objective'</span><span class="token punctuation">:</span><span class="token string">'binary:logistic'</span> <span class="token punctuation">}</span>
num_round <span class="token operator">=</span> <span class="token number">2</span>
bst <span class="token operator">=</span> xgb<span class="token punctuation">.</span>train<span class="token punctuation">(</span>param<span class="token punctuation">,</span> dtrain<span class="token punctuation">,</span> num_round<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># make prediction</span>
preds <span class="token operator">=</span> bst<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>dtest<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/xgb%E6%8E%A8%E5%AF%BC%E6%8C%87%E7%A4%BA%E5%9B%BE.jpeg" alt=""></p><ul><li><a href="https://xgboost.readthedocs.io/" target="_blank" rel="noopener">XGBoost官方文档</a> - 强推</li><li><a href="https://arxiv.org/pdf/1603.02754v1.pdf" target="_blank" rel="noopener">XGBoost论文</a></li><li><a href="https://www.yuque.com/agoclover/ml/axgv87" target="_blank" rel="noopener">这篇博客</a>也翻译的非常非常棒, 可以多读一下.</li><li>在知乎高赞中曾经有一篇文章写的不错, 原作者的博客已经无法使用了, 但在CSDN上有人曾<a href="https://blog.csdn.net/zhaojc1995/article/details/83094853" target="_blank" rel="noopener">转载</a>过.</li><li><a href="https://mp.weixin.qq.com/s?__biz=MzI1MzY0MzE4Mg==&mid=2247485159&idx=1&sn=d429aac8370ca5127e1e786995d4e8ec&chksm=e9d01626dea79f30043ab80652c4a859760c1ebc0d602e58e13490bf525ad7608a9610495b3d&scene=21" target="_blank" rel="noopener">20道XGB面试题</a></li><li><a href="[https://yuanxiaosc.github.io/2019/09/30/XGBoost%E7%9A%84%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%89%8B%E5%86%8C/](https://yuanxiaosc.github.io/2019/09/30/XGBoost的工程师手册/)">XGBoost的工程师手册</a></li></ul></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/36969.html">https://ADAning.github.io/posts/36969.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"><span class="chip bg-color">决策树</span> </a><a href="/tags/XGB/"><span class="chip bg-color">XGB</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/26379.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/18.jpg" class="responsive-img" alt="NLP相关知识"> <span class="card-title">NLP相关知识</span></div></a><div class="card-content article-content"><div class="summary block-with-text">2020.08.24: 更新word2vec的部分内容. NLP相关知识整个流程: 分词 Tokenize -&gt; 预处理 Preprocess -&gt; 特征工程 Feature engine -&gt; ML. 分词 Tok</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-08-17 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">机器学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/NLP/"><span class="chip bg-color">NLP</span> </a><a href="/tags/%E8%AF%8D%E8%A2%8B%E6%A8%A1%E5%9E%8B/"><span class="chip bg-color">词袋模型</span> </a><a href="/tags/Word2Vec/"><span class="chip bg-color">Word2Vec</span> </a><a href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/"><span class="chip bg-color">特征工程</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/60644.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/15.jpg" class="responsive-img" alt="机器学习之随机森林"> <span class="card-title">机器学习之随机森林</span></div></a><div class="card-content article-content"><div class="summary block-with-text">随机森林 Random Forest在集成学习中曾经提到过, Bagging + 决策树 = 随机森林. 这点很重要. Bagging(Bootstrap aggregating)并行训练多个同质弱学习器, 在取数据集时使用Boostra</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-08-15 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">机器学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/"><span class="chip bg-color">集成学习</span> </a><a href="/tags/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97/"><span class="chip bg-color">随机森林</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">405.9k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>