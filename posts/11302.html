<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="机器学习之决策树, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>机器学习之决策树 | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/11.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">机器学习之决策树</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"><span class="chip bg-color">决策树</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">机器学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-08-07</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-04-03</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.8k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 10 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p><strong>2020.09.08</strong>: 更新了剪枝.</p></blockquote><h1 id="决策树DT-Desicion-Tree"><a href="#决策树DT-Desicion-Tree" class="headerlink" title="决策树DT Desicion Tree"></a>决策树DT Desicion Tree</h1><p>决策树(Decision Tree) 是在已知各种情况发生概率的基础上, 通过构成决策树来求取净现值的期望值大于等于零的概率, 评价项目风险, 判断其可行性的决策分析方法, 是直观运用概率分析的一种图解法. 由于这种决策分支画成图形很像一棵树的枝干, 故称决策树. 在机器学习中, 决策树是一个预测模型, 他代表的是对象属性与对象值之间的一种映射关系. Entropy = 系统的凌乱程度, 使用算法ID3, C4.5和C5.0生成树算法使用熵. 这一度量是基于信息学理论中熵的概念. 决策树是一种<strong>树形结构</strong>, 其中每个内部节点表示一个属性上的测试, 每个分支代表一个测试输出, 每个叶节点代表一种类别.</p><h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><p>决策树分为两种, 也就是按照它们功能进行区分的, 回归树和分类树. 决策树作为树类模型, 不依赖于特征的离散或连续, 树的分裂仅取决于分裂时的判断条件, 与特征的离散或连续性无关.</p><blockquote><ol><li><strong>根结点</strong>(Root Node): 它表示整个样本集合, 并且该节点可以进一步划分成两个或多个子集.</li><li><strong>拆分</strong>(Splitting): 表示将一个结点拆分成多个子集的过程.</li><li><strong>决策结点</strong>(Decision Node): 当一个子结点进一步被拆分成多个子节点时, 这个子节点就叫做决策结点.</li><li><strong>叶子结点</strong>(Leaf/Terminal Node): 无法再拆分的结点被称为叶子结点.</li><li><strong>剪枝</strong>(Pruning): 移除决策树中子结点的过程就叫做剪枝, 跟拆分过程相反.</li><li><strong>分支/子树</strong>(Branch/Sub-Tree): 一棵决策树的一部分就叫做分支或子树.</li><li><strong>父结点和子结点</strong>(Paren and Child Node): 一个结点被拆分成多个子节点, 这个结点就叫做父节点；其拆分后的子结点也叫做子结点.</li></ol></blockquote><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/决策树.png" style="zoom:67%"><h2 id="构造过程"><a href="#构造过程" class="headerlink" title="构造过程"></a>构造过程</h2><p>决策树的构造过程一般分为3个部分, 分别是特征选择, 决策树生产和决策树裁剪.</p><ol><li><p><strong>特征选择</strong></p><p>特征选择表示从众多的特征中选择一个特征作为当前节点分裂的标准, 如何选择特征有不同的量化评估方法, 从而衍生出不同的决策树, 如ID3(通过信息增益选择特征) , C4.5(通过信息增益比选择特征) , CART(通过Gini指数选择特征) 等.</p><p>目的(准则) : 使用某特征对数据集划分之后, 各数据子集的纯度要比划分钱的数据集D的纯度高(也就是不确定性要比划分前数据集D的不确定性低.</p></li><li><p><strong>决策树的生成</strong></p><p>根据选择的特征评估标准, 从上至下递归地生成子节点, 直到数据集不可分则停止决策树停止生长. 这个过程实际上就是使用满足划分准则的特征不断的将数据集划分成纯度更高, 不确定行更小的子集的过程. 对于当前数据集的每一次划分, 都希望根据某个特征划分之后的各个子集的纯度更高, 不确定性更小.</p></li><li><p><strong>决策树的裁剪</strong></p><p>决策树容易过拟合, 一般需要剪枝来缩小树结构规模, 缓解过拟合.</p></li></ol><h2 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h2><p>划分选择是决策树进行学习的关键. 我们希望决策树的分支节点包含的样本尽可能属于同一类别, 即节点的纯度越来越高, 选择方法都是基于<strong>最大熵原理</strong>的. 最大熵原理是一种选择随机变量统计特性最符合客观情况的准则, 也称为最大信息原理, 在已知一些知识的情况下, 将其他所有未知的事件全部当做等概率事件来处理. <strong>万物趋近于无序, 当事件越不确定(等事件概率发生)时, 熵就最大</strong>.</p><h3 id="信息增益-Information-Gain"><a href="#信息增益-Information-Gain" class="headerlink" title="信息增益 Information Gain"></a>信息增益 Information Gain</h3><p>信息熵是度量样本集合纯度的一种常用指标. 对于当前样本集合$D$中第$k$类样本所占的比例$p_k$, 其信息熵定义为:<br>$$<br>{\rm Ent}(D) = - \sum_k^{K}p_k \log_2{p_k}<br>$$<br><strong>熵越小, 未知的信息就越少</strong>, 即纯度越高. 这里约定如果$p=0$, 则$p\log_2p=0$ .</p><p>而在节点划分时, 可能特征$a$有多个可以取到的可能性$V$, 对数据集进行划分, 这时候可以用条件熵是用来表示在这个特征下某值的不确定性. 这里的${\rm Ent}(D^v)$ 其实就是${\rm Ent}(D|a=a_v)$. 为了保证后续和西瓜书上的公式形式一致采取了前者.<br>$$<br>{\rm Ent}(D|a)=\sum_{v=1}^V\frac{|D^v|}{|D|}{\rm Ent}(D^v)<br>$$<br>信息增益就是在按照特征的某值进行划分后的熵的变化, 条件熵越大, 证明划分效果越差, 对应的信息增益就越少:<br>$$<br>{\rm Gain}(D, a) ={\rm Ent}(D)-{\rm Ent}(D|a)<br>$$<br>使用信息增益作为节点划分依据的算法称为<strong>ID3算法</strong>.</p><p>以周志华老师的西瓜书中的西瓜数据集为例:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/西瓜数据集.png" style="zoom:33%"><p>明显西瓜只有好瓜和坏瓜两种, 好瓜$p_1=\frac{8}{17}$. 坏瓜$p_2=\frac{9}{17}$首先计算出根节点的信息熵:<br>$$<br>{\rm Ent}(D) = - \sum_{k=1}^{2}p_k \log_2{p_k}=-(\frac{8}{17}\log_2\frac{8}{17}+\frac{9}{17}\log_2\frac{9}{17})=0.998<br>$$<br>然后要遍历当前的属性集合$\{色泽, 根蒂, 敲声, 纹理, 脐部, 触感\}$. 以色泽为例, 有三个可能取值$\{青绿, 乌黑, 浅白\}$. 将这个属性进行划分, $D^1(色泽=青绿)$, $D^2(色泽=乌黑)$, $D^3(色泽=浅白)$. 对于子集$D^1, p_1=\frac{3}{6}, p_2=\frac{3}{6}$, 对于子集$D^2, p_1=\frac{4}{6}, p_2=\frac{2}{6}$, 对于子集$D^3, p_1=\frac{1}{5}, p_2=\frac{4}{5}$, 以色泽为划分依据之后得到三个节点的信息熵为:<br>$$<br>\begin{aligned}<br>{\rm Ent}(D^1)&amp;=-(\frac{3}{6}\log_2\frac{3}{6}+\frac{3}{6}\log_2\frac{3}{6})=1 \\<br>{\rm Ent}(D^2)&amp;=-(\frac{4}{6}\log_2\frac{4}{6}+\frac{2}{6}\log_2\frac{2}{6})=0.918 \\<br>{\rm Ent}(D^3)&amp;=-(\frac{1}{5}\log_2\frac{1}{5}+\frac{4}{5}\log_2\frac{4}{5})=0.722 \\<br>\end{aligned}<br>$$<br>因此能够根据信息熵计算出信息增益为:<br>$$<br>\begin{aligned}<br>{\rm Gain}(D, 色泽)&amp;={\rm Ent}(D)-\sum_{v=1}^3\frac{|D^v|}{|D|}{\rm Ent}(D^v)\\<br>&amp;=0.998-(\frac{6}{17}\times 1 + \frac{6}{17} \times 0.918 + \frac{5}{17}\times 0.722) \\<br>&amp;=0.109<br>\end{aligned}<br>$$</p><h3 id="信息增益比-Information-Gain-Ratio"><a href="#信息增益比-Information-Gain-Ratio" class="headerlink" title="信息增益比 Information Gain Ratio"></a>信息增益比 Information Gain Ratio</h3><p>不要忘记西瓜数据集中, 仍然含有”编号”这一特征, 如果将其作为特征纳入决策树的选择中, 那岂不是决策树可以完美拟合编号这一特征, 而完全丧失了泛化能力? 其实对于其他取值较多的特征亦是如此, 当特征的可能性较多时, 每次做一次节点划分, <strong>信息增益会偏爱那些取值多的特征</strong>, 因为原本特征的不确定性就比较大, 所以当选择一个值作为划分时, 消除的熵也很多, 信息增益就会变得大.</p><p>这时就需要用某种熵的定义来平衡掉这个偏好, 也就是”信息增益率”.<br>$$<br>{\rm Gain\_ratio}(D, a) = \frac{ {\rm Gain}(D, a)} { {\rm IV}(a)}<br>$$<br>其中有:<br>$$<br>{\rm IV}(a) = -\sum_{v=1}^V\frac{|D^v|}{|D|}\log_2 \frac{|D^v|}{|D|}<br>$$<br>$a$ 的可能取值数目越多, 则${\rm IV}(a)$就越大(其实它完全就是按照熵来定义的, 不确定性越多熵越大). 但是信息增益率可能对取值数目少的特征有所偏好, 因此是先从候选划分属性中找出信息增益高于平均水平的属性, 然后再从中选择增益率最高的.</p><p>使用信息增益比作为节点划分依据的算法称为<strong>C4.5算法</strong>.</p><h3 id="基尼指数-Gini-Index"><a href="#基尼指数-Gini-Index" class="headerlink" title="基尼指数 Gini Index"></a>基尼指数 Gini Index</h3><p>基尼值表示了<strong>数据集的纯度</strong>, 因此划分准则可以用基尼指数:<br>$$<br>\begin{aligned}<br>{\rm Gini}(D)&amp;=\sum_{k=1}^K\sum_{k’\neq k}p_kp_{k’} \\<br>&amp;=1-\sum_{k=1}^Kp_k^2<br>\end{aligned}<br>$$<br>某个属性的基尼指数定义为:<br>$$<br>{\rm Gini\_index}(D,a)=\sum_{v=1}^{V}\frac{|D^v|}{|D|}{\rm Gini}(D^v)<br>$$<br>其实和之前的条件熵的形式如出一辙. 因此我们在选择候选属性时, 选择划分后基尼指数最小的属性为最优划分属性.</p><p>使用信息增益比作为节点划分依据的算法称为<strong>CART算法</strong>.</p><h2 id="连续值处理"><a href="#连续值处理" class="headerlink" title="连续值处理"></a>连续值处理</h2><p>对于连续属性, 可取值书目不再有限, 因此采用最简单的<strong>二分法</strong>. 对于给定样本中连续属性的所有不同取值, 从小到大进行排序, 然后对每个值进行一次二分, 每次都产生比划分点$t$ 的值不大的集合$D_t^-$和比它大的集合$D_t^+$, 然后再进行计算信息增益, 以信息增益最大的划分点作为划分依据即可.</p><h2 id="决策树剪枝"><a href="#决策树剪枝" class="headerlink" title="决策树剪枝"></a>决策树剪枝</h2><p>剪枝是决策树缓解过拟合的重要手段, 当决策树对节点划分过于细致时候就容易发生过拟合. 决策树有预剪枝和后剪枝两种剪枝策略, 即分别在决策树构建划分节点时和决策树生长完成后剪枝.</p><h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h3><p>预剪枝基于分支划分的准则, 在局部子树生成完成后, 依据<strong>验证集</strong>计算节点划分后能否带来收益, 如果没有性能上的提升或者导致性能下降, 则禁止该节点的划分.</p><p>除了依据划分准则进行预剪枝外, 还可以设定树的生长高度或导致叶子节点分裂的最小样本数, 禁止节点划分的最小阈值等参数, 达到防止过拟合的效果.</p><p>因为预剪枝是与决策树构建并行的, 所以可能会因为局部的性能提升而剪掉更有潜力的节点, 可能过早的停止决策树构造. 常常效果也没有后剪枝好.</p><h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><p>等决策树完整生成后, 后剪枝才开始工作. 后剪枝将从决策树的底部往上进行剪枝, 如果剪枝能够提高验证集的精度, 那么就将其裁去. 后剪枝还有许多其他的剪枝方法, 通过采用不同的性能标准来决定节点的保留与否.</p><p>后剪枝因为不具有视野上的问题, 保留的分支常比预剪枝要多, 泛化能力也更好一些.</p><h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><p>优点: 可解释性好, 分类速度快.</p><p>缺点: 如果不采用剪枝或随机森林很容易发生过拟合, 体现在决策树结构中就是树划分的过细, 或者深度过深.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/11302.html">https://ADAning.github.io/posts/11302.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"><span class="chip bg-color">决策树</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/40015.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/14.jpg" class="responsive-img" alt="机器学习之K邻近"> <span class="card-title">机器学习之K邻近</span></div></a><div class="card-content article-content"><div class="summary block-with-text">K邻近KNN K-Nearest NeighborK邻近是一种非常简单的监督学习分类方法. KNN指的是每个样本都可以通过它最近的K个样本来代表. 比方说在下述图片中, 若K=3, 找到距离未知样本即绿色圆圈最近的3个样本, 在该范围内红色</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-08-08 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">机器学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/KNN/"><span class="chip bg-color">KNN</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/63092.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/15.jpg" class="responsive-img" alt="机器学习之朴素贝叶斯"> <span class="card-title">机器学习之朴素贝叶斯</span></div></a><div class="card-content article-content"><div class="summary block-with-text">朴素贝叶斯NB Naive Bayes朴素贝叶斯有一个非常Naive的假设: 所有特征都是相互独立的, 因此所有特征总的条件概率总是每个特征条件概率的乘积. 这个算法的核心就在于贝叶斯公式. 条件概率条件概率是贝叶斯定理的铺垫. 指的是事件</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-08-06 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">机器学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"><span class="chip bg-color">贝叶斯</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">332.4k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>