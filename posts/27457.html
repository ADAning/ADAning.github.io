<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="PFN: A Partition Filter Network for Joint Entity and Relation Extraction, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>PFN: A Partition Filter Network for Joint Entity and Relation Extraction | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/1.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">PFN: A Partition Filter Network for Joint Entity and Relation Extraction</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-01-12</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-06-11</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 4.1k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 17 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li>RNN: 详见<a href="https://adaning.github.io/posts/60202.html">循环神经网络小结</a>.</li></ul></blockquote><h1 id="A-Partition-Filter-Network-for-Joint-Entity-and-Relation-Extraction"><a href="#A-Partition-Filter-Network-for-Joint-Entity-and-Relation-Extraction" class="headerlink" title="A Partition Filter Network for Joint Entity and Relation Extraction"></a>A Partition Filter Network for Joint Entity and Relation Extraction</h1><p>本文是论文<a href="https://arxiv.org/abs/2108.12202" target="_blank" rel="noopener">A Partition Filter Network for Joint Entity and Relation Extraction</a>的阅读笔记和个人理解, 论文来自<strong>EMNLP 2021</strong>. 图片全部出自原论文和<a href="https://docs.google.com/presentation/d/1CiHWBdwoQexY0JgSP_JxC-QFciZBmTGo" target="_blank" rel="noopener">PPT</a>. 本文为RTE问题中, 探讨NER和RE任务间关系的系列三部曲中的第三篇.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>在先前的联合抽取任务中, 人们少有考虑NER和RE任务间的关系.要么是以<strong>Pipeline</strong>的形式做NER和RE, 导致<strong>任务间的特征交互不平衡</strong>, 要么是<strong>并行</strong>的对NER和RE任务的特征分别编码, 导致特征构建很大程度上是<strong>相互独立</strong>的.</p><p>因此, 作者希望提出一种两路交互模型, 从<strong>多任务学习</strong>视角充分挖掘NER和RE两任务之间的关系, 保证二者之间信息的<strong>均衡传递</strong>, 在此基础上完成联合抽取任务.</p><h2 id="PFN"><a href="#PFN" class="headerlink" title="PFN"></a>PFN</h2><blockquote><p>PFN由LSTM改进而来, 有LSTM基础再理解会好一些.</p></blockquote><h3 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h3><p>首先联合抽取中的两个子任务NER, RE做出定义.</p><p>对于给定的长度为$L$ 的输入序列$s=\set{w_1, \dots, w_L}$:</p><ul><li>NER的任务目标是在给定实体起始Token$w_i$ 和结束Token$w_j$ 的情况下, 抽取出标有类别的实体$e \in \mathcal{E}$ , $\left\langle w_{i}, e, w_{j}\right\rangle \in S$.</li><li>RE的任务目标是在给定Subject的起始Token $w_i$ 和Object的起始Token$w_j$ 的情况下, 抽取出二者存在的关系$r \in \mathcal{R}$, 即$\left\langle w_{i}, r, w_{j}\right\rangle \in T$, $T$ 为三元组.</li></ul><p>从形式上观察, NER和RE这两个任务都可以仅由实体的Span完成, 它们从形式上是<strong>保持一致</strong>的. 只不过NER要求的Span同属于同一个实体, 而RE的Span一个来自于Subject, 另一个来自于Object.</p><h3 id="Partition-Filter-Encoder"><a href="#Partition-Filter-Encoder" class="headerlink" title="Partition Filter Encoder"></a>Partition Filter Encoder</h3><p>PFN的Ecndoer就是被改进过的<strong>LSTM</strong>, 作者在LSTM基础上增加了<strong>Partition</strong>和<strong>Filter</strong>机制, 使得两任务之间的信息能够均衡合理的传递.</p><h4 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h4><p>NER和RE之间存在很强的关联, 但每个任务也同样应该有自己独立的特征, 这部分独立特征是不该被另一个任务所影响的. 划分(Partition)机制的目标就是要学习到仅与本任务相关联的特征位置.</p><blockquote><p>并不是所有特征全部共享就好, 而是<strong>只共享该共享的</strong>. 这看起来是一句废话, 但在多任务学习(Multi Task Learning, MTL) 中很常见, 也很重要. 若共享了不该共享的部分, 对每个任务的完成可能都有害.</p></blockquote><p>先从LSTM的细胞状态入手, 当前时刻$t$ 的初始细胞状态$\tilde{c_t}$ 由当前时刻输入$x_t$ 和上个时刻的记忆$h_{t-1}$ 共同决定:</p><p>$$<br>\tilde{c}_{t}=\tanh \left(\operatorname{Linear}\left(\left[x_{t} ; h_{t-1}\right]\right)\right)<br>$$</p><p>这点与LSTM的输入门得到$\tilde{C}_t$ 的方式保持一致:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E8%BE%93%E5%85%A5%E9%97%A8.png" style="zoom:50%"><p>接着, 作者希望使用<strong>门控</strong>机制, 使得两个任务能够找到独属于自己的那部分特征划分. $\text{cummax}$ 可以完成划分的这个动作.<br>$$<br>\operatorname{cummax}(\cdot)=\operatorname{cumsum}(\operatorname{softmax}(\cdot))<br>$$<br>其中, $\text { cumsum }$ 为作者自定义的函数:<br>$$<br>\begin{gathered}<br>\text { cumsum }\left(x_{1}, x_{2}, \ldots, x_{n-1}, x_{n}\right)=\left(x_{1}, x_{1}+x_{2}, \ldots,\right. \\<br>\left.x_{1}+x_{2}+\cdots+x_{n-1}, x_{1}+x_{2}+\cdots+x_{n-1}+x_{n}\right)<br>\end{gathered}<br>$$</p><p>每个位置上的返回值为输入的对应位置元素及之前元素的和, 亦或许可以写做:<br>$$<br>\begin{gathered}<br>\text { cumsum }\left(x_{1}, x_{2}, \ldots, x_{n-1}, x_{n}\right)=\left(\sum^1_{n=1}x_i, \sum^2_{n=1}x_i,\sum^{n-1}_{n=1}x_i,\cdots, \sum^n_{n=1}x_i\right)<br>\end{gathered}<br>$$<br>$\text{cummax}$ 的输出值可以近似成一个二进制向量$(0, \cdots, 0, 1, \cdots, 1)$. 举个栗子:<br>$$<br>\begin{aligned}<br>x &amp;= (0.1, 0.1, 0.6, 0.1, 0.1) \\<br>\text{cumsum}(x) &amp;= (0.1, 0.2, 0.8, 0.9, 1.0) \\<br>&amp;\approx (0, 0, 1, 1, 1)<br>\end{aligned}<br>$$<br>NER和RE这两个任务都各有一个对输入划分的门控剪刀, 把输入分为任务<strong>相关</strong>, 任务<strong>不相关</strong>两块. 这两把剪刀分别记为$\tilde{e}$ 和$\tilde{r}$:<br>$$<br>\begin{aligned}<br>&amp;\tilde{e}=\operatorname{cummax}\left(\operatorname{Linear}\left(\left[x_{t} ; h_{t-1}\right]\right)\right) \\<br>&amp;\tilde{r}=1-\operatorname{cummax}\left(\operatorname{Linear}\left(\left[x_{t} ; h_{t-1}\right]\right)\right)<br>\end{aligned}<br>$$</p><p>该设计使得NER和RE任务都有独属于自己的部分.</p><blockquote><p>注意, 这两个$\text{Linear}$ 的参数是不一样的. 对于同一组输入, $\tilde{e}$ 和$\tilde{r}$ 可能得到一块交叉的区域, 这也就是<strong>共享区域</strong>, 该区域是由两个门控共同决定的.</p></blockquote><p>两刀切三份, 接下来就把两把剪刀切出来的结果表示出来.</p><p>这里给出的是上个时刻$t-1$ 的划分$\rho_{c_{t-1}}$, 因为在LSTM中, 后面要借助$t-1$ 时刻表达当前时刻$t$ 对应的划分:</p><p>$$<br>\begin{aligned}<br>\rho_{s, c_{t-1}} &amp;=\tilde{e}_{c_{t-1}} \circ \tilde{r}_{c_{t-1}} \\<br>\rho_{e, c_{t-1}} &amp;=\tilde{e}_{c_{t-1}}-\rho_{s, c_{t-1}} \\<br>\rho_{r, c_{t-1}} &amp;=\tilde{r}_{c_{t-1}}-\rho_{s, c_{t-1}}<br>\end{aligned}<br>$$<br>$\tilde{e}, \tilde{r}$ 的结果做逐元素点乘, 就能获取共享部分, <strong>细胞状态</strong>被切成了三份: <strong>NER区</strong>, <strong>RE区</strong>, <strong>Share区</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pfn1.jpg" style="zoom:50%"><p>对于三个式子, PPT中给出了一个例子. 若$\tilde{e}=(0, 1, 1), \tilde{r} =(1, 1, 0)$, 则有:<br>$$<br>\begin{aligned}<br>\rho_{s, c_{t-1}} &amp;= (0,1,1) \circ (1,1,0)=(0,1,0)\\<br>\rho_{e, c_{t-1}} &amp;= (0,1,1)- (0,1,0)=(0,0,1)\\<br>\rho_{r, c_{t-1}} &amp;= (1,1,0)- (0,1,0)=(1,0,0)<br>\end{aligned}<br>$$<br>对于NER, RE, Share区, 每个区域划分到的细胞状态$\rho$ 都由上个时刻的对应区域的细胞状态$c_{t-1}$ 和当前时刻对应区域的初始细胞状态$\tilde{c_t}$ 共同决定:<br>$$<br>\begin{aligned}<br>\rho_{e} &amp;=\rho_{e, c_{t-1}} \circ c_{t-1}+\rho_{e, \tilde{c}_{t}} \circ \tilde{c}_{t} \\<br>\rho_{r} &amp;=\rho_{r, c_{t-1}} \circ c_{t-1}+\rho_{r, \tilde{c}_{t}} \circ \tilde{c}_{t} \\<br>\rho_{s} &amp;=\rho_{s, c_{t-1}} \circ c_{t-1}+\rho_{s, \tilde{c}_{t}} \circ \tilde{c}_{t}<br>\end{aligned}<br>$$</p><p>$\rho$ 并不是PFN Encoder最终的细胞状态, 上述过程仅是与LSTM中的细胞状态更新相似:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E7%BB%86%E8%83%9E%E7%8A%B6%E6%80%81.png" style="zoom:50%"><blockquote><p>作者认为, 把细胞状态拆为三个区域, 再将它们合起来, 和不划分时不是等价的, 会损失一部分信息, 这个机制与LSTM的遗忘门类似:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E9%81%97%E5%BF%98%E9%97%A8.png" style="zoom:50%"><p>这种解释还是非常巧妙的, 不需要在模型中显式设计出遗忘门.</p></blockquote><h4 id="Filter"><a href="#Filter" class="headerlink" title="Filter"></a>Filter</h4><p>在上个阶段Partition对输入区域完成了划分, 在本阶段将对每个任务所需特征做<strong>表征重组</strong>.</p><p>首先把上阶段得到的三部分<strong>组装</strong>在一起, 对应区域得到新的记忆$\mu$.</p><p>NER可以使用独有的细胞状态$\rho_e$ 和共享细胞状态$\rho_s$, RE可以使用独有细胞状态$\rho_r$ 和共享细胞状态$\rho_s$, 对任务无关的信息直接被滤去:<br>$$<br>\begin{aligned}<br>\mu_{e}&amp;=\rho_{e}+\rho_{s} \\\<br>\mu_{r}&amp;=\rho_{r}+\rho_{s}\\<br>\mu_{s}&amp;=\rho_{s}<br>\end{aligned}<br>$$</p><p>然后给记忆$\mu$ 激活一下子:<br>$$<br>\begin{aligned}<br>&amp;h_{e}=\tanh \left(\mu_{e}\right) \\<br>&amp;h_{r}=\tanh \left(\mu_{r}\right) \\<br>&amp;h_{s}=\tanh \left(\mu_{s}\right)<br>\end{aligned}<br>$$</p><p>$h$ 将作为特定任务的表示, 在解码过程中使用.</p><p>最后就是PFN Encoder的更新细胞状态$c_t$, 并由$c_t$ 得到当前时刻隐态$h_t$, 完成输出过程:<br>$$<br>\begin{aligned}<br>c_{t} &amp;=\operatorname{Linear}\left(\left[\mu_{e, t} ; \mu_{r, t} ; \mu_{s, t}\right]\right) \\<br>h_{t} &amp;=\tanh \left(c_{t}\right)<br>\end{aligned}<br>$$</p><p>这与LSTM的输出门相似, 但又不太一样:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E8%BE%93%E5%87%BA%E9%97%A8.png" style="zoom:50%"><p>至此, PFN Encoder信息流可以由下图概括:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pfn3.jpg" style="zoom:50%"><p>只是看输入和输出, 相较于LSTM仍然没有变化, 信息流为:</p><ol><li>上时刻$t-1$ 被划分好的三份的细胞状态(NER区, RE区, Share区)记为$\rho_{c_{t-1}}$, 与当前时刻划分好的三份初始细胞状态$\rho_{\tilde{c}_t}$, 生成$t$ 时刻划分好的新细胞状态$\rho$.</li><li>新细胞状态进一步过滤得到任务特化的细胞状态$\mu$.</li><li>激活后得到任务所需的表征$h_e, h_r, h_s$.</li><li>用类似输出门的方式得到当前时刻$t$ 的最终细胞状态$c_t$, 和输出隐态$h_t$.</li></ol><h3 id="Global-Representation"><a href="#Global-Representation" class="headerlink" title="Global Representation"></a>Global Representation</h3><p>因为作者使用的是单向编码器, 只有前向(Forward)而没有反向(Backward), 所以这里作者用提取的全局特征$h_{g}$ 来代替反向编码所获取的信息:</p><p>$$<br>\begin{aligned}<br>h_{g_{e}, t}=\tanh \left(\operatorname{Linear}\left[h_{e, t} ; h_{s, t}\right]\right) \\<br>h_{g_{r}, t}=\tanh \left(\operatorname{Linear}\left[h_{r, t} ; h_{s, t}\right]\right) \\<br>h_{g_{e}}=\operatorname{maxpool}\left(h_{g_{e}, 1}, \ldots, h_{g_{e}, L}\right) \\<br>h_{g_{r}}=\operatorname{maxpool}\left(h_{g_{r}, 1}, \ldots, h_{g_{r}, L}\right)<br>\end{aligned}<br>$$</p><p>最后用了一个最大池化, 只保留整个句子中最重要的信息, 作为全局表示.</p><h3 id="Task-Units"><a href="#Task-Units" class="headerlink" title="Task Units"></a>Task Units</h3><p>Task Unit也就是Decoder, 采用朴实无华的<strong>Table Filling</strong> Decoding策略. 因为前面观察过NER和RE任务的形式一致, 均可视为<strong>二分类</strong>问题, 仅依赖于两两Token就能完成实体类别和关系类别的判定, 所以两个任务的解码单元也可以设计得一样.</p><h4 id="NER-Unit"><a href="#NER-Unit" class="headerlink" title="NER Unit"></a>NER Unit</h4><p>每个实体类型$k$ 都有一张表, 在$k$ 表中第$i$ 行第$j$ 列被填上的值为, 类型为$k$ 的实体起始Token为$w_i$, 结束Token为$w_j$ 的概率$e_{ij}^k$, 由$h_i^e, h_j^e$, 以及全局表示$h_{g_e}$ 拼接后变换得到:<br>$$<br>\begin{aligned}<br>h_{i j}^{e}&amp;=\operatorname{ELU}\left(\operatorname{Linear}\left(\left[h_{i}^{e} ; h_{j}^{e} ; h_{g_{e}}\right]\right)\right)\\<br>e_{i j}^{k} &amp;=p\left(e=\left\langle w_{i}, k, w_{j}\right\rangle \mid e \in S\right) \\<br>&amp;=\sigma\left(\operatorname{Linear}\left(h_{i j}^{e}\right)\right), \forall k \in \mathcal{E}<br>\end{aligned}<br>$$</p><h4 id="RE-Unit"><a href="#RE-Unit" class="headerlink" title="RE Unit"></a>RE Unit</h4><p>RE单元可以由NER单元如法炮制. 每个关系类型$l$ 都有一张表, 在$l$ 表中第$i$ 行第$j$ 列被填上的值为, Token为$w_i$ 的Subject和起始Token为$w_j$ 间存在关系$l$ 的概率$r_{ij}^l$ , 同样由两Token间表示$h_i^r, h_j^r$, 以及全局表示$h_{g_r}$ 拼接, 后经过激活, 变换得到:<br>$$<br>\begin{aligned}<br>h_{i j}^{r} &amp;=\operatorname{ELU}\left(\operatorname{Linear}\left(\left[h_{i}^{r} ; h_{j}^{r} ; h_{g_{r}}\right]\right)\right) \\<br>r_{i j}^{l} &amp;=p\left(r=\left\langle w_{i}, l, w_{j}\right\rangle \mid r \in T\right) \\<br>&amp;=\sigma\left(\operatorname{Linear}\left(h_{i j}^{r}\right)\right), \forall l \in \mathcal{R}<br>\end{aligned}<br>$$</p><h3 id="Training-and-Inference"><a href="#Training-and-Inference" class="headerlink" title="Training and Inference"></a>Training and Inference</h3><p>因为作者假定填表任务为二分类问题, 所以使用二分类交叉熵(BCE Loss)优化:</p><p>$$<br>\begin{aligned}<br>L_{n e r} &amp;=\sum_{\hat{e}_{i j}^{k} \in S} \operatorname{BCELoss}\left(e_{i j}^{k}, \hat{e}_{i j}^{k}\right) \\<br>L_{r e} &amp;=\sum_{\hat{r}_{i j}^{l} \in T} \mathrm{BCELoss}\left(r_{i j}^{l}, \hat{r}_{i j}^{l}\right)<br>\end{aligned}<br>$$</p><p>$\hat{e}_{i j}^{k}, \hat{r}_{i j}^{l}$ 为真实标签. 在推理时, 各实体, 关系存在的概率仅当均大于阈值$\lambda$ 时, 三元组$(s_{i, j}^k, l, o_{m, n}^{k\prime})$ 成立:<br>$$<br>e_{i j}^{k} \geq \lambda_{e} ; e_{m n}^{k^{\prime}} \geq \lambda_{e} ; r_{i m}^{l} \geq \lambda_{r}<br>$$</p><p>文中取阈值均为0.5.</p><p>PFN整体的模型框架图如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pfn2.jpg" style="zoom:50%"><p>先由Partition Filter划分过滤得到任务特化的特征, 再提取整句全局特征, 最后结合二者通过两个简单的Task Unit二分类填表, 完成联合抽取.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><h3 id="Main-Results"><a href="#Main-Results" class="headerlink" title="Main Results"></a>Main Results</h3><p>在联合抽取常用的两个数据集NYT和WebNLG上, 效果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pfn4.jpg" style="zoom:50%"><p>性能超过了之前最强的TPLinker.</p><p>在ADE, ACE05, ACE04, SciERC上结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pfn5.jpg" style="zoom:50%"> <img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pfn6.jpg" style="zoom:50%"><p>PFN的性能也与强调任务间交互的<a href="https://adaning.github.io/posts/37252.html">Table - Sequence</a>和Pipeline设计模型<a href="https://adaning.github.io/posts/22256.html">PURE</a>(也是本系列前两篇文章介绍的模型)各有优劣, 整体上来说PFN要好. PURE在ACE05的NER上性能仍为最强.</p><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p>在SciERC上消融实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pfn7.jpg" style="zoom:50%"><h4 id="Number-of-Encoder-Layers"><a href="#Number-of-Encoder-Layers" class="headerlink" title="Number of Encoder Layers"></a>Number of Encoder Layers</h4><p>堆叠PFN层数不能带来性能提升. 个人认为多层PFN会令信息流混乱, 干扰了任务之间的平衡.</p><h4 id="Bidirection-Vs-Unidirection"><a href="#Bidirection-Vs-Unidirection" class="headerlink" title="Bidirection Vs Unidirection"></a>Bidirection Vs Unidirection</h4><p>无论是单向和还是双向, 使用全局信息都有一点点提升, 但是全局信息对单向增益更大.</p><h4 id="Encoding-Scheme"><a href="#Encoding-Scheme" class="headerlink" title="Encoding Scheme"></a>Encoding Scheme</h4><p>作者把PFN Encoder替换成两个LSTM, 观察不同编码方式的效果. Joint代表本文的做法.</p><p>在后两种实验中均把PFN Encoder替换成LSTM. Sequential代表Pipeline式的做法, 即单路交互, 先生成实体特征再生成关系特征. Parallel代表两个LSTM都分别编码, 不做交互.</p><p>从结果上来看, 平衡交互 &gt; 单路交互 &gt; 不做交互. 似乎平衡交互更有利于召回.</p><blockquote><p>其实有点不公平, 比较单独比较编码策略的时候还是都用LSTM比较好, 可以补一个只用LSTM的Joint结果.</p></blockquote><h4 id="Partition-Granularity"><a href="#Partition-Granularity" class="headerlink" title="Partition Granularity"></a>Partition Granularity</h4><p>作者探究了粗细粒度门控对性能的影响. 例如表示是300维的, 如果把300维劈成10份, 每份都共用30维相同的实体门和关系门, 称为Coarse. 如果300维不劈开, 用300维的实体门和关系门处理, 就称为Fine - grained.</p><p>结果表明细粒度更强, 其实也很好解释. 细粒度能更好的区分任务所需要的特征区间.</p><h4 id="Decoding-Strategy"><a href="#Decoding-Strategy" class="headerlink" title="Decoding Strategy"></a>Decoding Strategy</h4><p>作者把Pipeline的解码方式称为Selective Decoding, 因为关系模型只对Entity Golden Label解码, 建立在有效实体对之上的. 作者认为, 更好的解码策略是让关系模型把有效和无效实体对都考虑进去, 即Universal Decoding.</p><p>Selective是将NER Unit预测得出的有效实体对送给RE Unit解码的结果.</p><p>接下来的观点就很有意思了, 作者认为通用解码类似于<strong>对比学习</strong>, 因为其中包含了无效实体对作为<strong>负例</strong>, 所以通用解码效果更好.</p><h3 id="Effects-of-Relation-Signal-on-Entity-Recognition"><a href="#Effects-of-Relation-Signal-on-Entity-Recognition" class="headerlink" title="Effects of Relation Signal on Entity Recognition"></a>Effects of Relation Signal on Entity Recognition</h3><p>在先前的研究中, NER的实体信息对RE有帮助是大家公认的, 但RE是否对NER有益仍然有争议.</p><h4 id="Analysis-on-Entity-Prediction-of-Different-Types"><a href="#Analysis-on-Entity-Prediction-of-Different-Types" class="headerlink" title="Analysis on Entity Prediction of Different Types"></a>Analysis on Entity Prediction of Different Types</h4><p>因为在主实验结果中, PFN的表现没有很抢眼, 作者认为, 可能是ACE05中包含很多<strong>不属于任何三元组的实体</strong>.</p><p>因此作者将NER任务的结果分为<strong>三元组内</strong>的实体预测, <strong>三元组外</strong>的实体预测, 观察它们的差距:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pfn8.jpg" style="zoom:50%"><p>结果发现, 在三元组内的实体预测和在三元组外的实体预测性能有巨大差距, 在不借助关系信息时, 精度下降的很厉害. 与ACE05上NER SOTA Pipeline模型PURE对比, PFN的NER性能似乎与三元组外的实体百分比负相关, 即<strong>对于联合模型来说</strong>, <strong>三元组外的实体越多</strong>, <strong>NER性能越差</strong>. 因为在三元组内的实体和三元组外的实体预测推理时本质上是不同的, <strong>在三元组内部的实体预测可以借助关系信息</strong>, <strong>而三元组外实体预测却不能</strong>.</p><h4 id="Robustness-Test-on-Named-Entity-Recognition"><a href="#Robustness-Test-on-Named-Entity-Recognition" class="headerlink" title="Robustness Test on Named Entity Recognition"></a>Robustness Test on Named Entity Recognition</h4><p>在ACE05上的鲁棒性测试结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/pfn9.jpg" style="zoom:50%"><p>相较于其他模型, PFN的鲁棒性非常好.</p><h4 id="Does-Relation-Signal-Helps-in-Predicting-Entities"><a href="#Does-Relation-Signal-Helps-in-Predicting-Entities" class="headerlink" title="Does Relation Signal Helps in Predicting Entities"></a>Does Relation Signal Helps in Predicting Entities</h4><p>与PURE中得出的结论相反, 作者认为关系信息对实体预测影响很大.</p><p>PURE中的实验是在ACE05上做的, 而忽略了ACE05上的三元组外实体的巨大影响.</p><blockquote><p>附录中还有CasRel, TPLinker, PFN三者在NYT和WebNLG上应对重叠三元组的详细表现, 结果表明PFN在处理重叠三元组的实力也很出色.</p></blockquote><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>本文从<strong>多任务学习</strong>视角, 以任务间<strong>不平衡的信息交互</strong>为出发点, 通过<strong>划分</strong>, <strong>过滤</strong>在最基础的<strong>特征区域</strong>上控制任务间的信息流通, 再结合整句的<strong>全局特征</strong>, 用两个任务特化的Task Unit用<strong>填表</strong>的方法解决联合抽取问题.</p><p>我个人认为, 这是一篇挺有想法的文章, 顺着论文的引文, 发现其灵感似乎也来自于<a href="https://openreview.net/forum?id=B1l6qiR5F7" target="_blank" rel="noopener">ON - LSTM</a>, 感兴趣的可以直接看<a href="https://spaces.ac.cn/archives/6621" target="_blank" rel="noopener">苏神博客</a>.</p><p>PFN进一步的说明了联合抽取中NER和RE任务之间是密不可分的, 并有效驳斥了PURE中的论点.</p><p>从论文本身来说, 是很优秀的一篇. 实验完备, 论据充分, 图也很好看.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/27457.html">https://ADAning.github.io/posts/27457.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/879.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/17.jpg" class="responsive-img" alt="SDN: Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction"> <span class="card-title">SDN: Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: LSTM: 循环神经网络小结 Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction本文</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-03-16 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/22256.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/1.jpg" class="responsive-img" alt="PURE: A Frustratingly Easy Approach for Entity and Relation Extraction"> <span class="card-title">PURE: A Frustratingly Easy Approach for Entity and Relation Extraction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">A Frustratingly Easy Approach for Entity and Relation Extraction本文是论文A Frustratingly Easy Approach for Entity and Relati</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-12-01 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">378.1k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>