<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="循环神经网络小结, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>循环神经网络小结 | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/5.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">循环神经网络小结</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/RNN/"><span class="chip bg-color">RNN</span> </a><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">神经网络</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-07-30</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-04-03</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3.2k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 11 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p><strong>2020.09.07</strong>: 重写了LSTM和GRU的描述.</p><p><strong>2020.08.22</strong>: 对部分内容进行了更新.</p></blockquote><h1 id="循环神经网络-Recurrent-Neural-Network"><a href="#循环神经网络-Recurrent-Neural-Network" class="headerlink" title="循环神经网络 Recurrent Neural Network"></a>循环神经网络 Recurrent Neural Network</h1><p>面对时序型数据, 如自然语言, 乐谱, 金融数据等包含隐含的时间信息在内的数据, 不能采用原始的稠密神经网络, 会产生很多问题. 比如, 很容易就产生海量的参数, 或者输入输出的神经元很有可能是不确定的, 最主要的是无法将时序的信息传递给稠密神经网络. 采用循环神经网络可以很好的处理时序问题.</p><h2 id="RNN的基本结构"><a href="#RNN的基本结构" class="headerlink" title="RNN的基本结构"></a>RNN的基本结构</h2><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rnn.jpg" alt=""></p><p>RNN因为满足<strong>循环递归</strong>的结构, 很多时候也画成左边折叠的样子. 能够看到, 下方的$X_i$ 对应着$t$时刻的输入. 在图中没有画出来的是, 对于图中的$A$ 实际上是一个含有若干个神经元的与输入输出相连的神经网络(其实对应数学结构就是一个矩阵), 只不过<strong>隐藏层之间相互有了连接</strong>, 下面这个图可能更好解释一些:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rnn6.png" style="zoom:50%"><p>在新的时刻$t$ ,输入视为是$t-1$时刻的神经元结果和$t$时刻的时序序列输入$X_t$的合成结果. 假设激活函数$f$, 当前时刻为$t$有:<br>$$<br>\displaylines{<br>A_t = f(UX_t + WA_{t-1} + b_a) \\<br>h_t = f(VA_t + b_y)}<br>$$<br><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rnn2.jpg" alt=""></p><p>在进行计算时, 既然是循环使用的神经元, 那么<strong>在时刻尺度上</strong>它的参数一定是<strong>共享</strong>的, 即对于同一组RNN, 它们的$U, W, V, b$ 采用的都是<strong>相同的值</strong>, 这也符合我们对<strong>递归</strong>的理解, RNN每个时间步都在做相同的事情, 只是输入不同. 并且在实际计算的过程中, 经常将$U$和$W$合并为同一个矩阵, 将$X_t, A_{t-1}$也合并成一个矩阵做矩阵乘.</p><p>其实上述过程就是RNN的前向传播, 非常的符合逻辑, 也同时隐含了它<strong>只能进行串行计算</strong>的弊病. 其实反向传播只要把前向传播过程反过来就行了, 损失函数为所有时刻的损失平均值.</p><h2 id="RNN的几种结构"><a href="#RNN的几种结构" class="headerlink" title="RNN的几种结构"></a>RNN的几种结构</h2><p>RNN也可以分为很多种, 有一对一, 一对多, 多对一, 多对多, 具体采用哪种需要结合具体的任务目标而定.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84rnn.jpg" alt=""></p><p>经典RNN由于结构输入和输出必须是一一对应的,应用范围受限很大. 图中所示的第一种多对多经常用于机器翻译, 前一段没有输出的神经网络对应的称为<code>encoder</code>即编码器, 后一段有输出的神经网络称为<code>decoder</code>即解码器, 机器在经过编码器读完整个句子后从解码器获取输出. 第二种多对多经常用于多对多经常用于序列生成.</p><h3 id="RNN的采样"><a href="#RNN的采样" class="headerlink" title="RNN的采样"></a>RNN的采样</h3><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rnn%E9%87%87%E6%A0%B7.jpg" alt=""></p><p>假设有个已经训练好的模型, 那么我们对输入$x^{&lt;1&gt;}$和$a^{&lt;0&gt;}$都置为零向量, 然后让RNN自己预测第一个单词的概率向量$\hat y^{&lt;1&gt;}$, 根据这个概率利用例如<code>np.random.choice</code>获取一个单词的index, 将这个单词的one-hot形式作为下时刻的输入. 当然不一定是单词级别的RNN, 字符级别也可以用, 但是计算成本非常大, 一般只有很多专业词汇才用.</p><h2 id="RNN的梯度爆炸和梯度消失"><a href="#RNN的梯度爆炸和梯度消失" class="headerlink" title="RNN的梯度爆炸和梯度消失"></a>RNN的梯度爆炸和梯度消失</h2><p>RNN因为是循环的结构, 循环多次很容易导致网络层数加深, 这样前面的网络参数很难被反向传播影响. 比如说RNN可能很难记住一个长句子里的时态语态信息, 其每个时刻的输出主要由临近的几个时刻所影响, 导致<strong>不善于处理长期依赖</strong>问题. 必须引入一些结构来传递需要被长期记忆的信息.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rnn长期依赖.png" style="zoom:33%"><h3 id="长短期记忆神经网络LSTM-Long-Short-Term-Memory"><a href="#长短期记忆神经网络LSTM-Long-Short-Term-Memory" class="headerlink" title="长短期记忆神经网络LSTM Long Short-Term Memory"></a>长短期记忆神经网络LSTM Long Short-Term Memory</h3><p>LSTM于1997年在<a href="(https://www.bioinf.jku.at/publications/older/2604.pdf)">Long Short-Term Memory</a>中出现, 是一种尝试保存长期记忆避免梯度消失的RNN. LSTM主要有四个部分, <strong>遗忘门</strong>, <strong>输入门</strong>, <strong>输出门</strong>, <strong>细胞状态</strong>. 因为引入了循环神经网络的记忆机制, 常形象地将结构单位称为<strong>记忆细胞</strong>(memory cell).</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm.png" alt=""></p><p>LSTM中所有的向量操作如下:</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E6%93%8D%E4%BD%9C.png" alt=""></p><p>黄框框代表<strong>神经层</strong>(注意是一层神经层, 不单单是图中标注的激活函数), 粉圈圈代表某种向量的操作, 单箭头代表向量的流向, 汇聚箭头代表向量的concat, 分离箭头代表向量拷贝成了两份.</p><p>LSTM最上面的那条水平线代表<strong>细胞状态</strong>, 细胞存储的状态实际上就是需要<strong>长期记忆</strong>的信息. 这条路上只有遗忘门和输入门能够对细胞状态进行更改, 只有一些少量的线性交互, 实际上这条线是非常<strong>容易不发生任何转变</strong>而传递到下一个时刻的. 如下所示:</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3.png" alt=""></p><p>下面来看数据在LSTM中从输入到输出的完整过程.</p><p>数据输入后, 数据首先经过LSTM的<strong>遗忘门</strong>. 遗忘门接收了当前时刻$t$的输入$x_t$和上个时刻的隐藏状态 $h_{t-1}$, 经过$\sigma$函数的处理, 能够决定到底<strong>留下</strong>多少在细胞状态中. $f_t=1$表示<strong>完全记住</strong>这个信息, $f_t=0$代表<strong>完全忘记</strong>这个值. 基于上文预测下文词的语言模型中, 可能细胞状态会包含前文的主题, 那么最好记住$h_{t-1}$, 如果得到一个新的语言主题, 则希望遗忘掉过去的信息.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E9%81%97%E5%BF%98%E9%97%A8.png" alt=""></p><p>第二步决定在细胞状态中<strong>储存</strong>什么样的信息, 与之对应的结构称为<strong>输入门</strong>. 输入门有两条并行的向量流向. 左侧线路用$\sigma$函数决定有哪些位置上的信息是需要更新的, 右侧线路利用$tanh$为等待细胞状态更新时的使用的候选值创建一个新的向量.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E8%BE%93%E5%85%A5%E9%97%A8.png" alt=""></p><p>第三步便是对<strong>细胞状态更新</strong>的过程. 细胞状态先通过遗忘门所给出的遗忘程度对先前状态遗忘, 然后再将输入门的左右两条并行路线的结果计算出来, 与细胞状态相加, 就完成了细胞状态的更新. 从下述式子中可以看到, 对于旧信息的遗忘和新信息的输入, 是让它们自己决定到底留下哪些, 加入哪些. 这点与GRU的风格是不同的, 后面会提到.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E7%BB%86%E8%83%9E%E7%8A%B6%E6%80%81.png" alt=""></p><p>最后决定要输出的东西, 所对应的结构就是<strong>输出门</strong>. 输出基于细胞当前的状态, 但会经过一次过滤才输出. 与输入门对应, 先利用$\sigma$函数得到一个输出的系数, 再将细胞状态过一次$tanh$将信息压到$[-1, 1]$之间, 与系数相乘就得到了结果. 也正是因为输出门的设置, 导致LSTM的输出$h_t$ 其实只是经过输出门过滤后的$C_t$ 的一部分信息.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm%E8%BE%93%E5%87%BA%E9%97%A8.png" alt=""></p><p>LSTM的遗忘门和输入门都对细胞状态进行了更改, 先遗忘再存储. 输出门发生作用的时候是不会对细胞状态再次更改的.</p><p>在这三种门控结构中, 不难观察门控作为一种关键的结构, 能起到让<strong>信息选择性通过</strong>的作用, 根据$\sigma$函数的特性, 向量的每个维度都能够得到一个介于$[0, 1]$ 之间的值, 在与其他向量相乘时, 可以作为保留或遗忘程度的依据.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/lstm门控.png" style="zoom:50%"><h3 id="门控循环单元-GRU-Gate-Recurrent-Unit"><a href="#门控循环单元-GRU-Gate-Recurrent-Unit" class="headerlink" title="门控循环单元 GRU Gate Recurrent Unit"></a>门控循环单元 GRU Gate Recurrent Unit</h3><p>GRU是一个LSTM的一个变种, 于<a href="https://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="noopener">Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation</a>中提出. 它比LSTM参数更少, 结构更简单, 具有更高的<strong>效率</strong>, 达到的精度和LSTM相近. GRU和LSTM同样借鉴了<strong>门控</strong>的思想, 在RNN中添加不同的门控, 从而决定是否要更新信息. GRU结构比较简单, 所以用一张图就完全可以说得清.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/gru.jpg" alt=""></p><p>GRU分别有两个门控结构, 分别是<strong>重置门</strong>$r_t$ (reset gate)和<strong>更新门</strong>$z_t$ (update gate).</p><blockquote><p>重置门: 重置门用于决定丢弃<strong>先前信息</strong>的程度.</p><p>更新门: 更新门能决定在当前时刻要丢弃哪些信息和要添加哪些<strong>新信息</strong>. 作用类似于LSTM中的遗忘门和输入门.</p></blockquote><p>$\tilde h_t$表示的是相较于普通RNN的隐藏状态输出$h_t$的<strong>候选</strong>, 最终不会使用它, 仅作为最终输出$h_t$的<strong>依据</strong>.</p><p>下面描述一下数据在GRU的传播过程:</p><ol><li><p>对于重置门, 上一个时刻$t-1$的隐藏状态$h_{t-1}$和当前时刻的输入$x_t$传入GRU, 通过重置门后将得到一个将$h_{t-1}$和$x_t$ 丢弃的程度系数向量$r_t$.</p></li><li><p>而对于更新门, 同样将是上一个时刻$t-1$的隐藏状态$h_{t-1}$和当前时刻的输入$x_t$传入, 获得表示一个更新程度的系数向量$z_t$.</p></li><li><p>重置门和更新门(或者说重置系数和更新系数)的值已经求出来了, 接着利用重置门的丢弃系数和上一时刻的隐藏状态$h_{t-1}$ 相乘, 并结合当前时刻输入, 经过激活函数为$tanh$ 的神经层, 求出当前时刻的候选隐藏状态$\tilde {h_t}$.</p></li><li><p>根据重置和更新的互斥关系, 求出当前时刻隐藏状态$h_t$ . 当更新门$z_t$的值趋近于1时, 就更倾向于更新记忆细胞的信息, $h_t$的值会和$\tilde{h_{t}}$相仿, 反之不更新, 即仍然沿用上个时刻的信息$h_{t-1}$.</p></li></ol><p>两个门的作用在进行运算中十分明显, <strong>重置门决定了要丢弃多少先前信息</strong>, 直接影响了$\tilde{h_t}$, 间接影响了结果$h_t$, <strong>更新门决定了细胞要替换多少新信息</strong>, 直接影响最终输出的隐藏状态 $h_t$.</p><h3 id="LSTM与GRU对比及个人理解"><a href="#LSTM与GRU对比及个人理解" class="headerlink" title="LSTM与GRU对比及个人理解"></a>LSTM与GRU对比及个人理解</h3><p>首先要明确细胞状态和隐藏状态的区别, 细胞状态$C_t$ 代表的是初始时刻一直到$t$ 时刻的全局信息, 而$h_t$ 代表的是初始时刻到$t-1$ 时刻的全局信息影响下, 当前$t$ 时刻的上下文表示.</p><p>LSTM中, 有细胞状态这个概念, GRU只有隐藏状态. LSTM对信息的保留更加<strong>细腻</strong>, 但对下一个时刻只暴露<strong>部分</strong>信息, 因为在LSTM中$h_t$ 才是真正的输出, $C_t$ 只作为一个信息载体继续传递下去. 相比于LSTM, GRU则更加<strong>简单粗暴</strong>, 对下个时刻暴露<strong>全部</strong>信息.</p><p>LSTM对细胞状态的更新过程中, 经过遗忘门和输入门后求出细胞状态$C_t$ 是<strong>相互独立</strong>的, 即$f_t$ 和 $i_t$ 之间没有关联, 由遗忘门和输入门分别控制遗忘和存储. 而对于GRU来说, 既然$h_t$ 被包含在$C_t$ 中了, 干脆将细胞状态与隐藏状态合并, 在求出最终隐藏状态$h_t$ 时, 而去除了细胞状态后, 当前信息与全局信息是此消彼长的, 即对于写入新信息和保留旧信息是<strong>互相制约</strong>的, 故令$f_t$ 和 $i_t$ 的总和1, 直接用一个更新门$z_t$ 来代替原有的遗忘门和输入门. 同样因为输出的调整, 重置门本质上是输出门的一种变化.</p><h2 id="双向RNN和RNN的堆叠"><a href="#双向RNN和RNN的堆叠" class="headerlink" title="双向RNN和RNN的堆叠"></a>双向RNN和RNN的堆叠</h2><p>双向RNN解决了网络不知道下文信息的问题, 使网络不光会结合前文进行判断, 还会结合后文信息进行预测. 如下图所示, 对于给定的$x^{&lt;1&gt;}, x^{&lt;2&gt;}, x^{&lt;3&gt;}, x^{&lt;4&gt;}$, 每个时刻都增加一个反向链接的神经元. 这样RNN就构成了一个无环图. 当进行前向传播时, 信息会从左到右, 再从右逆着传回来, 最后再做出预测, 即对于$t$时刻的预测值$y_t$, 是由$a^{&lt;t\rightarrow&gt;}$和$a^{&lt;t\leftarrow&gt;}$, $x^{&lt;t&gt;}$共同决定的.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/%E5%8F%8C%E5%90%91rnn.jpg" alt=""></p><p>和下面这张图是一样的:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/双向rnn2.jpg" style="zoom:67%"><p>RNN的堆叠方式其实也非常简单, 就是按照层数往上传递隐藏状态, 最终得到预测值.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/rnn%E5%A0%86%E5%8F%A0.png" alt=""></p><p>如果是若干双向RNN, 堆叠起来也和普通RNN大同小异:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/双向堆叠rnn.png" style="zoom:67%"></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/60202.html">https://ADAning.github.io/posts/60202.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/RNN/"><span class="chip bg-color">RNN</span> </a><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">神经网络</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/18683.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/7.jpg" class="responsive-img" alt="机器学习之评估指标"> <span class="card-title">机器学习之评估指标</span></div></a><div class="card-content article-content"><div class="summary block-with-text">评估指标 Metrics混淆矩阵 Confusion Matrix对于简单的二分类情况, 混淆矩阵就是如下形式: 混淆矩阵把数据和模型预测情况分为四类: 真实值是positive, 模型认为是positive的数量(True Positi</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-07-31 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="post-category">机器学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87/"><span class="chip bg-color">评估指标</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/28799.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="卷积神经网络小结"> <span class="card-title">卷积神经网络小结</span></div></a><div class="card-content article-content"><div class="summary block-with-text">卷积神经网络 Convolutional Neural Network卷积神经网络是一种含有空间信息的数据表示方法. 它与普通的DNN不同, 它包含了数据的位置信息, 以保证每次看到的是数据矩阵的一个区域, 而不是单纯的矩阵某一维. 卷积神</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-07-29 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/CNN/"><span class="chip bg-color">CNN</span> </a><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">神经网络</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">322.7k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>