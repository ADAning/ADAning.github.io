<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/13.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span> </a><a href="/tags/Vocoder/"><span class="chip bg-color">Vocoder</span> </a><a href="/tags/TTS/"><span class="chip bg-color">TTS</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2025-01-03</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2025-03-23</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.5k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 10 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="HiFi-GAN-Generative-Adversarial-Networks-for-Efficient-and-High-Fidelity-Speech-Synthesis"><a href="#HiFi-GAN-Generative-Adversarial-Networks-for-Efficient-and-High-Fidelity-Speech-Synthesis" class="headerlink" title="HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis"></a>HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</h1><p>本文是论文<a href="https://proceedings.neurips.cc/paper_files/paper/2020/hash/c5d736809766d46260d816d8dbc9eb44-Abstract.html" target="_blank" rel="noopener">HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</a> 的阅读笔记和个人理解. 论文来自<strong>NeurIPS 2020</strong>.</p><p>其实如果只看结构, 比较推荐直接阅读<a href="https://github.com/jik876/hifi-gan" target="_blank" rel="noopener">作者提供的源码</a>.</p><h2 id="HiFi-GAN"><a href="#HiFi-GAN" class="headerlink" title="HiFi - GAN"></a>HiFi - GAN</h2><blockquote><p>Support by <a href="https://chat.deepseek.com" target="_blank" rel="noopener">DeepSeek</a>.</p></blockquote><p>HiFi - GAN是一种声码器(Vocoder), 而Vocoder是一种用于将声学特征(<strong>梅尔频谱</strong>, 线性频谱等)转换为语音波形的技术或模型. 它是语音合成系统中的关键组件, 负责将高层次的声学特征映射为具体的语音信号.</p><p>从HiFi - GAN的结构角度来说, HiFi - GAN由<strong>一个Generator</strong>, <strong>两个Discriminator</strong>组成.</p><h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><p>宏观上, Generator $G$ 是一个<strong>全卷积网络</strong>, 以梅尔谱作为输入, 并以声波作为输出.</p><p>它会被由反卷积和MRF构成的结构上采样$|k_u|$ 次(也就是$|k_u|$ 个子块), 以匹配声波的原始分辨率:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan1.png" style="zoom:50%"><p>其中的Multi - Receptive Field Fusion(MRF)由$|k_r|$ 个连续的ResBlock组成. 第$n$ 个ResBlock中是由LeakyReLU和不同膨胀率$D_r[n]$ 和不同卷积核大小$k_r[n]$ 的CNN组成的.</p><p>MRF的若干个连续ResBlock会将抽取到的<strong>特征全部相加</strong>, 得到下一次上采样之前的特征.</p><blockquote><p>在论文作者公开的代码中有两种ResBlock实现, 一种是将Dilation Rate为<code>[1, 3, 5]</code> 和普通卷积交替使用, 参数相对多. 另外一种只有Dilation Rate仅有<code>[1, 3]</code> 的卷积交替.</p></blockquote><p>事实上, 作者在梅尔谱表示进入MRF前, 使用一个<code>Conv1d</code> 完成梅尔谱的编码, 并在MRF堆叠之后, 使用一个<code>LeakyReLU</code>, 一个<code>Conv1d</code>, 并以最终<code>Tanh</code> 的激活值作为输出:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan2.png" style="zoom:33%"><h3 id="Discriminator"><a href="#Discriminator" class="headerlink" title="Discriminator"></a>Discriminator</h3><h4 id="Multi-Period-Discriminator"><a href="#Multi-Period-Discriminator" class="headerlink" title="Multi - Period Discriminator"></a>Multi - Period Discriminator</h4><p>为了使得Discriminator也编码原始波形的长距离依赖, 作者设计了Multi - Period Discriminator(MPD), 对<strong>不同距离下的波形</strong>做判别, 这似乎是在GAN based Vocoder中的首次提出的.</p><p>将总时长为$T$ 的一维原始波形沿时间取间隔$p$, 将原始波形Reshape成宽为$p$, 高为$\frac{T}{p}$ 的二维数据.</p><p>然后用大小为$p \times 1$ 的二维卷积核, <strong>独立的处理每个Period中的同一个位置的波形数据</strong>. 若如此做, 每个$p \times 1$ 的卷积核会处理从波形中以周期$p$ 均匀采样到的波形数据.</p><blockquote><p>这里提到的二维卷积核, 虽然名义上实现采用的是Conv2d, 但实际上它也可以用Conv1d来实现, 这个二维卷积核仍然是$p \times 1$ 的大小, 每次单独处理的仍然是一个一维数据序列.</p></blockquote><p>下图是一个$p=3$ 的示意图:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan3.png" style="zoom:67%"><p>为了体现”Multi Period”, 作者设置了若干个”Sub discriminator”, 分别设置 <code>[2, 3, 5, 7, 11]</code> 的$p$.</p><p>每个”Sub discriminator” 内部由5个$5 \times 1$ 的Conv2d和Leaky ReLU堆叠构成:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan4.png" style="zoom:33%"><p>堆叠后由一个$5 \times 1$ 的Conv2d完成后处理, 最后将二维展平为一维.</p><h4 id="Multi-Scale-Discriminator"><a href="#Multi-Scale-Discriminator" class="headerlink" title="Multi - Scale Discriminator"></a>Multi - Scale Discriminator</h4><blockquote><p>这个结构在<a href="https://proceedings.neurips.cc/paper/2019/hash/6804c9bca0a615bdb9374d00a9fcba59-Abstract.html" target="_blank" rel="noopener">MelGAN</a>中使用过.</p></blockquote><p>与MPD类似的, Multi - Scale Discriminator(MSD) 由三种不同尺度的”Sub discriminator”组成, 它们分别对<strong>三种不同尺度下的音频声波</strong>做判别: 1x(原尺寸), 2x平均池化, 4x平均池化.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan5.png" style="zoom:67%"><p>每个”Sub discriminator” 内部由若干个分组卷积堆叠而成.</p><h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><p>除了MSD中的第一个Sub Discriminator(在原始波形尺度上的判别器)被应用了<a href="https://arxiv.org/abs/1802.05957" target="_blank" rel="noopener">Spectral Normalization</a>外, 几乎在HiFi - GAN中所有的参数都被施加了<a href="https://arxiv.org/abs/1602.07868" target="_blank" rel="noopener">Weight Norm</a>用于加速训练.</p><p>Weight Norm是一种解耦向量大小和方向的重参数方法, 它将每个参数拆解为方向向量$\mathbf{v}$ 和幅度向量$g$, 用于加速训练:</p><p>$$<br>\mathbf{w} = g \dfrac{\mathbf{v}}{\Vert\mathbf{v}\Vert}<br>$$</p><h3 id="Training-Loss-Terms"><a href="#Training-Loss-Terms" class="headerlink" title="Training Loss Terms"></a>Training Loss Terms</h3><h3 id="GAN-Loss"><a href="#GAN-Loss" class="headerlink" title="GAN Loss"></a>GAN Loss</h3><p>首先是GAN的Adversarial Loss:<br>$$<br>\begin{aligned}<br>&amp; \mathcal{L}_{\text {Adv }}(D ; G)=\mathbb{E}_{(x, s)}\left[(D(x)-1)^2+(D(G(s)))^2\right] \\<br>&amp; \mathcal{L}_{\text {Adv }}(G ; D)=\mathbb{E}_s\left[(D(G(s))-1)^2\right]<br>\end{aligned}<br>$$</p><p>$x$ 为音频的原始波形, $s$ 为输入条件, 在这里是梅尔谱.</p><h3 id="Mel-Spectrogram-Loss"><a href="#Mel-Spectrogram-Loss" class="headerlink" title="Mel - Spectrogram Loss"></a>Mel - Spectrogram Loss</h3><p>梅尔谱Loss就是一个Reconstruction Loss:</p><p>$$<br>\mathcal{L}_{M e l}(G)=\mathbb{E}_{(x, s)}\left[\Vert\phi(x)-\phi(G(s))\Vert_1\right]<br>$$</p><p>其中, $\phi$ 为将梅尔谱转换为波形的函数(这个过程本身就是可微的).</p><h3 id="Feature-Matching-Loss"><a href="#Feature-Matching-Loss" class="headerlink" title="Feature Matching Loss"></a>Feature Matching Loss</h3><p>与<a href="https://proceedings.neurips.cc/paper/2019/hash/6804c9bca0a615bdb9374d00a9fcba59-Abstract.html" target="_blank" rel="noopener">MelGAN</a>相同, 为了使得波形$x$ 与Generator$G$ 生成的波形$G(s)$ 进一步相似, 作者在这里还添加了一个Discriminator $D$ 对$x$ 捕获的特征$D(x)$ 与$D$ 对$G(s)$ 捕获的特征$D(G(s))$ 之间的特征匹配Loss:</p><p>$$<br>\mathcal{L}_{F M}(G ; D)=\mathbb{E}_{(x, s)}\left[\sum_{i=1}^T \frac{1}{N_i}\left\Vert D^i(x)-D^i(G(s))\right\Vert_1\right]<br>$$</p><p>$T$ 为Discriminator的层数, $D^i, N_i$ 分别为Discriminator的第$i$ 层的特征和特征数.</p><h3 id="Final-Loss"><a href="#Final-Loss" class="headerlink" title="Final Loss"></a>Final Loss</h3><p>最终GAN的Loss为:</p><p>$$<br>\begin{aligned}<br>&amp; \mathcal{L}_G=\mathcal{L}_{\text {Adv }}(G ; D)+\lambda_{f m} \mathcal{L}_{F M}(G ; D)+\lambda_{\text {mel }} \mathcal{L}_{M e l}(G) \\<br>&amp; \mathcal{L}_D=\mathcal{L}_{A d v}(D ; G)<br>\end{aligned}<br>$$</p><p>作者设定$\lambda_{fm}=2, \lambda_{mel}=45$.</p><p>由于每个MPD和MSD有多个Sub discriminator, 所以在计算与Discriminator相关的每一项Loss时, 实际上是取每个Sub discriminator的输出结果计算得到的Loss求和最后取平均得到的. 上述Loss的形式化描述为:</p><p>$$<br>\begin{aligned}<br>&amp; \mathcal{L}_G=\sum_{k=1}^K\left[\mathcal{L}_{\text {Adv }}\left(G ; D_k\right)+\lambda_{f m} \mathcal{L}_{F M}\left(G ; D_k\right)\right]+\lambda_{\text {mel }} \mathcal{L}_{M e l}(G) \\<br>&amp; \mathcal{L}_D=\sum_{k=1}^K \mathcal{L}_{A d v}\left(D_k ; G\right)<br>\end{aligned}<br>$$</p><p>其中$D_k$ 代表第$k$ 个MPD或MSD的Sub discriminator.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的模型参数设置和实验设置请参考原论文.</p><p>实验数据集有两个:</p><ul><li><strong>LJSpeech</strong>: 由13100条单Speaker的短时长朗读 7 本纪实类英语书籍的录音组成的数据集, 共计将近24小时, 采样率为22kHz.</li><li><strong>VCTK multi - speaker</strong>: 由44200条109位不同口音的Native English Speaker构成的数据集, 将近44小时, 采样率为44kHz, 作者将其降为22kHz.</li></ul><p>此外, 还设计了三种不同参数规格的HiFi - GAN V1, V2, V3:</p><ul><li>V1参数量最多, 属于常规设置.</li><li>V2是比V1的Hidden Size小很多的版本, 但具有和V1相同大小的感受野, 进需要0.92M参数.</li><li>V3相比于V1具有更少的层数但维持住了感受野大小.</li></ul><h3 id="MOS-Score"><a href="#MOS-Score" class="headerlink" title="MOS Score"></a>MOS Score</h3><blockquote><p>Support by <a href="https://chat.deepseek.com" target="_blank" rel="noopener">DeepSeek</a>.</p></blockquote><p><strong>MOS Score(Mean Opinion Score, 平均意见分数)</strong> 是一种用于评估合成语音质量的主观评价指标. 它通过人类听众对语音的自然度, 清晰度, 流畅度等方面进行打分, 从而反映合成语音的整体质量. 通常采用1到5分的评分标准:</p><ul><li><strong>1分</strong>: 质量极差, 完全无法理解.</li><li><strong>2分</strong>: 质量差, 理解困难.</li><li><strong>3分</strong>: 质量一般, 可以理解但不够自然.</li><li><strong>4分</strong>: 质量良好, 接近自然语音.</li><li><strong>5分</strong>: 质量优秀, 与自然语音几乎无差别.</li></ul><p>对于所有音频质量的主观评估, 采用MOS作为评估指标. 作者是在Amazon Mechanical Turk上对结果进行的众包测试.</p><h3 id="Audio-Quality-and-Synthesis-Speed"><a href="#Audio-Quality-and-Synthesis-Speed" class="headerlink" title="Audio Quality and Synthesis Speed"></a>Audio Quality and Synthesis Speed</h3><p>作者进行了LJSpeech上反演频谱的MOS Test, 结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan6.png" style="zoom:33%"><p>HiFi - GAN在参数量, 推理速度占优势的情况下能达到更好的性能, 而且在参数量相对少得多的设置下仍然能取得比先前方法更好或相近的表现, 尤其是在GPU推理加速的情况下速度非常快, 能满足Vocoder的实时推理需求. 这都体现出HiFi - GAN作为Vocoder的潜力.</p><p>此外, 能够观察到, GAN based Method在参数量和推理速度上都有优势.</p><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p>下面作者在LJSpeech上进行了消融实验:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan7.png" style="zoom:33%"><p>在去掉MPD后, HiFi - GAN的性能有显著的下降, 同时在给MelGAN加上MPD后, MelGAN的性能有了显著的提升, 这证明了MPD的建模有效性, 也说明了在Vocoder中的长距离依赖建模是比较重要的. 此外, 梅尔谱Loss也会有比较大的影响.</p><h3 id="Generalization-to-Unseen-Speakers"><a href="#Generalization-to-Unseen-Speakers" class="headerlink" title="Generalization to Unseen Speakers"></a>Generalization to Unseen Speakers</h3><p>为了验证HiFi - GAN的泛化能力, 作者将HiFi - GAN直接在Unseen Speaker Dataset(VCTK multi - speaker)上进行推理, 结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan8.png" style="zoom:33%"><p>HiFi - GAN的表现甚至快接近于Ground Truth.</p><h3 id="End-to-End-Speech-Synthesis"><a href="#End-to-End-Speech-Synthesis" class="headerlink" title="End-to-End Speech Synthesis"></a>End-to-End Speech Synthesis</h3><p>最后作者直接把HiFi - GAN放到TTS任务上, 用Tacotron2完成文本到梅尔谱的生成, 然后直接用Vocoder解码, 做了微调和不微调两种:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan9.png" style="zoom:33%"><p>无论是否微调, 效果都超过WaveGlow. 微调后效果更好.</p><p>作者认为, 无论是否微调, 最终合成音频的效果都和Ground Truth差距比较大, 作者发现这是Tacotron2本身生成的梅尔谱就比较Noisy了, 所以作者在这个基础上继续对Tacotron2做了微调, 结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/hifi - gan10.png" style="zoom:33%"><p>HiFi - GAN的提升比较明显, 但WaveGlow提升就不是很明显, 这表明HiFi - GAN对E2E的TTS系统适应性比较好.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>HiFi - GAN作为声码器(Vocoder) 中相当具有代表性的作品, 相较于传统的Autoregressive模型有<strong>显著的推理优势</strong>, 性能表现也较好, 尤其是在<a href="https://arxiv.org/abs/2206.04658" target="_blank" rel="noopener">BigVGAN</a>, <a href="https://arxiv.org/abs/2402.00892" target="_blank" rel="noopener">EVA - GAN</a>没有出来之前, HiFi - GAN还是挺能打的.</p><blockquote><p>不过性能表现较好可能也受限于主观评估指标有偏的问题, 按现有经验评价HiFi - GAN是在实际应用中音色很准, 但比较明显的缺点就是容易带电. HiFi - GAN还是在诸多项目中被实际应用过, 例如<a href="https://github.com/babysor/MockingBird" target="_blank" rel="noopener">MockingBird</a>, <a href="https://github.com/openvpi/DiffSinger" target="_blank" rel="noopener">DiffSinger</a> 等.</p></blockquote><p>网络结构也相对比较简单, 不过以现在的眼光来看与CNN相关模型设计的论文感觉无非就是用各种CNN堆<strong>感受野</strong>, 或者用Dilated Convolution堆感受野, 然后再加上一些小Trick… 说实话, 感觉看论文不如直接看代码… 所以这里也直接附上<a href="https://github.com/jik876/hifi-gan" target="_blank" rel="noopener">代码链接</a>, 推荐阅读.</p><p>另外, 这次也是首次尝试将LLM用于博客写作中, 能够灵活运用LLM节省自己的搜索时间还是非常方便的.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/43190.html">https://ADAning.github.io/posts/43190.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span> </a><a href="/tags/Vocoder/"><span class="chip bg-color">Vocoder</span> </a><a href="/tags/TTS/"><span class="chip bg-color">TTS</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/63265.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/21.jpg" class="responsive-img" alt="Whisper: Robust Speech Recognition via Large-Scale Weak Supervision"> <span class="card-title">Whisper: Robust Speech Recognition via Large-Scale Weak Supervision</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Robust Speech Recognition via Large-Scale Weak Supervision本文是论文Robust Speech Recognition via Large-Scale Weak Supervisio</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2025-01-14 </span><span class="publish-author"><i class="fas fa-user fa-fw"></i> DaNing</span></div></div><div class="card-action article-tags"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/ASR/"><span class="chip bg-color">ASR</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/8589.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/18.jpg" class="responsive-img" alt="DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism"> <span class="card-title">DiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanism</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: DDPM: Denoising Diffusion Probabilistic Model. DiffSinger: Singing Voice Synthesis via Shallow Diffusion Me</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2024-10-18 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/Audio/"><span class="chip bg-color">Audio</span> </a><a href="/tags/SVS/"><span class="chip bg-color">SVS</span> </a><a href="/tags/DDPM/"><span class="chip bg-color">DDPM</span> </a><a href="/tags/Diffusion/"><span class="chip bg-color">Diffusion</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">433.1k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>