<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="KG-BERT: BERT for Knowledge Graph Completion, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>KG-BERT: BERT for Knowledge Graph Completion | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/14.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">KG-BERT: BERT for Knowledge Graph Completion</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/BERT/"><span class="chip bg-color">BERT</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-11-28</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-03-27</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.2k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 8 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li>BERT: 详见<a href="https://adaning.github.io/posts/3996.html">ELMo, GPT, BERT</a>.</li></ul></blockquote><p>本文是论文<a href="https://arxiv.org/abs/1909.03193" target="_blank" rel="noopener">KG-BERT: BERT for Knowledge Graph Completion</a>的阅读笔记和个人理解.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>在先前的KGE方法中, 虽然它们能学到独特的实体关系表示, 但是却忽略了<strong>上下文</strong>. <strong>句法</strong>和<strong>语义</strong>信息在大规模文本数据中没有得到很好的利用, 它们仅仅使用了实体描述, 关系提及或者实体共现.</p><p>因为BERT在NLP中作为PLM取得的成果非常亮眼, 所以作者希望将它迁移到知识图谱补全任务中, 测试其在KGC中的性能. BERT是针对自然语言进行处理的, 作者简单的将实体和关系描述放入BERT, 使BERT能够获取KGC的能力, 称之为KG - BERT. 作者称, 这是<strong>第一项</strong>使用PLM对三元组进行建模的研究.</p><h2 id="KG-BERT"><a href="#KG-BERT" class="headerlink" title="KG - BERT"></a>KG - BERT</h2><p>既然BERT是基于自然语言的, 那么很容易就想到用实体和关系的<strong>描述</strong>或者它们的<strong>名字</strong>放入BERT, 然后获得通过某种训练方式得到三元组的表示. 作者设计了两种训练方式的KG - BERT, 这样能使它被运用到不同的知识图谱补全任务当中.</p><h3 id="KG-BERT-a"><a href="#KG-BERT-a" class="headerlink" title="KG - BERT(a)"></a>KG - BERT(a)</h3><p>在第一种方式中, 作者非常朴素的完全沿用了BERT的方法, 将实体, 关系<strong>描述</strong>或名字全部放入BERT中, 并用<code>[CLS]</code>处的隐态输出$C$ 来预测三元组是否正确, 该方式与BERT中的<strong>NSP任务</strong>完全一致. 第一种方式是针对<strong>三元组建模</strong>的.</p><p>例如, 三元组$(\text{SteveJobs}, \text{founded}, \text{AppleInc})$ 中的头实体$\text{SteveJobs}$ 可以表示为它的描述<code>Steven Paul Jobs was an American business magnate, entrepreneur and investor</code> 或者它的名字<code>Steve Jobs</code>, 而尾实体$\text{AppleInc}$ 可以表示为<code>Apple Inc. is an American multinational technology company headquartered in Cupertino, California</code>或者它的名字<code>Apple Inc</code>.</p><blockquote><p>在后续的研究中, NSP已经被证实会在NLP任务中带来<strong>副作用</strong>.</p></blockquote><p>在不同实体和关系之间用<code>[SEP]</code> 进行分隔, 并且每个Token的描述分别由Token本身的Embedding, Segment Embedding, Position Embedding组成. Segment Embedding因<strong>元素类型</strong>不同而不同, 头实体和尾实体都使用$e_A$ 作为Segment Embedding, 而关系采用$e_B$.</p><p>我们把<code>[CLS]</code>处的隐态输出$C$ 用来计算三元组的分类, 对于三元组$(h, r, t)$, 其打分函数为:<br>$$<br>\mathbf{s}_{\tau}=f(h, r, t)=\operatorname{sigmoid}\left(C W^{T}\right)<br>$$<br>其中$W$ 是变换矩阵, 和$C$ 乘完后可以获得三元组是否正确的概率$s_\tau$.</p><blockquote><p>在文中写到, $s_\tau$ 是一个二维向量, 包含$s_{\tau0}, s_{\tau1}$. $s_{\tau0} + s_{\tau1}=1$. 这是不是有点多余了… 其实只需要一个一维的$s_{\tau}$ 就足够了, 因为另一半可以用概率和为1算出来.</p></blockquote><p>现在对前面的模型描述进行总结, 整体结构如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/kgbert1.jpg" style="zoom:33%"><p>其中优化用的损失函数为BCE:<br>$$<br>\mathcal{L}=-\sum_{\tau \in \mathbb{D}+\cup \mathbb{D}^{-}}\left(y_{\tau} \log \left(s_{\tau 0}\right)+\left(1-y_{\tau}\right) \log \left(s_{\tau 1}\right)\right)<br>$$<br>其中$y_\tau$ 是三元组是正例还是负例的标签, 在0和1之间取. $\mathbb{D}^{-}$ 代表负例, $\mathbb{D}^{+}$ 代表正例.</p><p>负样本仍然是<strong>负采样</strong>, 仅替换头实体和尾实体得来的:<br>$$<br>\mathbb{D}^{-}=\left\{\left(h^{\prime}, r, t\right) \mid h^{\prime} \in \mathbb{E} \wedge h^{\prime} \neq h \wedge\left(h^{\prime}, r, t\right) \notin \mathbb{D}^{+}\right\}<br>\cup\left\{\left(h, r, t^{\prime}\right) \mid t^{\prime} \in \mathbb{E} \wedge t^{\prime} \neq t \wedge\left(h, r, t^{\prime}\right) \notin \mathbb{D}^{+}\right\}<br>$$</p><h3 id="KG-BERT-b"><a href="#KG-BERT-b" class="headerlink" title="KG - BERT(b)"></a>KG - BERT(b)</h3><p>在第二种方式中, 作者只使用两个实体$h, t$ 的描述, 来预测它们之间的关系$r$. 在实验中, 作者发现这种结构在预测关系时效果要优于KG - BERT(a).</p><p>KG - BERT(b)采用<code>[CLS]</code> 处的隐态输出$C$ 后接一个分类矩阵来预测两实体之间的关系:<br>$$<br>\mathbf{s}_{\tau}^{\prime}=f(h, r, t)=\operatorname{softmax}\left(C W^{\prime T}\right)<br>$$<br>其中$W$ 为关系的分类矩阵, 多分类也将$\operatorname{sigmoid}$ 换成了$\operatorname{softmax}$.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/kgbert2.jpg" style="zoom:33%"><p>负样本仍然来源于负采样, 只是对正例三元组的关系进行替换即可.</p><p>因为变更了任务, 损失函数不再使用BCE, 而是采用CE进行多分类:<br>$$<br>\mathcal{L}^{\prime}=-\sum_{\tau \in \mathbb{D}^{+}} \sum_{i=1}^{R} y_{\tau i}^{\prime} \log \left(s_{\tau i}^{\prime}\right)<br>$$<br>其中$y_{\tau i}^{\prime}$ 是关系的独热向量.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>在实验中, 作者希望探究KG - BERT的下述能力:</p><ul><li>模型能不能判断没见过的三元组的正确与否?(KG - BERT(a))</li><li>模型能不能根据给出的单个实体和关系描述预测出另一个实体?(Link Prediction)</li><li>模型能不能预测两个实体之间的关系?(KG - BERT(b))</li></ul><p>作者使用BERT - BASE初始化权重, 因为BASE比LARGE版本所受超参影响更小, 可选择的超参也很少. 其余参数设置详见原论文.</p><h3 id="Knowledge-Graph-Compeltion-Tasks"><a href="#Knowledge-Graph-Compeltion-Tasks" class="headerlink" title="Knowledge  Graph Compeltion Tasks"></a>Knowledge Graph Compeltion Tasks</h3><h4 id="Triple-Classification"><a href="#Triple-Classification" class="headerlink" title="Triple Classification"></a>Triple Classification</h4><p>在三元组分类问题上, 作者在WN11和FB13做了实验:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/kgbert3.jpg" style="zoom:33%"><p>KG - BERT效果非常明显, 该任务目标与其训练目标是一致的. 作者将其优秀的表现总结如下:</p><ol><li>输入中含有实体和关系的单词序列(使用了文本描述).</li><li>三元组分类与BERT训练时的NSP任务类似.</li><li>Token Vector结合了上下文, 在不同的三元组中描述往往是不同的, 因此不同三元组中的相同元素能获得不同表示.</li><li>Self - Attention很强.</li></ol><p>作者绘制了测试集准确率随训练集数据量提升的变化曲线:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/kgbert4.jpg" style="zoom:33%"><p>WN11(左), FB13(右). KG - BERT从开始就优于其他模型, 得益于BERT强大的特征抽取能力.</p><h4 id="Link-Prediction"><a href="#Link-Prediction" class="headerlink" title="Link Prediction"></a>Link Prediction</h4><p>在链接预测上, 作者对多种模型在WN18RR和FB15k - 237上, 以及UMLS上做了测试:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/kgbert5.jpg" style="zoom:33%"><p>KG - BERT(a)在MR上取得了很好的效果, 但是Hits@10的表现总比MR差很多, 作者对其的解释是KG - BERT虽然能避免实体和关系相关性很强的相似三元组, 但是没有对<strong>三元组本身</strong>进行<strong>明确</strong>的建模, 因此不好给定它们的准确排名.</p><blockquote><p>虽然作者在论文中没有明确写出模型输入数据的方法, 但大致能够猜到是对每个实体挨个替换实体描述.</p></blockquote><h4 id="Relation-Prediction"><a href="#Relation-Prediction" class="headerlink" title="Relation Prediction"></a>Relation Prediction</h4><p>作者在FB15k上测试了KG - BERT(b)关系预测的性能:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/kgbert6.jpg" style="zoom:50%"><p>碍于打分函数和模型方法的限制, 没有Conv系列的模型登场. KG - BERT在诸多模型中取得了最好的成绩.</p><h3 id="Attention-Visualization"><a href="#Attention-Visualization" class="headerlink" title="Attention Visualization"></a>Attention Visualization</h3><p>对<strong>注意力可视化</strong>能增强模型的可解释性, 也能一定程度上观察模型所学到的东西是否有效. 我认为这部分可以算作是本文的亮点之一.</p><p>作者从KG - BERT(a)取出第11层, 从WN18RR中取出的正例三元组<code>(twenty dollar bill NN 1,hypernym,note NN 6)</code>作为例子, 绘制Attention的可视化情况. 以头实体描述为<code>a United States bill worth 20 dollars</code>, 关系名<code>hypernym</code>, 尾实体描述<code>a piece of paper money</code>, 作为输入序列:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/kgbert7.jpg" style="zoom:50%"><p>第11层中<code>paper</code>, <code>money</code>具有很高的权重, <code>worth</code>, <code>20</code> 具有很低的权重. 抛开句子不谈, 模型很好的学到了<code>[SEP]</code>的作用, 因为它在不同的头之间多多少少分配了一些权重.</p><p>在KG - BERT(b)中, 以三元组<code>(20th century, /time/event/includes event, World War II)</code>为例:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/kgbert8.jpg" style="zoom:50%"><p>能看到b学到了类似a的模式. 但在这个例子中似乎每个头的注意力更为分散. KG - BERT(b)的目标是对实体进行关系预测, 所以对<code>[CLS]</code> 分配了更高的权重.</p><h3 id="Discussions"><a href="#Discussions" class="headerlink" title="Discussions"></a>Discussions</h3><p>作者提到, KG - BERT现在最大的问题还是<strong>计算成本</strong>太过高昂. 尤其是在链接预测的Evaluation时, 因为轮流替换实体描述花费了大量的时间. 作者认为可行的方法是使用像ConvE那样的<strong>1 - N Scoring</strong>或者采用更加轻量级的语言模型.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>KG - BERT是BERT最早在KG上的应用. 输入数据的方式也非常的简单, 符合我们的直觉, 效果也还不错. 从现在的眼光来看, 与KG相结合的BERT最好不要再使用之前的训练方式.</p><p>缺点是没有对三元组进行直接的建模, 计算成本比较高.</p><p>只是NSP任务在BERT上已经被证明会给BERT带来副作用, 如果要沿用KG - BERT的训练方式, 就需要对NSP任务在KG - BERT上的效果进行研究, 如果去掉NSP任务需要用什么任务来代替?</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/18273.html">https://ADAning.github.io/posts/18273.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/BERT/"><span class="chip bg-color">BERT</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/40162.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/10.jpg" class="responsive-img" alt="基于轻量级卷积和动态卷积替代的注意力机制"> <span class="card-title">基于轻量级卷积和动态卷积替代的注意力机制</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: Depthwise Convolution: 详见深度可分离卷积与分组卷积. Attention: 详见Seq2Seq和Attention. Transformer: 详见Transformer精讲. 本文是论文PA</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-12-05 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/CNN/"><span class="chip bg-color">CNN</span> </a><a href="/tags/Attention/"><span class="chip bg-color">Attention</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/42031.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/6.jpg" class="responsive-img" alt="ConvE: Convolutional 2D Knowledge Graph Embeddings"> <span class="card-title">ConvE: Convolutional 2D Knowledge Graph Embeddings</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: CNN 本文是论文Convolutional 2D Knowledge Graph Embeddings的阅读笔记和个人理解. 与之前在AcrE中提到的ConvE不同, 本文重新对整篇论文进行叙述, 而非仅介绍论文中</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-11-27 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></span></div></div><div class="card-action article-tags"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/CNN/"><span class="chip bg-color">CNN</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">358.1k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>