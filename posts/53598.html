<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="Introduction: Variational Auto - Encoder, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>Introduction: Variational Auto - Encoder | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/22.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Introduction: Variational Auto - Encoder</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/VAE/"><span class="chip bg-color">VAE</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2021-07-09</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-06-24</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.9k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 11 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="Introduction-Variational-Auto-Encoder"><a href="#Introduction-Variational-Auto-Encoder" class="headerlink" title="Introduction: Variational Auto - Encoder"></a>Introduction: <strong>V</strong>ariational <strong>A</strong>uto - <strong>E</strong>ncoder</h1><p>变分自动编码器(<strong>VAE</strong>, <strong>V</strong>ariational <strong>A</strong>uto - <strong>E</strong>ncoder)是一种基于自编码器结构的<strong>深度生成模型</strong>.</p><p>本文对VAE更深层次的数学原理没有探讨, 一般概率基础即可放心食用, 更深层次的数学原理在文末深入阅读处给出.</p><p>VAE与GAN有非常紧密的关系, GAN之后找个机会细说(先挖坑).</p><h2 id="自编码器"><a href="#自编码器" class="headerlink" title="自编码器"></a>自编码器</h2><blockquote><p>本节图片全部出自<a href="https://towardsdatascience.com/applied-deep-learning-part-3-autoencoders-1c083af4d798" target="_blank" rel="noopener">Applied Deep Learning - Part 3: Autoencoders</a>.</p></blockquote><p>在介绍VAE之前, 必须要简要介绍一下<strong>自编码器</strong>(<strong>AE</strong>, <strong>A</strong>uto - <strong>E</strong>ncoder).</p><p>自编码器是一种先把输入数据压缩为某种编码, 后仅通过该编码<strong>重构</strong>出原始输入的结构. 从描述来看, AE是一种<strong>无监督</strong>方法.</p><p>AE的结构非常明确, 需要有一个<strong>压缩编码</strong>的Encoder和就一个相应<strong>解码重构</strong>的Decoder:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae1.png" style="zoom:50%"><p>Encoder能够将给定的输入$X$ 映射为<strong>编码</strong>$Z$, 即$Z=g(X)$, Decoder能将编码$Z$ 映射回与原输入相似的$\hat{X}$, 即$\hat{X}=f(Z)$. $Z$ 也被称为<strong>隐变量</strong>, 其维度必须是远远小于$X$ 的, 否则就达不到压缩编码的目的.</p><p>如果Decoder能仅依赖Encoder生成的编码$Z$ 尽可能好的还原输入数据, 那么就说明$Z$ 中真的存在某种能表征原始输入$X$ 的信息, 甚至$Z$ 的每一维都可能对应着某个输入数据变化的具体含义, 例如人脸的笑容, 褶皱, 皮肤颜色等属性.</p><p>对于压缩编码和解码重构的结构, 使用普通的神经网络, 只需要让神经元的个逐渐减少到编码的维度, 再由编码维度逐渐增大到原输入维度:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae2.png" style="zoom:50%"><blockquote><p>Encoder和Decoder的不一定是完全对称的, 甚至也不一定是同质的.</p></blockquote><p>我们希望Auto Encoder所重构的输入$\hat{X}$ 和真正输入$X$ 的差距越小越好, 所以通常使用均方误差(MSE)来作为AE的损失函数, 即$\mathcal{L}_{MSE}=\Vert X - \hat{X} \Vert ^ 2$.</p><p>AE有一种常见的变形, 称为<strong>去噪自编码器</strong>(Denoising Auto - Encoder). 这种AE在原始输入数据的基础上添加了<strong>噪声</strong>, 然后再将其送给AE, 并要求Decoder还原出不带噪声的输入数据. 这就要求Encoder和Decoder具有更强大的能力:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae3.png" style="zoom:50%"><p>AE不是我们今天的重点, 就不再展开说了.</p><p>仔细想想, Auto Encoder虽然是可以分成Encoder和Decoder两个部分, 但实际上Encoder和Decoder是没法作为两个组件单独使用的, 它们必须配套使用.</p><p>例如我们想用单独使用Decoder做生成, 我们只能把随机生成的向量输入到Decoder中, 强行让Decoder解码出一个极少概率有用的内容, 效果一定不会很好. 因为在训练时, Decoder获得的编码全部是来自于Encoder的, 而我们直接随机采样得到的向量与Encoder压根没有关联, 让Decoder解码出有效的结果是不可能的.</p><h2 id="变分自编码器"><a href="#变分自编码器" class="headerlink" title="变分自编码器"></a>变分自编码器</h2><blockquote><p>本节图片出自<a href="https://www.jeremyjordan.me/variational-autoencoders/" target="_blank" rel="noopener">Variational autoencoders.</a>, 内容讲解参考苏神的博客.</p></blockquote><p><strong>变分自编码器</strong>(<strong>VAE</strong>, <strong>V</strong>ariational <strong>A</strong>uto - <strong>E</strong>ncoder)从概率的角度描述隐空间与输入样本.</p><h3 id="隐变量-概率分布式"><a href="#隐变量-概率分布式" class="headerlink" title="隐变量 - 概率分布式"></a>隐变量 - 概率分布式</h3><p>理想形态下的生成模型可以被描述为$X = g(Z)$. 由于没法直接知道$p(X)$, 我们得引入隐变量$Z$ 来求:<br>$$<br>p(X) = \sum_Z p(X\mid Z) p(Z)<br>$$</p><p>如果我们能把输入样本$X$ 编码得到的$Z$ 控制在我们已知的某个分布中, 那么我们就可以从隐变量的分布中采样, 解码得到生成内容$\hat{X}$, 也算不错.</p><p>在这样的想法下, 将样本的隐变量建模为<strong>概率分布</strong>, 而非像AE一样把隐变量看做是离散的值:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae5.png" style="zoom:67%"><p>AE将样本编码为离散的点, 而VAE将样本编码为概率分布, 直接点就是给隐变量<strong>添加噪声</strong>.</p><p>那么在Decoder解码时, 从隐变量中<strong>随机采样</strong>, 得到采样后的向量作为Decoder的输入:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae4.png" style="zoom:67%"><p>沿着这个思路, 如果假设$p(Z) \sim \mathcal{N}(\mu, \sigma^2)$, 可以从其中采样得到$Z_1, Z_2 , \dots, Z_n$, 然后由生成模型得到$\hat{X}_1 = g(Z_1),\hat{X}_2 = g(Z_2),\dots,\hat{X}_n = g(Z_n)$, 但我们根本没法度量生成的结果$\{\hat{X}_1,\hat{X}_2,\dots,\hat{X}_n\} $ 和样本数据$\{X_1,X_2,\dots,X_n\}$ 之间的差异, 因为我们压根不知道$Z_k, X_k, \hat{X}_k$ 之间的<strong>对应关系</strong>.</p><p>没有$X, \hat{X}$ 分布的表达式, 我们就没有办法通过对齐二者分布的方法来优化模型.</p><p>所以, 我们应该在给定真实样本$X_k$ 的情况下, 假设存在分布$p(Z \mid X_k) \sim \mathcal{N}(\mu, \sigma^2)$. Decoder就可以把$p(Z \mid X_k)$ 中采样得到的$Z_k$ 还原为$X_k$, 这样保证$Z_k, X_k, \hat{X}_k$ 之间可以对应.</p><p>尽管分布内采样到的隐变量的值<strong>不完全相同</strong>, 但都应该重建回相同的输出, 这也就是把<strong>样本编码为概率分布</strong>的真正含义:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae6.png" style="zoom:67%"><p><strong>每一个样本都对应着一个自己专属的正态分布</strong>, 样本之间必定存在重合, 当采样到两个样本叠加的区域时, 解码的内容会变得介于二者之间. 按照AE中的假设, 隐变量的每维都可能有具体的含义. 若是如此, 在概率分布视角下的隐变量就可以等距采样, 通过观察控制生成的内容. 例如:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae10.jpg" style="zoom:67%"><p>从满月到半月等距采样, 应该能观察到由满月逐渐变到半月的所有月相.</p><blockquote><p>本图出自<a href="https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/GAN%20(v3).pdf" target="_blank" rel="noopener">李宏毅老师课程配套Slide</a>.</p></blockquote><p>那每个分布的均值和方差要怎么求出来呢? 没什么好方法, 用神经网络来直接拟合样本对应的正态分布的均值$\mu$ 和方差$\sigma^2$ 吧:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae7.png" style="zoom:67%"><blockquote><p>但我们实际上拟合的是$\log \sigma^2$, 因为$\sigma^2$ 非负, 想要让变为负数需要加激活函数处理, 而$\log \sigma^2$ 可以直接在不加激活函数的情况下变为负值.</p></blockquote><h3 id="KL散度-防止神经网络偷懒"><a href="#KL散度-防止神经网络偷懒" class="headerlink" title="KL散度 - 防止神经网络偷懒"></a>KL散度 - 防止神经网络偷懒</h3><p>神经网络一看拟合$\mu, \sigma^2$ 的任务, 心想: “采样得到的$Z$ 是包含噪声的, 重构起来多难啊, 我直接让方差$\sigma^2$ 学出个0来, 我学一个点的拟合肯定比学一个分布的拟合简单, 美滋滋”.</p><p>神经网络很容易过拟合, 把方差学成0, 那就坏了. 如果把样本重新映射回一个点, 那么VAE就直接退化回了AE. 所以我们还是希望$Z$ 是含有噪音的(方差不为0)的分布.</p><p>对于我们之前的假设$p(Z \mid X) \sim \mathcal{N}(\mu, \sigma^2)$ 要更严格, 不但要约束$\sigma^2 \neq 0$, 还要令方差不能太大, 也不能太小.</p><p>但如果假设$p(Z \mid X) \sim \mathcal{N}(0, I)$, 还保证了模型的<strong>生成能力</strong>:</p><p>$$<br>\begin{aligned}<br>p(Z) = &amp; \sum_X p(Z \mid X) p(X) \\<br>= &amp; \sum_x \mathcal{N}(0, I) p(X)\\<br>= &amp; \mathcal{N}(0, I) \sum_X p(X) \\<br>= &amp; \mathcal{N}(0, I)<br>\end{aligned}<br>$$</p><p>在该条件下$p(Z) \sim \mathcal{N}(0, I)$, 当脱离Encoder, 即不依靠输入样本$X$ 时, 我们可以直接从$\mathcal{N}(0, I)$ 中采样来生成可靠的结果.</p><p>我们直接使用KL散度来约束$p(Z \mid X)$, 令其服从标准正态分布.</p><blockquote><p><strong>KL散度</strong>(也称为<strong>相对熵</strong>)常用于度量两个分布之间的差异性, 假设$P$ 为样本真实分布, $Q$ 为模型预测的分布, 根据KL散度有:<br>$$<br>D_{\mathrm{KL}}(P \| Q)=\mathbb{E}_{\mathrm{x} \sim P}\left[\log \frac{P(x)}{Q(x)}\right]=\mathbb{E}_{\mathrm{x} \sim P}[\log P(x)-\log Q(x)]<br>$$<br>当$P, Q$ 越接近时, $D_{\mathrm{KL}}(P \| Q)$ 就越小, 当$P, Q$ 分布完全相同时, $D_{\mathrm{KL}}(P \| Q)$ 为0.</p><p>KL散度还有两个性质:</p><ol><li>非负: KL散度是非负的.</li><li>不对称: 通常情况下, $D_{\mathrm{KL}}(P \| Q) \neq D_{\mathrm{KL}}(Q \| P)$, KL散度并不是真正意义上的距离.</li></ol></blockquote><p>求解过程如下:</p><p>$$<br>\begin{aligned}<br>&amp;KL\Big(N(\mu,\sigma^2)\Big\Vert N(0,1)\Big)\\<br>=&amp;\int \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x-\mu)^2/2\sigma^2} \left(\log \frac{e^{-(x-\mu)^2/2\sigma^2}/\sqrt{2\pi\sigma^2}}{e^{-x^2/2}/\sqrt{2\pi}}\right)dx\\\<br>=&amp;\int \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x-\mu)^2/2\sigma^2} \log \left\{\frac{1}{\sqrt{\sigma^2}}\exp\left\{\frac{1}{2}\big[x^2-(x-\mu)^2/\sigma^2\big]\right\} \right\}dx\\\<br>=&amp;\frac{1}{2}\int \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(x-\mu)^2/2\sigma^2} \Big[-\log \sigma^2+x^2-(x-\mu)^2/\sigma^2 \Big] dx \\<br>=&amp;\frac{1}{2}(-\log\sigma^2+\mu^2+\sigma^2-1)<br>\end{aligned}<br>$$</p><p>求解时, 需要<strong>最小化</strong>KL散度.</p><p>VAE常用的损失函数为:<br>$$<br>\begin{aligned}<br>\mathcal{L} = &amp; \mathcal{L}_\mathrm{Recon} + \mathcal{L}_\mathrm{KL} \\<br>= &amp; \mathcal{D}(\hat{X}_k,X_k)^2 + KL\Big(N(\mu,\sigma^2)\Big\Vert N(0,1)\Big)<br>\end{aligned}<br>$$<br>即重构损失和KL散度两部分.</p><h3 id="梯度断裂-重参数"><a href="#梯度断裂-重参数" class="headerlink" title="梯度断裂 - 重参数"></a>梯度断裂 - 重参数</h3><p>我们想要用梯度下降来优化$p(Z \mid X_k)$ 的均值$\mu$ 和方差$\sigma $, 但”采样”这个操作是<strong>不可导</strong>的, VAE利用<strong>重参数化技巧</strong>(Reparameterization Trick)使得梯度不因采样而断裂.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae8.png" style="zoom:67%"><blockquote><p>图片来自<a href="https://www.jeremyjordan.me/variational-autoencoders/" target="_blank" rel="noopener">Variational autoencoders.</a></p></blockquote><p>原理很简单, $Z$ 的导数可以写成:<br>$$<br>\begin{aligned}&amp;\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(z-\mu)^2}{2\sigma^2}\right)dz \\<br>=&amp; \frac{1}{\sqrt{2\pi}}\exp\left[-\frac{1}{2}\left(\frac{z-\mu}{\sigma}\right)^2\right]d\left(\frac{z-\mu}{\sigma}\right)<br>\end{aligned}<br>$$<br>说明$(z - \mu) / \sigma^2 \sim \mathcal{N}(0, I)$, 从$\mathcal{N}(\mu, \sigma^2)$ 中采样, 就等价与从标准正态分布$\mathcal{N}(0, I)$ 中采样出一个$\epsilon$, 然后再通过$Z= \mu + \epsilon \times \sigma$ 缩放回去. 采样的导致梯度断裂的锅就丢给了$\epsilon$ 这个无关变量, 使得$\mu, \sigma^2$ 可以重新参与到梯度下降中优化:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/vae9.png" style="zoom:67%"><h2 id="深入阅读及参考资料来源"><a href="#深入阅读及参考资料来源" class="headerlink" title="深入阅读及参考资料来源"></a>深入阅读及参考资料来源</h2><ul><li><p>视频推荐:</p><ol><li>强推李宏毅: <a href="https://www.bilibili.com/video/BV1Wv411h7kN" target="_blank" rel="noopener">李宏毅2021春机器学习课程</a> 的<a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=44" target="_blank" rel="noopener">p44</a> 和<a href="https://www.bilibili.com/video/BV1Wv411h7kN?p=45" target="_blank" rel="noopener">p45</a>, 以及其<a href="https://speech.ee.ntu.edu.tw/~tlkagk/courses/ML_2017/Lecture/GAN%20(v3).pdf" target="_blank" rel="noopener">配套的Slide</a></li><li>通俗篇: <a href="https://www.bilibili.com/video/BV1hf4y1r7C7" target="_blank" rel="noopener">变分自动编码器(Variational AutoEncoder, VAE)，直观理解、数学推导与最新应用</a></li><li>硬核篇: <a href="https://www.bilibili.com/video/BV1q64y1y7J2" target="_blank" rel="noopener">[论文简析]VAE: Auto-encoding Variational Bayes[1312.6114]</a></li></ol></li><li><p>文章推荐 - 苏神系列博客:</p><ol><li><a href="https://spaces.ac.cn/archives/5253" target="_blank" rel="noopener">变分自编码器（一）：原来是这么一回事</a></li><li><a href="https://kexue.fm/archives/5343" target="_blank" rel="noopener">变分自编码器（二）：从贝叶斯观点出发</a></li><li><a href="https://kexue.fm/archives/5383" target="_blank" rel="noopener">变分自编码器（三）：这样做为什么能成？</a></li><li><a href="https://kexue.fm/archives/7725" target="_blank" rel="noopener">变分自编码器（六）：从几何视角来理解VAE的尝试</a></li></ol></li><li><p>外文文章推荐:</p><ol><li>VAE原论文: <a href="https://arxiv.org/abs/1312.6114" target="_blank" rel="noopener">Auto-Encoding Variational Bayes</a></li><li>关于重参数: <a href="http://gregorygundersen.com/blog/2018/04/29/reparameterization/" target="_blank" rel="noopener">The Reparameterization Trick</a></li></ol></li></ul><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>VAE是一个有严格数学推导的模型, 但在学的时候千万不要被”变分”二字给唬住了, 变分二字只是来源于VAE推导过程中所使用的KL散度.</p><p>实际上, VAE由于把样本编码为概率分布, 生成的实际上是训练样本之间的<strong>平均</strong>, 在样本的<strong>分布叠加</strong>后(高斯混合模型), VAE记录了一个样本到另一个样本之间的<strong>演化过程</strong>. 这也就是为什么VAE生成的结果会存在<strong>模糊</strong>的问题, 但仍然不妨碍它成为最强大的深度生成模型之一.</p><p>强烈推荐看苏神的博客, 苏神的见解要深刻得多.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/53598.html">https://ADAning.github.io/posts/53598.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/VAE/"><span class="chip bg-color">VAE</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/9047.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/1.jpg" class="responsive-img" alt="Pytorch实现: VAE"> <span class="card-title">Pytorch实现: VAE</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: VAE基本原理: 详见变分自编码器入门. Pytorch实现: VAE本文是VAE的Pytorch版本实现, 并在末尾做了VAE的生成可视化. 本文的代码已经放到了Colab上, 打开设置GPU就可以复现(需要科学上</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-07-10 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/VAE/"><span class="chip bg-color">VAE</span> </a><a href="/tags/Pytorch/"><span class="chip bg-color">Pytorch</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/39586.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/11.jpg" class="responsive-img" alt="知识蒸馏: Distilling the Knowledge in a Neural Network"> <span class="card-title">知识蒸馏: Distilling the Knowledge in a Neural Network</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Distilling the Knowledge in a Neural Network本文是论文Distilling the Knowledge in a Neural Network的阅读笔记和个人理解. Basic Idea现有机器学</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-07-03 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/KD/"><span class="chip bg-color">KD</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">383.8k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>