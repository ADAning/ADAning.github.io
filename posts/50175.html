<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="SPN: Joint Entity and Relation Extraction with Set Prediction Networks, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>SPN: Joint Entity and Relation Extraction with Set Prediction Networks | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/20.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">SPN: Joint Entity and Relation Extraction with Set Prediction Networks</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-06-22</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2023-02-11</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 12 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="Joint-Entity-and-Relation-Extraction-with-Set-Prediction-Networks"><a href="#Joint-Entity-and-Relation-Extraction-with-Set-Prediction-Networks" class="headerlink" title="Joint Entity and Relation Extraction with Set Prediction Networks"></a>Joint Entity and Relation Extraction with Set Prediction Networks</h1><p>本文是论文<a href="https://arxiv.org/abs/2011.01675" target="_blank" rel="noopener">Joint Entity and Relation Extraction with Set Prediction Networks</a> 的阅读笔记和个人理解.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>现有的基于Seq2Seq的方法, 在训练阶段需要将<strong>三元组集合</strong>转化为<strong>Sequence</strong>输入到模型中, 这样存在预测<strong>三元组之间顺序</strong>的问题, 但实际上句子中抽取出的三元组是<strong>无序</strong>的. 作者希望将RTE问题转化直接的<strong>集合预测</strong>问题, 并使用<strong>非自回归Decoder</strong>来解决集合预测问题.</p><h2 id="SPN"><a href="#SPN" class="headerlink" title="SPN"></a>SPN</h2><h3 id="Task-Definition"><a href="#Task-Definition" class="headerlink" title="Task Definition"></a>Task Definition</h3><p>对与输入序列$X$, Relational Triple Extraction的任务目标是抽取所有目标三元组$Y=\set{(s_1, r_1, o_1), \dots, (s_n, r_n, o_n)}$, 其条件概率为:</p><p>$$<br>P(Y \mid X ; \theta)=p_{L}(n \mid X) \prod_{i=1}^{n} p\left(Y_{i} \mid X, Y_{j \neq i} ; \theta\right)<br>$$</p><p>其中$p_L(n|X)$ 建模了句子中目标三元组的数量, $p\left(Y_{i} \mid X, Y_{j \neq i} ; \theta\right)$ 代表目标三元组$Y_i$ 与句子中其他存在的三元组$Y_{j \neq i}$和输入序列$X$ 同时相关.</p><h3 id="Sentence-Encoder"><a href="#Sentence-Encoder" class="headerlink" title="Sentence Encoder"></a>Sentence Encoder</h3><p>Sentence Encoder直接用<strong>BERT</strong>, 提取到的特征为$\mathbf{H}_e \in \mathbb{R} ^{l \times d}$, $l$ 为包括<code>[CLS]</code>和<code>[SEP]</code>的序列长度.</p><h3 id="Non-Autoregressive-Decoder-for-Triple-Set-Generation"><a href="#Non-Autoregressive-Decoder-for-Triple-Set-Generation" class="headerlink" title="Non - Autoregressive Decoder for Triple Set Generation"></a>Non - Autoregressive Decoder for Triple Set Generation</h3><blockquote><p>首先来介绍下, <strong>Non - Autoregressive Decoder</strong>(<strong>NAD</strong>)最早使用在机器翻译中, 与三元组抽取问题出发点完全不同. 生成译文时如果是自回归的方式太<strong>慢</strong>了, 非自回归的生成方式可以<strong>一次性</strong>生成所有译文. 具体的, 在Decoder进行解码时并非一步一步的遵循自回归将输入反复喂入Decoder中得到单步生成内容, 而是使用多个Query向量同时喂入Decoder中以得到全部的生成内容:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn1.png" style="zoom:25%"><p>该图出自最早采用NAD的论文<a href="https://arxiv.org/abs/1711.02281" target="_blank" rel="noopener">Non-Autoregressive Neural Machine Translation</a>, 当时所使用的方法是将输入端内容复制多次喂入Decoder, 与现在使用的Query Embedding相似.</p></blockquote><h4 id="Input"><a href="#Input" class="headerlink" title="Input"></a>Input</h4><p>现在我们回归正题. 前人已有方法往往将三元组抽取建模为<strong>序列生成</strong>问题, 由于使用的是自回归Deocder, 模型生成三元组时明显存在三先后生成顺序的问题:<br>$$<br>P(Y \mid X ; \theta)=\prod_{i=1}^{n} p\left(Y_{i} \mid X, Y_{j&lt;i} ; \theta\right)<br>$$</p><p>而作者将三元组抽取视为一个用NAD完成的<strong>集合预测</strong>问题, 式子同Task Definition中给出的句子中所有目标三元组条件概率公式:<br>$$<br>P(Y \mid X ; \theta)=p_{L}(n \mid X) \prod_{i=1}^{n} p\left(Y_{i} \mid X, Y_{j \neq i} ; \theta\right)<br>$$<br>在解码前, Decoder需要知道句子中的目标三元组个数. 作者简单的设$p_L(n|X)$ 为一个常数. 对于每个句子, Decoder需要预测比句子Ground Truth中三元组数量$n$ 稍大一点的固定的集合数$m$, 以达到三元组全覆盖的效果. 具体的, 在词表中添加$m$ 个可学习的Query Embedding, 在Decoder解码时一次性输入即可.</p><h4 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h4><p>SPN的模型结构本身其实比较简单, 就是由BERT和NAD以及最后分类用的FFN组成:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn2.png" style="zoom:33%"><p>将$m$ 个三元组Query Vector同时输入NAD, 同时获得所有三元组表示记为$\mathbf{H}_d \in \mathbb{R}^{m \times d}$, Decoder生成的三元组中的关系和实体由不同的FFN得到.</p><blockquote><p>由于使用的是NAD, 所有三元组是被一次性生成的, 所以Decoder可以做到双向解码, 同Encoder的双向上下文.</p></blockquote><p>每个Decoder的输出$\mathbf{h}_d \in \mathbb{R}^d$, 目标三元组对应的关系$r$ 的概率$\mathbf{p}^r$ 可以由下式得到:<br>$$<br>\mathbf{p}^{r}=\operatorname{softmax}\left(\mathbf{W}_{\mathbf{r}} \mathbf{h}_{\mathrm{d}}\right)<br>$$</p><p>其中, $\mathbf{W}_r$ 为可训练参数.</p><p>每个目标三元组中的实体由<strong>起始</strong>位置和<strong>结束</strong>位置分别确定, 也就是做$l$ 分类. Decoder每个输出$\mathbf{h}_d$ 和BERT下的句子输出 $\mathbf{H}_e$ 同时将Subject和Object的下标分别确定下来:<br>$$<br>\begin{aligned}<br>\mathbf{p}^{s-s t a r t} &amp;=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{1}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{1}} \mathbf{h}_{\mathrm{d}}+\mathbf{W}_{\mathbf{2}} \mathbf{H}_{\mathbf{e}}\right)\right) \\<br>\mathbf{p}^{s-e n d} &amp;=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{2}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{3}} \mathbf{h}_{\mathrm{d}}+\mathbf{W}_{\mathbf{4}} \mathbf{H}_{\mathbf{e}}\right)\right) \\<br>\mathbf{p}^{o-s t a r t} &amp;=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{3}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{5}} \mathbf{h}_{\mathrm{d}}+\mathbf{W}_{\mathbf{6}} \mathbf{H}_{\mathbf{e}}\right)\right) \\<br>\mathbf{p}^{o-e n d} &amp;=\operatorname{softmax}\left(\mathbf{v}_{\mathbf{4}}^{\mathbf{T}} \tanh \left(\mathbf{W}_{\mathbf{7}} \mathbf{h}_{\mathrm{d}}+\mathbf{W}_{\mathbf{8}} \mathbf{H}_{\mathbf{e}}\right)\right)<br>\end{aligned}<br>$$</p><p>其中, $\set{\mathbf{W}_i \in \mathbb{R}^{d \times d}}^8_{i=1}, \set{\mathbf{v}_i \in \mathbb{R}^{d \times d}}^4_{i=1}$ 为可学习参数, $t$ 为包含空关系在内的所有关系总数, $l$ 为句子长度.</p><h3 id="Bipartite-Matching-Loss"><a href="#Bipartite-Matching-Loss" class="headerlink" title="Bipartite Matching Loss"></a>Bipartite Matching Loss</h3><p>由于将联合抽取视为一个<strong>集合预测</strong>问题, 所以在优化时使用自回归时所采用的有序交叉熵就不太合适了, 因为自回归中的交叉熵是对<strong>每个时间步</strong>Decoder的输出分别应用上去的. 但是在三元组抽取任务中, 三元组本身是<strong>无序</strong>的, 模型生成的顺序和Ground Truth不一定完全匹配.</p><p>对此, 作者的解决思路非常简单, 既然原来交叉熵是有序的, 那我做<strong>全排列穷举</strong>出所有的顺序, 找到一个和Ground Truth相匹配的序列不就行了? 没错, 该过程可以抽象为一个<strong>二部图匹配</strong>问题, 需要找到模型预测结果和Ground Truth之间的一个最优匹配结果:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn3.png" style="zoom:25%"><p>假定$\mathbf{Y}=\left\{\mathbf{Y}_{i}\right\}_{i=1}^{n}$ 为Ground Truth, $\hat{\mathbf{Y}}=\left\{\hat{\mathbf{Y}}_{i}\right\}_{i=1}^{m}$ 为模型预测到的三元组. 因为$m$ 比$n$ 要稍大些, 所以把多出来的那部分用空三元组填上.</p><p>更为具体的, 需要找到使得Cost<strong>最小</strong>的三元组排列顺序$\pi^\star$:</p><p>$$<br>\pi^{\star}=\underset{\pi \in \Pi(m)}{\arg \min } \sum_{i=1}^{m} \mathcal{C}_{m a t c h}\left(\mathbf{Y}_{i}, \hat{\mathbf{Y}}_{\pi(i)}\right)<br>$$</p><p>其中$\Pi(m)$ 代表长度为$m$ 的全排列空间, $\mathcal{C}_{m a t c h}\left(\mathbf{Y}_{i}, \hat{\mathbf{Y}}_{\pi(i)}\right)$ 为Ground Truth$\mathbf{Y}_i$ 和排列顺序为$\pi(i)$ 时的模型预测结果$\hat{\mathbf{Y}}_{\pi(i)}$ 之间的Cost.</p><p>接着定义二部图匹配的Cost, 每个三元组实际上由<strong>五元组</strong>确定, 即Ground Truth $\mathbf{Y}_i = \left(r_{i}, s_{i}^{\text {start }}, s_{i}^{e n d}, o_{i}^{\text {start }}, o_{i}^{e n d}\right)$, 模型预测结果 $\hat{\mathbf{Y}}_{i}=\left(\mathbf{p}_{i}^{r}, \mathbf{p}_{i}^{s-s t a r t}, \mathbf{p}_{i}^{s-e n d}, \mathbf{p}_{i}^{o-s t a r t}, \mathbf{p}_{i}^{o-e n d}\right)$, 定义$\mathcal{C}_{m a t c h}\left(\mathbf{Y}_{i}, \hat{\mathbf{Y}}_{\pi(i)}\right)$ 如下:</p><p>$$<br>\begin{aligned}<br>\mathcal{C}_{\text {match}}\left(\mathbf{Y}_{i}, \hat{\mathbf{Y}}_{\pi(i)}\right)<br>&amp;=-\mathbb{1}_{\left\{r_{i} \neq \varnothing\right\}}\left[\mathbf{p}_{\pi(i)}^{r}\left(r_{i}\right)\right.\\<br>&amp;+\mathbf{p}_{\pi(i)}^{s-start}\left(s_{i}^{start}\right) \\<br>&amp;+\mathbf{p}_{\pi(i)}^{s-e n d}\left(s_{i}^{end }\right) \\<br>&amp;+\mathbf{p}_{\pi(i)}^{o- start }\left(o_{i}^{start }\right) \\<br>&amp;+\mathbf{p}_{\pi(i)}^{o-e n d}\left(o_{i}^{end }\right)\left.\right]<br>\end{aligned}<br>$$</p><blockquote><p>在指示函数$\mathbb{1}$ 影响下, $\mathbf{p}_{\pi(i)}^{r}(r_i)$ 就代表模型预测排列为$\pi(i)$ 时关系为$r_i$ 的概率, 对于实体位置的表示同理.</p></blockquote><p>上式即计算预测关系$r_i$ 不为空时, Ground Truth对应的关系类型, Subject, Object的起始位置和结束位置的概率的和.</p><p>如果Ground Truth所对应的预测概率比较大, 那么Cost就比较小, 这种排序就越有可能是对Ground Truth的最优排序.</p><p>作者在这里采用<strong>匈牙利算法</strong>来完成二部图匹配, 由此可以得到Ground Truth所对应的最优模型预测排序, 由此规避生成三元组顺序与Ground Truth不一致的问题.</p><blockquote><p>扩展阅读:</p><ul><li><a href="https://www.bilibili.com/video/BV16K4y1X7Ph" target="_blank" rel="noopener">14-4: 匈牙利算法 Hungarian Algorithm</a>.</li></ul><p>匈牙利算法的作用是找到二部图的最大或最小匹配(要求二部图的两个集合节点数相同), 在这里是找到$\mathbf{Y}$ 和$\hat{\mathbf{Y}}$ 之间Cost的<strong>最小匹配</strong>.</p></blockquote><p>最后按照最优的排列顺序$\pi^\star$ 去计算<strong>负对数似然</strong>, 最大化最优排序下对应的关系预测概率和实体起始结束位置概率:<br>$$<br>\begin{aligned}<br>\mathcal{L}(\mathbf{Y}, \hat{\mathbf{Y}}) &amp;=\sum_{i=1}^{m}\left\{-\log \mathbf{p}_{\pi^{\star}(i)}^{r}\left(r_{i}\right)\right.\\<br>&amp;+\mathbb{1}_{\left\{r_{i} \neq \varnothing\right\}}\left[-\log \mathbf{p}_{\pi^{\star}(i)}^{s-s t a r t}\left(s_{i}^{start }\right)\right.\\<br>&amp;-\log \mathbf{p}_{\pi^{\star}(i)}^{s-e n d}\left(s_{i}^{end}\right) \\<br>&amp;-\log \mathbf{p}_{\pi^{\star}(i)}^{o-s t a r t}\left(o_{i}^{start }\right) \\<br>&amp;\left.\left.-\log \mathbf{p}_{\pi^{\star}(i)}^{o-e n d}\left(o_{i}^{end}\right)\right]\right\}<br>\end{aligned}<br>$$</p><blockquote><p>没理解也不要紧, 原文附录中有一个完整的例子, 可以帮助大家理解二部图匹配损失, 可以自行查阅原论文.</p></blockquote><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的参数设置请参照原论文.</p><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>所采用的数据集是两个常用数据集NYT24和WebNLG, 具体信息如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn4.png" style="zoom:33%"><h3 id="Main-Results"><a href="#Main-Results" class="headerlink" title="Main Results"></a>Main Results</h3><p>在NYT24上, SPN的部分匹配和精准匹配结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn5.png" style="zoom:33%"><p>当时最厉害的SOTA还是<a href="https://adaning.github.io/posts/27105.html">CasRel</a>, SPN超过了CasRel, 实际上也超过了同年的<a href="https://adaning.github.io/posts/49694.html">TPLinker</a>.</p><p>在WebNLG上结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn6.png" style="zoom:33%"><p>在WebNLG上SPN的Recall比CasRel要高得多, 个人认为这种收益来自于比Ground Truth多数量稍一点的Query Embedding, 且和SPN同时抽取实体和关系有关(CasRel是两阶段抽取).</p><p>分类看实体和关系的抽取结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn7.png" style="zoom:33%"><p>CasRel除了在WebNLG的精度上稍稍比SPN好一点, 其余地方都不如SPN.</p><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p>SPN在NYT24上的消融实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn8.png" style="zoom:33%"><p>不使用二部图匹配损失, 而是强套一个交叉熵上去, 严重的影响了Recall, Precision也有很大影响, NAD和二部图匹配损失才是最为重要的核心部分. 从Decoder层数来看的话, 单纯堆叠层出带来的增益没想象中那么小.</p><h3 id="Sentences-with-Different-Number-of-Triples"><a href="#Sentences-with-Different-Number-of-Triples" class="headerlink" title="Sentences with Different Number of Triples"></a>Sentences with Different Number of Triples</h3><p>将句子中的三元组个数进行分类, 结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn9.png" style="zoom:33%"><p>SPN的各类型抽取效果都比CasRel好, 在NYT上的多三元组抽取比CasRel好挺多.</p><h3 id="Different-Overlapping-Patterns"><a href="#Different-Overlapping-Patterns" class="headerlink" title="Different Overlapping Patterns"></a>Different Overlapping Patterns</h3><p>按照不同的重叠类型区分句子, 结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/spn10.png" style="zoom:40%"><p>SPN本身并没有设计特别针对SEO和EPO的优化方法, 似乎对普通三元组的抽取能力提升更大些.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>SPN算是<strong>生成</strong>和<strong>Tagging</strong>混合的RTE模型, 不同于前人所使用的生成式方法, 将三元组抽取完全建模为自回归生成式任务, 而是将RTE建模为<strong>集合预测</strong>问题, 避免了三元组生成时存在的<strong>先后顺序</strong>问题, 同时因为使用了NAD, 获得了<strong>双向解码</strong>的能力, 使得每个三元组生成时都可以考虑到其他三元组的信息.</p><blockquote><p>也是很巧, NAD因为在机器翻译中<strong>难以保证序列</strong>的生成顺序而导致性能降低, 而在RTE问题中根本不需要考虑三元组之间的顺序问题, NAD用在这里非常合适.</p></blockquote><p>SPN性能不错, 相对于模型结构本身, 把三元组抽取建模成<strong>集合预测</strong>的思想倒是比较重要, 在<strong>NAD</strong>的选取和<strong>二部图匹配损失</strong>的设计上都有体现.</p><blockquote><p>另外, 有兴趣的小伙伴可以看看DETR: <a href="https://arxiv.org/abs/2005.12872" target="_blank" rel="noopener">End-to-End Object Detection with Transformers</a>这篇文章, SPN和DETR实际上是几乎一样的.</p></blockquote></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/50175.html">https://ADAning.github.io/posts/50175.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/42381.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/16.jpg" class="responsive-img" alt="RFBFN: A Relation - First Blank Filling Network for Joint Relational Triple Extraction"> <span class="card-title">RFBFN: A Relation - First Blank Filling Network for Joint Relational Triple Extraction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: SPN: SPN: Joint Entity and Relation Extraction with Set Prediction Networks. RFBFN: A Relation - First Blank</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-07-09 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/54052.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/11.jpg" class="responsive-img" alt="GRTE: A Novel Global Feature-Oriented Relational Triple Extraction Model based on Table Filling"> <span class="card-title">GRTE: A Novel Global Feature-Oriented Relational Triple Extraction Model based on Table Filling</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: CasRel: 详见CasRel: A Novel Cascade Binary Tagging Framework for Relational Triple Extraction. TPLinker: 详见TPLin</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-06-02 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">354.4k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>