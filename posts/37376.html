<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="W2NER: Unified Named Entity Recognition as Word - Word Relation Classification, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>W2NER: Unified Named Entity Recognition as Word - Word Relation Classification | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/22.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">W2NER: Unified Named Entity Recognition as Word - Word Relation Classification</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/NER/"><span class="chip bg-color">NER</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-10-16</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-10-16</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.9k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 12 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="W2NER-Unified-Named-Entity-Recognition-as-Word-Word-Relation-Classification"><a href="#W2NER-Unified-Named-Entity-Recognition-as-Word-Word-Relation-Classification" class="headerlink" title="W2NER: Unified Named Entity Recognition as Word - Word Relation Classification"></a>W2NER: Unified Named Entity Recognition as Word - Word Relation Classification</h1><p>本文是论文<a href="http://arxiv.org/abs/2112.10070" target="_blank" rel="noopener">Unified Named Entity Recognition as Word-Word Relation Classification</a> 的阅读笔记和个人理解, 论文来自<strong>AAAI 2022</strong>.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>在之前, NER可以被独立的分为<strong>Flat</strong>, <strong>Overlapped</strong>, <strong>Discontinuous</strong> 三大类. 最近有些工作尝试将上述三类NER归整到一个统一的NER框架当中, 当前主要有<strong>基于Span</strong>的和<strong>Seq2Seq</strong>两大类, 这两类模型要么对<strong>边界识别能力不足</strong>, 要么受到<strong>曝光偏差</strong>影响.</p><blockquote><p>当然, Nested可以视为是一种Overlapped的特殊情况.</p></blockquote><p>作者尝试提出一个<strong>统一</strong>的NER框架W2NER, 将NER转变成一个<strong>单词间</strong>的<strong>关系分类</strong>问题:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner1.png" style="zoom:80%"><p>在上例中, <code>aching in legs</code> 和<code>aching in shoulders</code> 分别是连续实体和不连续实体, 依照Token之间的关系判断可以将它们分离出来.</p><h2 id="W2NER"><a href="#W2NER" class="headerlink" title="W2NER"></a>W2NER</h2><h3 id="NER-as-Word-Word-Relation-Classification"><a href="#NER-as-Word-Word-Relation-Classification" class="headerlink" title="NER as Word-Word Relation Classification"></a>NER as Word-Word Relation Classification</h3><p>无论是对于Flat, Overlapped, Discontinuous这三类NER中的哪一类, 都可以被抽象为从对于给定的$N$ 个Token或单词$X=\set{x_{1,}x_{2,}\dots, x_N}$ 中抽取出Token Pair$(x_{i,}x_j)$ 之间的关系$\mathcal{R}$, 其中$\mathcal{R}$ 可以是$\text{None}$, $\text{Next-Neighboring-Word}$ (NNW), 或者$\text{Tail-Head-Word-}\star$ (THW-*).</p><p>结合下图来说明这三种Token Pair之间的关系的含义:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner2.png" style="zoom:67%"><p>对于每行Token $x_i$ 和每列Token $x_j$, 即Token Pair$(x_{i,}x_j)$, 其之间的关系代表着:</p><ul><li>$\text{None}$: 该Token Pair之间不存在任何关系.</li><li>$\text{Next-Neighboring-Word}$: $(x_{i,}x_j)$ 位于一个实体提及中, 且在该实体提及中, 行Token $x_i$ 是列Token $x_j$ 的<strong>前一个</strong>Token.</li><li>$\text{Tail-Head-Word-}\star$: $(x_{i,}x_j)$ 位于一个实体提及中, 且在该实体提及中, 行Token $x_i$ 是该实体提及的<strong>结束Token</strong>, 列Token $x_j$ 为该实体提及的<strong>起始Token</strong>. $\star$ 代表该实体提及的实体类型.</li></ul><blockquote><p>从标签设计上来说, NNW指明了<strong>Token之间的连续性</strong>. THW指明了<strong>实体边界</strong>和<strong>实体类型</strong>. 熟悉信息抽取这块的小伙伴可能会觉得这个THW有些似曾相识. 在文末Summary我会指出它的来源.</p></blockquote><p>在上图例子中, 实体<code>aching in legs</code>, <code>aching in shoulders</code> 分别是一个连续实体和不连续实体, 它们共享了<code>aching in</code>.</p><p>通过提到的NNW关系, 可以建立<code>(aching -&gt; in)</code>, <code>(in -&gt; legs)</code>, <code>(in -&gt; shoulders)</code> 之间的关联. 然后再通过THW关系, 定位实体的边界和它们对应的类型<code>(legs -&gt; aching, Symptom)</code>, <code>(shoulders -&gt; aching, Symptom)</code>. 我们根据THW反向往回找, 就能解码出对应的整个实体提及了.</p><h3 id="Unified-NER-Framework"><a href="#Unified-NER-Framework" class="headerlink" title="Unified NER Framework"></a>Unified NER Framework</h3><p>整个W2NER的概览图如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner3.png" style="zoom:67%"><p>大致可以分为Encoder Layer, Convolution Layer, Co - Predictor Layer和最后的Decoding.</p><h4 id="Encoder-Layer"><a href="#Encoder-Layer" class="headerlink" title="Encoder Layer"></a>Encoder Layer</h4><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner4.png" style="zoom:50%"><p>对于给定的句子$X = \set{x_{1,}x_{2,}\dots, x_N}$, 首先使用BERT获得每个Token或者Word $x_i$ 的表示. 每个Word可能由多个Token组成, 使用最大池化获得每个Word的表示. 接着用一个双向LSTM完成编码. 记最终编码表示$\mathbf{H}=\left\{\mathbf{h}_1, \mathbf{h}_2, \ldots, \mathbf{h}_N\right\} \in \mathbb{R}^{N \times d_h}$, 其中$d_h$ 为Word表示的维度.</p><h4 id="Convolution-Layer"><a href="#Convolution-Layer" class="headerlink" title="Convolution Layer"></a>Convolution Layer</h4><p>由于W2NER会构成一个2D的<strong>表格</strong>, 采用<strong>Conv2D</strong>来聚合表格信息就比较合适:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner5.png" style="zoom:67%"><h5 id="Conditional-Layer-Normalization"><a href="#Conditional-Layer-Normalization" class="headerlink" title="Conditional Layer Normalization"></a>Conditional Layer Normalization</h5><p>表格可以被看做是一个三维矩阵$\mathbf{V} \in \mathbb{R}^{N \times N \times d_h}$, $\mathbf{V}_{ij}$ 代表Word Pair $(x_{i,}x_j)$ 的表示. 由于输入的句子是有向的, 而作者设计的Word Pair间关系也是<strong>有向</strong>的, 作者希望这种<strong>有向条件关系</strong>能够被表示出来. 例如, $(x_{i,}x_j)$ 之间的关系是由 $x_i$ 指向 $x_j$ 时, 应该有$\mathbf{h_j}= f(x_{j} \mid x_{i})$.</p><p>作者使用<strong>Conditional Layer Normalization</strong>(<strong>CLN</strong>)来建模这种隐含关系:</p><p>$$<br>\mathbf{V}_{i j}=\operatorname{CLN}\left(\mathbf{h}_i, \mathbf{h}_j\right)=\gamma_{i j} \odot\left(\frac{\mathbf{h}_j-\mu}{\sigma}\right)+\lambda_{i j}<br>$$</p><p>$\mathbf{h}_i$ 将用于生成缩放系数$\gamma_{ij}$ 和平移系数$\lambda_{ij}$:</p><p>$$<br>\begin{aligned}<br>\gamma_{ij} = \mathbf{W}_{\alpha}\mathbf{h}_{i}+ \mathbf{b}_{\alpha}\\<br>\lambda_{ij} = \mathbf{W}_{\beta}\mathbf{h}_{i}+ \mathbf{b}_{\beta}<br>\end{aligned}<br>$$</p><p>$\mu, \sigma$ 分别是$\mathbf{h}_j$ 中跨元素的均值和标准差:</p><p>$$<br>\mu=\frac{1}{d_h} \sum_{k=1}^{d_h} h_{j k}, \quad \sigma=\sqrt{\frac{1}{d_h} \sum_{k=1}^{d_h}\left(h_{j k}-\mu\right)^2}<br>$$</p><p>$h_{jk}$ 代表$\mathbf{h}_j$ 的第$k$ 维.</p><h5 id="BERT-Style-Grid-Representation-Build-Up"><a href="#BERT-Style-Grid-Representation-Build-Up" class="headerlink" title="BERT-Style Grid Representation Build - Up"></a>BERT-Style Grid Representation Build - Up</h5><p>虽然BERT里面包含了Word Embedding, Positional Embedding, Segment Embedding, 但作者觉得还不够, 因此仿照BERT构建一种新的表格表示, 由三部分组成:</p><ul><li><strong>CLN</strong>得到的Word Pair表示$\mathbf{V} \in \mathbb{R}^{N \times N \times d_h}$.</li><li>Word Pair之间的<strong>相对位置信息</strong>记作$\mathbf{E}^d \in \mathbb{R}^{N \times N \times d_{E_d}}$.</li><li>上下三角的<strong>区域</strong>Embedding$\mathbf{E}^t \in \mathbb{R}^{N \times N \times d_{E_t}}$.</li></ul><p>把上面三种表示拼接到一起, 再用一个MLP整合, 即<strong>Position - Region Aware Representation</strong> $\mathbf{C} \in \mathbb{R}^{N \times N \times d_c}$:</p><p>$$<br>\mathbf{C}=\operatorname{MLP}_1\left(\left[\mathbf{V} ; \mathbf{E}^d ; \mathbf{E}^t\right]\right)<br>$$</p><h5 id="Multi-Granularity-Dilated-Convolution"><a href="#Multi-Granularity-Dilated-Convolution" class="headerlink" title="Multi - Granularity Dilated Convolution"></a>Multi - Granularity Dilated Convolution</h5><p>用2D卷积在2D表格上做聚合是比较符合我们直觉的.</p><p>前人实验表明, 空洞卷积可以有更大的<strong>感受野</strong>, 在NLP上表现良好, 在此使用<strong>空洞卷积</strong>来捕获二维表格上的信息:</p><p>$$<br>\mathbf{Q}^l=\sigma\left(\operatorname{DConv}_l(\mathbf{C})\right)<br>$$</p><p>$l$ 为空洞卷积的膨胀系数.</p><p>多粒度主要体现在不同的膨胀系数, 作者将三种不同膨胀系数的空洞卷积抽出的特征拼接到一起:</p><p>$$<br>\mathbf{Q}= \left[\mathbf{Q}^{1}, \mathbf{Q}^{2}, \mathbf{Q}^{3}\right] \in \mathbb{R}^{N \times N \times 3d_c}<br>$$</p><blockquote><p>作者在代码里写的与论文中似乎不同, 代码中使用的空洞卷积是<strong>顺序</strong>的, 即$\mathbf{Q}^1=\sigma\left(\operatorname{DConv}_1(\mathbf{C})\right)$, $\mathbf{Q}^2=\sigma\left(\operatorname{DConv}_2(\mathbf{Q}^1)\right)$, $\mathbf{Q}^3=\sigma\left(\operatorname{DConv}_3(\mathbf{Q}^2)\right)$, 而不是像文中叙述的分别对$\mathbf{C}$ 做空洞卷积激活再拼接, 不过这不是很重要.</p></blockquote><h4 id="Co-Predictor-Layer"><a href="#Co-Predictor-Layer" class="headerlink" title="Co - Predictor Layer"></a>Co - Predictor Layer</h4><p>Co - Predictor由双仿射和MLP两个组件同时对前面Encoder Layer的特征$\mathbf{H} \in \mathbb{R}^{N \times d_h}$ 和Convolution Layer特征$\mathbf{Q} \in \mathbb{R}^{N \times N \times 3d_c}$ 做聚合, 得到Logits:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner6.png" style="zoom:67%"><h5 id="Biaffine-Predictor"><a href="#Biaffine-Predictor" class="headerlink" title="Biaffine Predictor"></a>Biaffine Predictor</h5><p>Biaffine Predictor的作用对象是Encoder所抽取出的特征, 用两个MLP分别获得Subject和Object对应的表示, 然后再用双仿射获取Logits:</p><p>$$<br>\begin{aligned}<br>\mathbf{s}_i &amp;=\operatorname{MLP}_2\left(\mathbf{h}_i\right) \\<br>\mathbf{o}_j &amp;=\operatorname{MLP}_3\left(\mathbf{h}_j\right) \\<br>\mathbf{y}_{i j}^{\prime} &amp;=\mathbf{s}_i^{\top} \mathbf{U} \mathbf{o}_j+\mathbf{W}\left[\mathbf{s}_i ; \mathbf{o}_j\right]+\mathbf{b}<br>\end{aligned}<br>$$</p><p>这些都是NER里面比较常规的操作了, 不过多赘述.</p><h5 id="MLP-Predictor"><a href="#MLP-Predictor" class="headerlink" title="MLP Predictor"></a>MLP Predictor</h5><p>MLP的作用对象是前面空洞卷积获得的特征$\mathbf{Q}$, 用于聚合Convolution Layer获得的每个格子中的信息:</p><p>$$<br>\mathbf{y}_{i j}^{\prime \prime}=\operatorname{MLP}\left(\mathbf{Q}_{i j}\right)<br>$$</p><p>最后简单的将两个Logits相加到一起即可(也可以视为是同等权重求和):</p><p>$$<br>\mathbf{y}_{i j}=\operatorname{Softmax}\left(\mathbf{y}_{i j}^{\prime}+\mathbf{y}_{i j}^{\prime \prime}\right)<br>$$</p><p>双仿射没对卷积得到的特征操作, 而是以Encoder Layer的$\mathbf{H}$ 为输入, 也可以是看成一种从Encoder Layer拉出来的<strong>残差连接</strong>吧.</p><h4 id="Decoding"><a href="#Decoding" class="headerlink" title="Decoding"></a>Decoding</h4><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner7.png" style="zoom:67%"><p>对于Word Pair之间的关系解码, 可以抽象为一个<strong>有向图</strong>的路径查找, 即利用NNW(蓝)找到有向图中的<strong>实体提及路径</strong>, THW(红)来提供<strong>辅助信息</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner8.png" style="zoom:67%"><ul><li>(a): 两个Flat实体. 对于简单的完全Flat的情况, 其实两条路径<code>A -&gt; B</code>, <code>D -&gt; E</code>就可以标注出来, THW在此时仅标注它们的实体类型.</li><li>(b): 两个重叠实体(该情况也是嵌套), 此时单纯用NNW没法解码出两个嵌套实体, 但THW在使得其可以解码出两个嵌套实体<code>ABC</code>, <code>BC</code>.</li><li>(c): 含有重叠的一个Flat实体和一个不连续实体. NNW可以找到<code>A -&gt; B -&gt; C</code> 和<code>A -&gt; B -&gt; D</code>这两条边, 在THW的辅助下解码出实体<code>ABC</code>和<code>ABD</code>.</li><li>(d): 最为复杂的情况, 两个部分重叠且不连续的实体. 同样是通过NNW无法单独解码出, 但在THW辅助下可解码出.</li></ul><blockquote><p>其实就是用NNW和THW结合成环, <strong>环即实体</strong>.</p></blockquote><h4 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h4><p>因为是填表式的Token Pair分类, 所以采用多分类交叉熵就好:</p><p>$$<br>\mathcal{L}=-\frac{1}{N^2} \sum_{i=1}^N \sum_{j=1}^N \sum_{r=1}^{|\mathcal{R}|} \hat{\mathbf{y}}_{i j}^r \log \mathbf{y}_{i j}^r<br>$$</p><p>其中$N$ 为句子中单词总数, $\hat{\mathbf{y}}_{i j}$ 为WordPair $(x_{i,}x_j)$ 之间的Golden Label, $\mathbf{y}_{i j}$ 则为模型预测概率分布, $r$ 代表预定义好的关系集合$\mathcal{R}$ 的关系.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的实验参数设置请参照原论文. 另外, 在阅读实验部分时, 要关注W2NER强大的任务形式统一能力.</p><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>根据现有的三大类NER采用了三大类不同的数据集:</p><ul><li><strong>Flat</strong>: CoNLL - 2003, OntoNotes 5.0(English), OntoNotes 4.0, MSRA, Weibo, Resume.</li><li><strong>Overlapped</strong>: ACE2004, ACE2005, GENIA.</li><li><strong>Discontinuous</strong>: 三个英文数据集CADEC, ShARe13, ShARe14, 两个中文数据集ACE2004, ACE2005.</li></ul><h3 id="Flat-NER"><a href="#Flat-NER" class="headerlink" title="Flat NER"></a>Flat NER</h3><p>在Flat NER上六个数据集结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner9.png" style="zoom:60%"> <img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner10.png" style="zoom:50%"><p>在Flat上结果不多说了, W2NER表现很好.</p><h3 id="Overlapped-NER"><a href="#Overlapped-NER" class="headerlink" title="Overlapped NER"></a>Overlapped NER</h3><p>在Overlapped NER三个数据集上表现如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner11.png" style="zoom:67%"><p>能够看到W2NER的Recall和Precision都维持在不错的水平.</p><h3 id="Discontinuous-NER"><a href="#Discontinuous-NER" class="headerlink" title="Discontinuous NER"></a>Discontinuous NER</h3><p>现有NER在Discontinuous NER上比较具有挑战性, 这部分应重点关注, 三个英文数据集上结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner12.png" style="zoom:67%"><p>W2NER较其他方法拥有很好的性能, 要记得它在其他NER上表现仍然很猛.</p><p>两个中文数据集上结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner13.png" style="zoom:67%"><p>Baseline两篇论文并没有在中文数据集上跑过, 这是作者自行使用官方源码得到的结果. 在两个数据集上领先Baseline半个点.</p><p>因为上述数据集也是含有Flat实体的, 所以作者做了ShARe14上重叠和不连续实体的预测性能:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner14.png" style="zoom:67%"><p>在重叠和不连续这两类比较难的问题下, W2NER相较于其他模型是有明显提升的, 而且差距不小. 其实在附录里还有其他两个数据集的对比, 提升也很明显.</p><h3 id="Model-Ablation-Studies"><a href="#Model-Ablation-Studies" class="headerlink" title="Model Ablation Studies"></a>Model Ablation Studies</h3><p>各组件消融实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/w2ner15.png" style="zoom:67%"><p>作者在文中的消融实验部分叙述非常简单, 能从结果中看到比较关键的有Region Embedding, 膨胀系数为2的空洞卷积, MLP, 以及NNW的标签设计. 其实相对位置编码和双仿射影响也不少.</p><p>空洞卷积的话好像<strong>组合</strong>起来性能提升比较多.</p><blockquote><p>MLP是挺猛的… 我倒是挺好奇<strong>CLN</strong>在Convolution Layer里面的作用, 可惜作者没有做实验.</p></blockquote><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>W2NER构建出一张Word Pair之间的<strong>二维表</strong>, 将现有的三大类NER任务转化成<strong>单词间</strong>的<strong>关系分类</strong>问题, 因此可以<strong>统一</strong>到同一个NER框架当中.</p><p>模型中, 引入了<strong>Conv2D</strong>来从<strong>二维表结构</strong>中获取信息, 并将Encoder Layer的信息和Convolution Layer的信息剥离开, 用Co -Predictor单独得到Logits.</p><p>从实验结果来看, W2NER展现出<strong>强大的NER任务形式统一能力</strong>, 并且性能良好, 以至于在实验部分作者也不需要过多的分析.</p><blockquote><p>这种基于Token Pair的分类方式很大程度受到<a href="https://adaning.github.io/posts/49694.html">TPLinker</a>的启发(也就是我在文中说的THW的相似性). 其实不光在NER, 在情感分析中, 以及其他信息抽取领域中已经逐渐成为主流.</p></blockquote></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/37376.html">https://ADAning.github.io/posts/37376.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/NER/"><span class="chip bg-color">NER</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/20020.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/23.jpg" class="responsive-img" alt="OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction"> <span class="card-title">OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction本文是论文OneEE: A One-Stage Framework for Fast</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-11-21 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/EE/"><span class="chip bg-color">EE</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/8137.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/17.jpg" class="responsive-img" alt="UniRE: A Unified Label Space for Entity Relation Extraction"> <span class="card-title">UniRE: A Unified Label Space for Entity Relation Extraction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">UniRE: A Unified Label Space for Entity Relation Extraction本文是论文UniRE: A Unified Label Space for Entity Relation Extract</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-09-22 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">350.9k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>