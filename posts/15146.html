<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="KEQA: Knowledge Graph Embedding Based Question Answering, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>KEQA: Knowledge Graph Embedding Based Question Answering | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/12.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">KEQA: Knowledge Graph Embedding Based Question Answering</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/KBQA/"><span class="chip bg-color">KBQA</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2021-03-30</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-03-27</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 11 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="Knowledge-Graph-Embedding-Based-Question-Answering"><a href="#Knowledge-Graph-Embedding-Based-Question-Answering" class="headerlink" title="Knowledge Graph Embedding Based Question Answering"></a>Knowledge Graph Embedding Based Question Answering</h1><p>本文是论文<a href="https://dl.acm.org/doi/abs/10.1145/3289600.3290956" target="_blank" rel="noopener">Knowledge Graph Embedding Based Question Answering</a>的阅读笔记和个人理解.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>作者发现KBQA中的三个挑战问题:</p><ol><li>谓词(关系)有多种<strong>自然语言</strong>的表示法.</li><li>实体也会有严重的模糊性而产生大量候选答案, 即实体的<strong>歧义问题</strong>.</li><li>用户的问题领域可能是<strong>开放</strong>的, KG也有可能是不完整的, 这对鲁棒性有一定的要求.</li></ol><p>Knowledge Embedding可以将实体映射为低维向量, KG中的<strong>关系信息</strong>会被保存, 各种<strong>KRL</strong>会非常有益于下游任务. 因此, 作者希望提出一种基于<strong>KGE</strong>方法, 并能够回答所有<strong>自然语言问题</strong>的框架.</p><p>KGE能够保证得到的单词表示的<strong>质量</strong>, 因为每个嵌入表示都是与<strong>整个KG交互</strong>的结果, 并且它也能保持相似的关系或实体之间的<strong>表示相似性</strong>.</p><blockquote><p>在本文中, 作者只关注了最简单的QA, 直接使用一个<strong>三元组</strong>就能描述整个问题, 而非多跳推理的问题.</p></blockquote><h2 id="KEQA"><a href="#KEQA" class="headerlink" title="KEQA"></a>KEQA</h2><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/keqa1.jpg" style="zoom:50%"><p>KEQA的大致思路是通过某种结构, 对自然语言中的<strong>整个句子</strong>抽取出与Knowledge Embedding<strong>相似</strong>的表示, 即希望用句子抽取后的表示空间<strong>等价于</strong>Knowledge Embedding的空间.</p><h3 id="Predicate-and-Head-Entity-Learning-Models"><a href="#Predicate-and-Head-Entity-Learning-Models" class="headerlink" title="Predicate and Head Entity Learning Models"></a>Predicate and Head Entity Learning Models</h3><h4 id="Knowledge-Graph-Embedding"><a href="#Knowledge-Graph-Embedding" class="headerlink" title="Knowledge Graph Embedding"></a>Knowledge Graph Embedding</h4><p>对于头实体$\mathbf{e}_h$, 谓词(关系)$\mathbf{p}_\ell$, KGE方法能通过打分函数$f(\mathbf{e}_t, \mathbf{p}_\ell)$得出对应的尾实体$\mathbf{e}_t$, 即$\mathbf{e}_t \approx f(\mathbf{e}_h, \mathbf{p}_\ell)$. 通过KGE, 我们能获得一个KG中的实体嵌入表示集$\mathbf{E}$ 和谓词嵌入表示集$\mathbf{P}$.</p><blockquote><p>当KGE训练完成时, 实体和关系的表示将会<strong>固定</strong>下来, 这样才能保存住KG的信息. 若继续在后续训练时更新Embedding, 将会对原有信息扰动. 所以KGE只是做了空间指示作用.</p></blockquote><h4 id="Neural-Network-Based-Predicate-Representation-Learning"><a href="#Neural-Network-Based-Predicate-Representation-Learning" class="headerlink" title="Neural Network Based Predicate Representation Learning"></a>Neural Network Based Predicate Representation Learning</h4><p>有了KGE中获取的$\mathbf{P}, \mathbf{E}$, 接着需要将自然语言中的<strong>谓词</strong>表示(在三元组中也是关系)与KGE空间相<strong>对齐</strong>, 作者在这里采用了比较简单的<strong>双向LSTM + Attention</strong>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/keqa2.jpg" style="zoom:50%"><blockquote><p>其实在作者发布的代码中, 用的是<strong>GRU</strong>, 不过都大差不差了.</p></blockquote><p>图中在绿色向量$\mathbf{r}_j$ 和拼接后的向量$\mathbf{h}_j$ 之间还有一个FC层没画出来.</p><p>先将自然语言的Token转换为Embedding(图中灰色), 记为$\mathbf{x}_j$, 然后再用双向LSTM获取双向表示$\mathbf{h}_j$ (图中红色蓝色).</p><p>下述数学表达都是LSTM, 左右双向同理, 下面只是单向:<br>$$<br>\begin{array}{l}<br>\mathrm{f}_{j}=\sigma\left(\mathbf{W}_{x f} \mathbf{x}_{j}+\mathbf{W}_{h f} \overleftarrow{\mathbf{h}}_{j+1}+\mathbf{b}_{f}\right) \\<br>\mathbf{i}_{j}=\sigma\left(\mathbf{W}_{x i} \mathbf{x}_{j}+\mathbf{W}_{h i} \overleftarrow{\mathbf{h}}_{j+1}+\mathbf{b}_{i}\right) \\<br>\mathbf{o}_{j}=\sigma\left(\mathbf{W}_{x o} \mathbf{x}_{j}+\mathbf{W}_{h o} \overleftarrow{\mathbf{h}}_{j+1}+\mathbf{b}_{o}\right) \\<br>\mathbf{c}_{j}=\mathbf{f}_{j} \circ \mathbf{c}_{j+1}+\mathbf{i}_{j} \tanh \left(\mathbf{W}_{x c} \mathbf{x}_{j}+\mathbf{W}_{h c} \overleftarrow{\mathbf{h}}_{j+1}+\mathbf{b}_{c}\right) \\<br>\overleftarrow{\mathbf{h}}_{j}=\mathbf{o}_{j} \circ \tanh \left(\mathbf{c}_{j}\right)<br>\end{array}<br>$$</p><p>将最初的$\mathbf{x}_j$ 和双向LSTM抽取得到的$\mathbf{h}_j$ 拼到一起, 计算Attention Score $q_j$ 和注意力权重$\alpha_j$ (图中紫色):<br>$$<br>\begin{aligned}<br>\alpha_{j} &amp;=\frac{\exp \left(q_{j}\right)}{\sum_{i=1}^{L} \exp \left(q_{i}\right)} \\<br>q_{j} &amp;=\tanh \left(\mathbf{w}^{\top}\left[\mathbf{x}_{j} ; \mathbf{h}_{j}\right]+b_{q}\right)<br>\end{aligned}<br>$$<br>将注意力权重与$\mathbf{h}_j$ 加权, 与$\mathbf{x}_j$ 拼接得到隐态$\mathbf{s}_j=[\mathbf{x}_j;\alpha_j\mathbf{h}_j]$. 之后再经过一个FC层得到最终的结果$\mathbf{r}_j$.</p><p>然后对求得的每个Token的最终表示$\mathbf{r}_j$ (图中绿色) 求个平均, 得到与KGE中谓词表示$\mathbf{p}_{\ell}$ 相似的表示$\hat{\mathbf{p}}_{\ell}$:<br>$$<br>\hat{\mathbf{p}}_{\ell}=\frac{1}{L} \sum_{j=1}^{L} \mathbf{r}_{j}^{\top}<br>$$</p><p>其中$L$ 是问题的句子长度.</p><h4 id="Neural-Network-based-Head-Entity-Learning-Model"><a href="#Neural-Network-based-Head-Entity-Learning-Model" class="headerlink" title="Neural Network based Head Entity Learning Model"></a>Neural Network based Head Entity Learning Model</h4><p>对于一个自然语言问题, 作者用类似获取谓词表示的方法获取头实体表示$\hat{\mathbf{e}}_{h}$, 用同样的架构获取头实体的表示, 也与KGE空间相对齐.</p><blockquote><p>这样直接把NER这步给省略掉了, 规避了自然语言中实体表示的模糊性问题.</p></blockquote><h3 id="Head-Entity-Detection-Model"><a href="#Head-Entity-Detection-Model" class="headerlink" title="Head Entity Detection Model"></a>Head Entity Detection Model</h3><p>因为自然语言问题中的候选实体可能过多, 所以需要一个<strong>头实体检测模型</strong>来减少问题中的候选实体, 从一个句子中选择一个或几个连续的Token作为实体名称.</p><p>同样是使用双向LSTM去处理整个句子:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/keqa3.jpg" style="zoom:50%"><p>先获取词嵌入$\mathbf{x}_j$, 再使用双向LSTM获得$\mathbf{h}_j$, 后接一个FC层和Softmax, 能获得两个概率, 分别是该Token属于实体名的概率$\text{HED}_{\text{entity}}$, 和Token不属于实体名的概率$\text{HED}_\text{non}$.</p><p>这样, 相连的HED可能是同一个实体, 而不相连的HED可能是多个实体名. 在获取完实体名后, 再从KG中找到对应的<strong>候选实体集</strong>, 很大程度上缩小了与KG中实体匹配的范围.</p><h3 id="Joint-Search-on-Embedding-Spaces"><a href="#Joint-Search-on-Embedding-Spaces" class="headerlink" title="Joint Search on Embedding Spaces"></a>Joint Search on Embedding Spaces</h3><p>如果只是想简单的缩小模型与KGE空间中的距离, 只需计算模型抽取出的表示与KGE空间中表示的范数. 但这显然没有考虑过KGE中保留的<strong>关系信息</strong>.</p><p>基于前面的谓词学习模型, 实体学习模型, 头实体检测模型, 作者提出了对三种模型的<strong>联合距离度量</strong>:</p><p>$$<br>\begin{aligned}<br>\underset{(h, \ell, t) \in C} {\operatorname{minimize}} \quad\lVert\mathbf{p}_{\ell}-\hat{\mathbf{p}}_{\ell}\rVert_{2}+\beta_{1}\lVert\mathbf{e}_{h}-\hat{\mathbf{e}}_{h}\rVert_{2}+\beta_{2}\lVert f\left(\mathbf{e}_{h}, \mathbf{p}_{\ell}\right)-\hat{\mathbf{e}}_{t}\rVert_{2}<br>\\\ -\beta_{3} \operatorname{sim}\left[n(h), \mathrm{HED}_{\text {entity}}\right]-\beta_{4} \operatorname{sim}\left[n(\ell), \mathrm{HED}_{\text {non}}\right]<br>\end{aligned}<br>$$</p><p>其中, $\beta_1,\beta_2,\beta_3,\beta_4$ 是预定义的超参, 即损失中四项的权重, 用来衡量所对应的影响力. $n(\cdot)$ 代表取实体或谓词的具体名的操作.</p><p>第一, 二项均用于缩小模型抽取出的头实体和谓词表示与KGE空间中相应表示的距离, 第三项用于缩小尾实体表示与KGE中相应实体表示的距离. 第四项和第五项针对头实体检测模型, $\operatorname{sim}[\cdot;\cdot]$ 是度量两个<strong>字符串</strong>之间相似性的函数, 在这里最大化标出的头实体和目标实体之间的相似度, 以及句子的非实体部分和真实谓词之间的相似度.</p><p>KEQA的框架执行流程如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/keqa4.jpg" style="zoom:67%"><p>大致流程是:</p><ol><li>分别<strong>训练</strong>谓词学习模型, 实体学习模型, 头实体检测模型. 训练谓词和实体表示模型时最小化模型结果与KGE相应表示的距离. 训练头实体检测模型时采用极大似然.</li><li>训练结束后, 面对每个问题, 分别用谓词学习模型和实体学习模型抽取出问题的谓词表示$\hat{\mathbf{p}}_\ell$ 和头实体表示$\hat{\mathbf{e}}_h$.</li><li>使用头实体检测模型检测出问题中出现的头实体$\text{HED}_{\text{entity}}$.</li><li>在KG中找到与检测出的头实体所匹配的候选集$\mathcal{C}$, 然后用KGE的打分函数$f(\cdot)$, 将$\hat{\mathbf{p}}_\ell$ 和$\hat{\mathbf{e}}_h$ 预测出相应的尾实体.</li><li>根据预测出的尾实体, 计算出与当前三元组<strong>联合距离最小</strong>的三元组, 作为答案返回.</li></ol><blockquote><p>头实体检测模型训练时采用的损失与联合距离度量略有不同, 训练时采用的是极大似然, 但在计算联合距离时采用的是字符串相似度.</p><p>KEQA对不同的损失项的优化实际上是<strong>分步</strong>运行的, 并且不同损失项针对的是不同模型.</p></blockquote><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>实验部分详细的参数请参照原论文.</p><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>因为本文探讨的是<strong>简单问题</strong>的回答, 作者除了采用FB2M, FB5M外, 还使用了从FB2M中的子集数据集SimpleQuestions, 统计信息如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/keqa5.jpg" style="zoom:67%"><h3 id="Effectiveness-of-KEQA"><a href="#Effectiveness-of-KEQA" class="headerlink" title="Effectiveness of KEQA"></a>Effectiveness of KEQA</h3><p>KEQA在FB2M, FB5M上的实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/keqa8.jpg" style="zoom:67%"><p>其中, KEQA_noEmbed是<strong>随机</strong>得到的Embedding, 没有经过KGE训练.</p><p>相较于提出的Baseline, 提升比较大. 在引入Knowledge Embedding后, 模型性能有了进一步的提升, 但其实在没引入KGE模型的情况下, 本身的效果也还可以, 因为它仍然超过了其他的Baseline.</p><h3 id="Generalizability-and-Robustness-Evaluation"><a href="#Generalizability-and-Robustness-Evaluation" class="headerlink" title="Generalizability and Robustness Evaluation"></a>Generalizability and Robustness Evaluation</h3><p>为检测KEQA的<strong>鲁棒性</strong>, 作者从两个角度做了实验:</p><ol><li>对KEQA使用不同的KGE方法.</li><li>对所有的谓词划分为三个组, 然后将训练集, 验证集, 测试集的问题按照谓词划分为三组. 这样测试集中出现的谓词肯定没有在训练集和验证集中出现过, 三类数据的谓词都是相互独立的. 按照该方法将SimpleQuestions改进为SimpleQ_Missing.</li></ol><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/keqa6.jpg" style="zoom:67%"><p>不同的KGE方法对结果其实没有太大的影响. 最简单的TransE就能有不错的结果. 对于新的数据集, 在TransE的帮助下仍然有40%左右的精度, 比不依赖KGE方法要高一些.</p><h3 id="Parameter-Analysis"><a href="#Parameter-Analysis" class="headerlink" title="Parameter Analysis"></a>Parameter Analysis</h3><p>为了探究联合距离度量中每项的贡献程度, 作者分别采用三种设置:</p><ul><li>Only_Keep: <strong>仅保留</strong>五项中的该度量.</li><li>Remove: 从五项中<strong>删除</strong>该项度量.</li><li>Accumulate: <strong>逐项添加</strong>度量.</li></ul><p>实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/keqa7.jpg" style="zoom:67%"><p>仅保留实体相关项的精度都非常低, 而仅保留谓词项的精度都比较高, 这也侧面说明了关系在KGE中发挥的重要作用, 实际上就是在针对关系学习.</p><p>在第一二项均保留的情况下, 结合谓词信息, 实体信息能够得到充分的利用.</p><p>第五项仍然使得模型性能涨了一个点, 说明问题中的某些Token可能和谓词<strong>共享信息</strong>.</p><blockquote><p>我认为第三项和第一二项可能是<strong>近似等价</strong>的, 而不是<strong>互为补充</strong>的.</p><p>因为第三项的引入并没有使得模型性能提升产生多大的变化, 但仅保留时仍然发挥了相当重要的作用, 而且在删除第三项时也没有对性能产生太大的影响.</p><p>即仅保留第三项时没有第一二项, 性能好. 删除第三项, 剩下其余四项, 性能没有明显变化. 在已经有第一二项的情况下, 加上第三项, 几乎无提升.</p></blockquote><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>KEQA是一种基于<strong>Knowledge Embedding</strong>的<strong>问答</strong>框架, 能从繁杂的<strong>自然语言</strong>中直接抽取出<strong>谓词表示</strong>和<strong>实体表示</strong>, 缓解了自然语言的<strong>模糊性</strong>和<strong>歧义性</strong>问题. 并通过<strong>头实体检测</strong>模型过<strong>滤掉</strong>非常多的候选实体三元组, <strong>缩小搜索范围</strong>. 同时, 作者充分结合了KGE能够保存<strong>关系信息</strong>的特性, 提出了<strong>联合距离度量</strong>.</p><p>除此外, 我个人认为联合度量中第三项的必要性是有待商榷的.</p><p>BERT具有类似KGE获取表示的能力, 在依托KGE方法的KEQA的框架下, 结合一些<strong>上下文相关</strong>的KGE方法可能会有奇效, 例如<a href="https://adaning.github.io/posts/42304.html">CoKE</a>, <a href="https://adaning.github.io/posts/28100.html">CoLAKE</a>, 因为它们与KEQA类似能够利用<strong>自然语言信息</strong>的能力, 而不单单是利用知识本身.</p><p>本文只关注于最基本的单跳简单问题, 该如何扩展到多跳复杂问题?</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/15146.html">https://ADAning.github.io/posts/15146.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/KBQA/"><span class="chip bg-color">KBQA</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/45769.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="CompGCN: Composition-based Multi-Relational Graph Convolutional Networks"> <span class="card-title">CompGCN: Composition-based Multi-Relational Graph Convolutional Networks</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: GCN: 详见图神经网络入门 R - GCN: 详见R - GCN: Modeling Relational Data with Graph Convolutional Networks Composition-ba</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-04-03 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></span></div></div><div class="card-action article-tags"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/GNN/"><span class="chip bg-color">GNN</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/14355.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/17.jpg" class="responsive-img" alt="CoPER: Contextual Parameter Generation for Knowledge Graph Link Prediction"> <span class="card-title">CoPER: Contextual Parameter Generation for Knowledge Graph Link Prediction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: ConvE: 详见ConvE: Convolutional 2D Knowledge Graph Embeddings Contextual Parameter Generation for Knowledge Gr</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2021-03-28 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></span></div></div><div class="card-action article-tags"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">398k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>