<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="深度神经网络小结, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>深度神经网络小结 | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/11.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">深度神经网络小结</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">神经网络</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-07-28</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-04-03</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 2.1k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 7 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p><strong>2020.09.09</strong>: 叙述调整.</p></blockquote><h1 id="深度神经网络-Deep-Neural-Network"><a href="#深度神经网络-Deep-Neural-Network" class="headerlink" title="深度神经网络 Deep Neural Network"></a>深度神经网络 Deep Neural Network</h1><p>在本文中的神经网络是指的<strong>深度神经网络 Deep Neural Network</strong>. 进入到深度学习领域后, 除去DL计算量大, 参数多的特点外, 还会发现深度学习中有一个很大的特点: 不需要特征工程. 特征提取直接由模型自动端到端的完成. DL大多是用仿生学的结构, 来获得信息的新的表示, 所以我们也常说, <strong>深度学习的本质是表示学习</strong>. 其强大的功能我认为是由神经网络本身对事物的表征方式和神经网络的万能逼近定理决定的.</p><p>在错杂的神经网络结构中, 对数据进行非线性拟合. 由于其结构的复杂性, DL也<strong>没有很好的解释性</strong>, 但是研究人员常常将其逐步拆开, 发现其中的规律, 看看神经网络究竟学习到了什么.</p><h2 id="神经元-Neuron"><a href="#神经元-Neuron" class="headerlink" title="神经元 Neuron"></a>神经元 Neuron</h2><p>神经元的概念这个比较简单, 神经网络是由神经元构成的. 一定都看过一张类似的图:</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/DNN.png" alt=""></p><p>这就是神经网络的结构, 两端的分别称为<strong>输入层</strong>和<strong>输出层</strong>, 中间的称为<strong>隐藏层</strong>. 最左侧的输入层大小与输入的特征维数是保持一致的. 最右侧的输出层大小与输出的维数保持一致, 如果任务是分类任务, 输出层的神经元个数就是要分类的类别数, 预测的是归属于每类的类别概率. 如果是回归任务, 最后一层的神经元只有一个, 预测的是回归值.</p><p>在不对神经网络注入灵魂的情况下, 每个神经层之间是做最简单的<strong>线性回归</strong>, 只不过我们形象的将这个过程拆解为神经元的描述(或者说二者互相表示).</p><p>从神经元和神经层的角度来看, 在第$l$ 层每个神经元$j$, 都有一个与上一层神经元$i$ 连接的权重$w_{ij}^{(l)}$, 以及每个神经元的偏置项$b^{(l)}_j$, 把权重矩阵记作$W^{(l)}$, 上一层$l-1$ 的输出$Y^{(l-1)}$ 给进当前层$l$ 记作本层输入$X^{(l-1)}$, 偏置向量记为$b^{(l)}$, 那么该层的输出$Y^{(l)}$ 为:<br>$$<br>Y^{(l)} = W^{(l)}X^{(l-1)} +b^{(l)}<br>$$<br>它的形式上就是单纯的线性回归. 如果只是这样, 神经网络不论有多少层, 输入输出都是线性的, 加不加隐藏层都一样, 是无法拟合非线性关系的. 这时候必须加入一些非线性元素使得神经网络具有非线性拟合的能力, 必须用某种方式给神经网络注入灵魂.</p><h2 id="激活函数-Activation-Function"><a href="#激活函数-Activation-Function" class="headerlink" title="激活函数 Activation Function"></a>激活函数 Activation Function</h2><p>激活函数是作用在神经元输出上的<strong>非线性函数</strong>, 最开始是被单独作为一个神经层而存在的, 后来被集成到神经元身上. 它使得神经网络具有了逼近任意函数的潜力, 只要神经元够多, 数据足够健壮, 那么它可以拟合任意的情况. 激活函数常用的只有几种, 现在最常见的是<code>Relu</code>, 解决了梯度爆炸和梯度消失的难题(后面提到). 在有了激活函数$f(x)$后, 每个神经元的输出变为了:<br>$$<br>Y^{(l)} = f(W^{(l)}X^{(l-1)} + b^{(l)})<br>$$</p><h3 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h3><p>它是早期很常见的激活函数, 但是因为存在一些缺陷, 近些年使用的人数越来越少. 公式如下:<br>$$<br>\sigma(x) = \frac{1}{1+e^{-x}}<br>$$<br>这个函数的导数很好求. 并且它能够将任意的输入都放缩到$[0, 1]$的区间内.<br>$$<br>\sigma’(x) = \sigma(x)(1-f(x))<br>$$<br><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sigmoid.png" style="zoom:33%"></p><p>它的缺点也很明显, 当输入过大或过小时, 所对应的的导数近乎为0, 这种现象称为梯度消失. 这对于之后梯度下降的链式求导是极为不利的. 因为我们对神经网络的权值初始化范围在$[0, 1]$之间, 当发生反向传播时, 如果隐藏层特别多, 就很容易发生梯度消失, 使链式求导趋于0. 还有一个问题就是, <code>Sigmoid</code>每次输出的数据都不是Zero-centered, 其输出值全是正数, 会在收敛的路上越走越远, 导致收敛慢.</p><h3 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h3><p>Tanh不是很了解, 但是现在用在NLP里很多(RNN经常用).<br>$$<br>tanh(x) =\frac{e^x-e^{-x}}{e^x+e^{-x}} \<br>tanh’(x) = 1-tanh^2(x)<br>$$<br><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/tanh.png" style="zoom:33%"></p><h3 id="Relu"><a href="#Relu" class="headerlink" title="Relu"></a>Relu</h3><p>为了改善梯度消失和梯度爆炸的问题, 计算也非常简单. 当时的<code>Relu</code>是非常具有统治力的(现在也是).<br>$$<br>ReLu(x) = max(0, x)<br>$$<br>其实就是一个取最大值的函数, 如果输入是负数直接取0. 不是全区间可导, 但是可以取次梯度.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/relu.jpg" style="zoom:33%"><p>它的优点就是收敛快, 在输入大于0的情况下, 导数恒为1, 改善了梯度消失问题. 但是<code>Relu​</code>的输出同样不是Zero-centered. 而且还有可能会造成<code>Dead neuron</code>. 因为有些输入是小于0的, 或者有些节点因为不幸的初始化或者Learning rate设的太大, 导致整个权重矩阵的分布发生变化, 若矩阵分布中心在负区域, 则负输入的梯度为0, 导致神经元可能永远不被更新.</p><p>基于这个问题, 人们提出了许多别的解决方案, 都是在负输入上做一些手脚. 比如说LeakyRelu, 在负输入区域上的值就不全为零, 而是用一个可以调整的参数$\alpha$(通常取0.01)乘上输入.即:<br>$$<br>LeakyReLu(x)=max(\alpha x, x)<br>$$<br>参数$\alpha$可以通过反向传播学习到. 理论上来说<code>LeakyRelu</code>会继承<code>Relu</code>的所有优点, 并改善它的缺点. 但是实际上并没有相关实验证明它会在所有情况下比Relu好.</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/leakyrelu.png" style="zoom:33%"><h3 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h3><p>在处理多分类问题时, 最后一层上会使用<code>Softmax</code>函数作为激活函数. <code>Softmax</code>保证了最后神经元输出是以概率形式输出. 对于分$C$类的问题, 最后一层第$i$个神经元在未激活的情况下的输出$y_i$, 有:<br>$$<br>Softmax(y_i) = \frac{e^i}{\sum\limits_i^Ce^i}<br>$$</p><h2 id="反向传播BP-Back-Propagation"><a href="#反向传播BP-Back-Propagation" class="headerlink" title="反向传播BP Back Propagation"></a>反向传播BP Back Propagation</h2><p>深度神经网络也被称为BP神经网络, 就是指的反向传播. 反向传播可以说是神经网络中最重要的部分之一了. 这种方式告诉我们如何调整神经元的相关权重. 首先, BP是基于梯度下降来调整权重的. 对于第$l$层, 第$i$个神经元对下一层第$j$个神经的权重$w_{ij}$, 损失函数为$E$, 人为设定学习率$\eta$ , 更新$w_{ij}$有:</p><p>$$<br>w^{(l)}_{ij} = w^{(l)}_{ij} - \eta\frac{\partial E(W, b)}{\partial w^{(l)}_{ij}}<br>$$<br>对于每层的偏置$b^{(l)}$ 同理. 这其中涉及到链式求导, 因为在计算时, 是通过输出层的最终复合函数逐渐向输入层求导, 所以就叫反向传播.</p><h2 id="随机失活-Dropout"><a href="#随机失活-Dropout" class="headerlink" title="随机失活 Dropout"></a>随机失活 Dropout</h2><p>当某些神经元过于强势时, 导致其他某些神经元会不被得到训练, 从而增大过拟合的几率, 当强大神经元对应输入的部分数据出现问题时, 就会出现单点故障. 所以需要一个方法使得其他神经元也得到训练, 并避免某些神经元过于强大. 此时, 采用神经元的随机失活策略, 使得每个神经元在训练时都有一定的概率权重不被更新, 能够保证绝大多数的神经元都处于活跃状态.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/dropout.png" alt=""></p><h2 id="参数计算"><a href="#参数计算" class="headerlink" title="参数计算"></a>参数计算</h2><p>DNN的参数计算比较简单, 假设第$l$层有$m$个神经元, 第$l+1$层有$n$个神经元, 那么$l$层的每个神经元都对应$l+1$层的$n$个权重, 外加一个偏置$b$, 第$l$层需训练的参数个数是$m\times n + 1$.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/50630.html">https://ADAning.github.io/posts/50630.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">神经网络</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/28799.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/0.jpg" class="responsive-img" alt="卷积神经网络小结"> <span class="card-title">卷积神经网络小结</span></div></a><div class="card-content article-content"><div class="summary block-with-text">卷积神经网络 Convolutional Neural Network卷积神经网络是一种含有空间信息的数据表示方法. 它与普通的DNN不同, 它包含了数据的位置信息, 以保证每次看到的是数据矩阵的一个区域, 而不是单纯的矩阵某一维. 卷积神</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-07-29 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/CNN/"><span class="chip bg-color">CNN</span> </a><a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"><span class="chip bg-color">神经网络</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/57255.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/16.jpg" class="responsive-img" alt="操作系统常见问题整理"> <span class="card-title">操作系统常见问题整理</span></div></a><div class="card-content article-content"><div class="summary block-with-text">操作系统操作系统问的比较多的就是进程线程的区别, 作业调度算法, 分页分段, 死锁很关键, 假脱机这部分也需要重视起来. 文中有部分算法的细节没有提到, 只是列出来名字, 需要自己补充. 当时整理的排版可能比较乱, 以后有空再整理. 计算机</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-07-27 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/" class="post-category">计算机基础</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"><span class="chip bg-color">操作系统</span> </a><a href="/tags/%E9%9D%A2%E8%AF%95/"><span class="chip bg-color">面试</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">362.2k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>