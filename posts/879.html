<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="SDN: Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>SDN: Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/17.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">SDN: Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-03-16</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-06-11</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3.5k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 16 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li><strong>LSTM</strong>: <a href="https://adaning.github.io/posts/60202.html">循环神经网络小结</a></li></ul></blockquote><h1 id="Synchronous-Dual-Network-with-Cross-Type-Attention-for-Joint-Entity-and-Relation-Extraction"><a href="#Synchronous-Dual-Network-with-Cross-Type-Attention-for-Joint-Entity-and-Relation-Extraction" class="headerlink" title="Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction"></a>Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction</h1><p>本文是论文<a href="https://aclanthology.org/2021.emnlp-main.219/" target="_blank" rel="noopener">Synchronous Dual Network with Cross-Type Attention for Joint Entity and Relation Extraction</a>的阅读笔记和个人理解, 论文来自<strong>EMNLP 2021</strong>.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>联合抽取因NER和RE之间的复杂交互而有挑战性, 现有的方法经把二者通过一个共享的网络来解决, 丢失了<strong>实体类型</strong>和<strong>关系类型</strong>的<strong>相互依赖</strong>.</p><p>因此, 作者从<strong>多任务学习</strong>角度, 设计了一种跨类型注意力的同步对偶网络, 来充分利用实体类型和关系类型之间的联系.</p><p>下图是一个实体关系抽取的例子, 需要根据给出的句子来抽取出实体以及其对应的实体类型, 并判断实体之间所存在的关系, 以此组成三元组:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn1.jpg" style="zoom:50%"><h2 id="Type-Attention-LSTM"><a href="#Type-Attention-LSTM" class="headerlink" title="Type - Attention LSTM"></a>Type - Attention LSTM</h2><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn3.jpg" style="zoom:50%"><p>作者设计的框架TA - LSTM(<strong>T</strong>ype <strong>A</strong>ttention <strong>LSTM</strong>)是基于LSTM的, 作者先介绍了标准LSTM. 在$t$ 时刻, 输入的Token的Embedding为$\mathbf{x}_t$, 基于细胞状态$\mathbf{c}_t$ 的隐态输出$\mathbf{h}_t^c$ 计算流程为:</p><p>$$<br>\begin{aligned}<br>\left[\begin{array}{c}<br>\mathbf{i}_{t} \\<br>\mathbf{o}_{t} \\<br>\mathbf{f}_{t} \\<br>\widetilde{\mathbf{c}}_{t}<br>\end{array}\right] &amp;=\left[\begin{array}{c}<br>\sigma \\<br>\sigma \\<br>\sigma \\<br>\tanh<br>\end{array}\right]\left(\mathbf{W}\left[\mathbf{h}_{t-1} ; \mathbf{x}_{t}\right]+\mathbf{b}\right) \\<br>\mathbf{c}_{t} &amp;=\mathbf{i}_{t} \odot \widetilde{\mathbf{c}}_{t}+\left(\mathbf{1}-\mathbf{i}_{t}\right) \odot \mathbf{c}_{t-1} \\<br>\mathbf{h}_{t}^{c} &amp;=\mathbf{o}_{t} \odot \tanh \left(\mathbf{c}_{t}\right)<br>\end{aligned}<br>$$</p><p>其中$\mathbf{W}, \mathbf{b}$ 为可学习参数, $\sigma$ 为Sigmoid激活函数.</p><p>上述式子由上到下分别为: $t$ 时刻的输入门$\mathbf{i}_t$, 输出门$\mathbf{o}_t$, 遗忘门$\mathbf{f}_t$, 初始细胞状态$\tilde{\mathbf{c}}_t$, 细胞状态$\mathbf{c}_t$, 隐态输出$\mathbf{h}_t^c$(也作为上下文表示).</p><h3 id="Type-Attention-Mechanism"><a href="#Type-Attention-Mechanism" class="headerlink" title="Type - Attention Mechanism"></a>Type - Attention Mechanism</h3><blockquote><p>这部分是TA - LSTM额外添加的内容.</p></blockquote><p>在Type - Attention机制中, 对于类型$k$, 以及给定的$t$ 时刻输入$\mathbf{x}_t$ 和$t-1$ 时刻的隐态$\mathbf{h}_{t-1}$. 该类型相关的Key - Value对可以由下式计算得来:<br>$$<br>\left[\begin{array}{l}<br>\mathbf{k}_{k}^{(t)} \\<br>\mathbf{v}_{k}^{(t)}<br>\end{array}\right]=\left[\begin{array}{c}<br>\sigma \\<br>\sigma<br>\end{array}\right]\left(\mathbf{W}_{k}\left[\mathbf{h}_{t-1} ; \mathbf{x}_{t}\right]+\mathbf{b}_{k}\right)<br>$$</p><p>$k \in \left[1, \dots, m \right]$ 可以是实体类型或关系类型, 其中$\mathbf{W}_k, \mathbf{b}_k$ 为可学习参数, $\sigma$ 为Sigmoid函数. 其实跟$\mathbf{i}_t, \mathbf{o}_t, \mathbf{f}_t$ 得来的方式差不多.</p><p>这样就可以根据类型数量$m$, 得到$m$ 个类别特化的Key - Value对$\mathbf{K}^{(t)}=\left[\mathbf{k}_{1}^{(t)}, \ldots, \mathbf{k}_{m}^{(t)}\right]$ 和$\mathbf{V}^{(t)}=\left[\mathbf{v}_{1}^{(t)}, \ldots, \mathbf{v}_{m}^{(t)}\right]$.</p><p>接着把上下文表示$\mathbf{h}_{t}^c$ 视为Query, 把Attention机制应用到这上面来:<br>$$<br>\begin{aligned}<br>\mathbf{h}_{t}^{l} &amp;=\operatorname{attention}\left(\mathbf{h}_{t}^{c}, \mathbf{K}^{(t)}, \mathbf{V}^{(t)}\right)=\boldsymbol{\alpha}^{(t)} \mathbf{V}^{(t)} \\<br>\boldsymbol{\alpha}^{(t)} &amp;=\operatorname{softmax}\left(\frac{\mathbf{h}_{t}^{c} \mathbf{K}^{(t)}{ }^{\top}}{\sqrt{d_{e}}}\right)<br>\end{aligned}<br>$$</p><p>$\sqrt{d_e}$ 为Hidden state维度.</p><p>最后, TA - LSTM的$t$ 时刻上下文表示$\mathbf{h}_t^c$ 和类别表示$\mathbf{h}_t^l$ 相加得到$t$ 时刻的最终表示$\mathbf{h}_t$:</p><p>$$<br>\mathbf{h}_{t}=\mathbf{h}_{t}^{c}+\mathbf{h}_{t}^{l}<br>$$</p><h2 id="Synchronous-Dual-Network-with-Cross-Type-Attention"><a href="#Synchronous-Dual-Network-with-Cross-Type-Attention" class="headerlink" title="Synchronous Dual Network with Cross - Type Attention"></a>Synchronous Dual Network with Cross - Type Attention</h2><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn2.jpg" style="zoom:50%"><h3 id="Task-Definition"><a href="#Task-Definition" class="headerlink" title="Task Definition"></a>Task Definition</h3><p>在这里重新给出<strong>形式化</strong>的实体关系抽取任务定义.</p><p>对于给定的包含$n$ 个单词的句子$\mathbf{s}=[w_1, \dots, w_n]$, RTE的任务目标是抽取出句子$\mathbf{s}$ 中的关系三元组$\mathcal{T}=\left\{\left(\mathbf{e}_i, r, \mathbf{e}_j \right) \mid \mathbf{e}_i, \mathbf{e}_j \in \mathcal{E}, r \in \mathcal{R}\right\}$. $\mathbf{e}_i, \mathbf{e}_j, r$ 分别代表关系三元组的Subject, Object, Relation.</p><p>Subject, Object规定在实体集$\mathcal{E}=\left\{\mathbf{e}_i\right\}^P_{i=1}$中, 关系从预定义好的关系集$\mathcal{R}=\{\mathcal{R}_1, \dots, \mathcal{R}_m\}$中选出, $m$ 为有效关系类型数.</p><h3 id="Synchronous-Dual-Learning"><a href="#Synchronous-Dual-Learning" class="headerlink" title="Synchronous Dual Learning"></a>Synchronous Dual Learning</h3><p>接下来作者将通过Entity Type Learning和Relation Type Learning来捕获实体类型增强的表示$\mathbf{h}_t^e$, 关系类型增强的表示$\mathbf{h}_t^r$, 以增强模型对Type的感知力.</p><h4 id="Entity-Type-Learning"><a href="#Entity-Type-Learning" class="headerlink" title="Entity Type Learning"></a>Entity Type Learning</h4><p>NER作为序列标注问题, 实体类型作为标签, 例如PER, LOC, ORG等:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn5.jpg" style="zoom:50%"><p>若有$p$ 种实体标签, 每个实体类型都对应一个<strong>ETC</strong>(Entity Type Cell), 就有$p$ 个ETCs.</p><p>为了让模型学会实体类型预测的感知, 所以引入了<strong>Entity Type Learning</strong>作为<strong>辅助任务</strong>.</p><blockquote><p>下面的公式有些琐碎, 与原论文保持同步, 但其实<strong>并不复杂</strong>, 请耐心看完.</p></blockquote><p>从上一节可以仅用LSTM直接得到$t$ 时刻的上下文表示$\mathbf{h}_t^c$​, 用双向平均来, 即$\bar{\mathbf{h}}_{t}^{c}=\left[\left(\overrightarrow{\bar{\mathbf{h}}_{t}^{c}}+\overleftarrow{\bar{\mathbf{h}}_{t}^{c}}\right) / 2\right]$.</p><p>并由Type Attention机制得到一组与每种关系一一对应的Key - Value对 $\bar{\mathbf{K}}^{(t)}=\left[\bar{\mathbf{k}}_{1}^{(t)}, \ldots, \bar{\mathbf{k}}_{p}^{(t)}\right]$, $\bar{\mathbf{V}}^{(t)}=\left[\bar{\mathbf{v}}_{1}^{(t)}, \ldots, \bar{\mathbf{v}}_{p}^{(t)}\right]$, 其中的每个实体类型$p$ 对应的Key和Value也是由单向LSTM生成后, 将双向平均而来, 即 $\bar{\mathbf{k}}_{l}^{(t)}=\left[\left(\overrightarrow{\bar{\mathbf{k}}_{l}^{(t)}}+\overleftarrow{\bar{\mathbf{k}}_{l}^{(t)}}\right) / 2\right]$, $\bar{\mathbf{v}}_l^{(t)} = \left[\left(\overrightarrow{\bar{\mathbf{v}}_{l}^{(t)}}+\overleftarrow{\bar{\mathbf{v}}_{l}^{(t)}}\right) / 2\right],(l \in[1, \ldots, p])$.</p><p>$t$ 时刻实体类型相关的表示由两个方向拼接而成, $\mathbf{h}_{t}^{e}=\left[\overrightarrow{\mathbf{h}_{t}^{e}} \oplus \overleftarrow{\mathbf{h}_{t}^{e}}\right]$, 整个序列的实体类型表示记为$\mathbf{H}^{(e)}=\left[\mathbf{h}_{1}^{e}, \ldots, \mathbf{h}_{n}^{e}\right]$.</p><p>根据上述过程, <strong>每个时间步$t$ 都能得到不同的Type Specific Key - Value对</strong>.</p><p>然后把上下文表示$\bar{\mathbf{h}}_{t}^{c}$ 和不同实体类型的Key$\bar{\mathbf{k}}_{l}^{(c)}$做缩放点积, 得到当前时刻Token最相似的实体类型$T_l^e$:<br>$$<br>p\left(T_{l}^{e} \mid w_{t}\right)=\operatorname{softmax}\left(\frac{\overline{\mathbf{h}}_{t}^{c} \overline{\mathbf{k}}_{l}^{(t) \top}}{\sqrt{d_{e}}}\right)<br>$$</p><p>然后用极大似然优化:</p><p>$$<br>\mathcal{L}_{E T}=-\sum_{t=1}^{n} \log \left(p\left(T_{t}^{e} \mid w_{t}\right)\right)<br>$$</p><h4 id="Relation-Type-Learning"><a href="#Relation-Type-Learning" class="headerlink" title="Relation Type Learning"></a>Relation Type Learning</h4><p>同样的, 跟Entity Type Learning相类似, Relation Type Learning也是用来强化模型对类型感知的<strong>辅助任务</strong>.</p><p>因为存在<strong>相同实体对存在多种关系</strong>的情况(<strong>EPO</strong>问题), 所以用<strong>多标签</strong>来标注, 即用0, 1标签来表明实体之间的关系, 例如:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn6.jpg" style="zoom:50%"><p>在这里, 作者区分了Subject和Object的<strong>位置关系</strong>, 并将其纳入标签中. 设$M$ 为关系数量, 加上<strong>没有关系</strong>的情况, 共含有$2\times M + 1$ 种标签.</p><p>下内容与Entity Type Learning完全类似, 这里只是将实体类型转换为$q$ 种关系类型, 不再多加赘述.</p><p>上下文表示为$\hat{\mathbf{h}}_{t}^{c}=\left[\left(\overrightarrow{\hat{\mathbf{h}}_{t}^{c}}+\overleftarrow{\hat{\mathbf{h}}_{t}^{c}}\right) / 2\right]$, Key - Value对 $\hat{\mathbf{K}}^{(t)}=\left[\hat{\mathbf{k}}_{1}^{(t)}, \ldots, \hat{\mathbf{k}}_{q}^{(t)}\right]$, $\hat{\mathbf{V}}^{(t)}=\left[\hat{\mathbf{v}}_{1}^{(t)}, \ldots, \hat{\mathbf{v}}_{q}^{(t)}\right]$, 由双向后求和平均得到, $\hat{\mathbf{k}}_{l}^{(t)}=\left[\left(\overrightarrow{\hat{\mathbf{k}}_{l}^{(t)}}+\overleftarrow{\hat{\mathbf{k}}_{l}^{(t)}}\right) / 2\right]$,$\left[\left(\overrightarrow{\hat{\mathbf{v}}_{l}^{(t)}}+\overleftarrow{\hat{\mathbf{v}}_{l}^{(t)}}\right) / 2\right],(l \in[1, \ldots, q])$</p><p>最后也是将双向拼接得到关系表示, $\mathbf{h}_{t}^{r}=\left[\overrightarrow{\mathbf{h}_{t}^{r}} \oplus \overleftarrow{\mathbf{h}_{t}^{r}}\right]$, 整个句子的关系表示记为$\mathbf{H}^{(e)}=\left[\mathbf{h}_{1}^{r}, \ldots, \mathbf{h}_{n}^{r}\right]$.</p><p>因为是多标签问题, 所以用的是Sigmoid得到$w_t$ 的关系类型$T_l^r$:</p><p>$$<br>p\left(T_{l}^{r} \mid w_{t}\right)=\operatorname{sigmoid}\left(\frac{\hat{\mathbf{h}}_{t}^{c} \hat{\mathbf{k}}_{l}^{(t) \top}}{\sqrt{d_{e}}}\right)<br>$$</p><p>也是用极大似然优化:</p><p>$$<br>\mathcal{L}_{R T}=-\sum_{t=1} \sum_{r=1}^{2}<br>\left\{\log \left(p\left(T_{t}^{r} \mid w_{t}\right)\right)^{\mathbb{I}\left\{\hat{T}_{t}^{r}=1\right\}}+\log \left(1-p\left(T_{t}^{r} \mid w_{t}\right)\right)^{\mathbb{I}\left\{\hat{T}_{t}^{r}=0\right\}}\right\}<br>$$</p><h3 id="Cross-Type-Attention-Mechanism"><a href="#Cross-Type-Attention-Mechanism" class="headerlink" title="Cross - Type Attention Mechanism"></a>Cross - Type Attention Mechanism</h3><p>其实在Entity Type Learning和Relation Type Learning中的Entity Type和Relation Type使用是<strong>独立</strong>的, 所以接下来作者需要让它们彼此产生<strong>交互</strong>.</p><p>对于Entity Type Learning中得到的实体类型增强的表示$\mathbf{h}_t^e$, 以及关系类型相关的Key - Value对$\hat{\mathbf{K}}^{(t)}, \hat{\mathbf{V}}^{(t)}$, 关系 - 实体表示$\mathbf{c}_t^e$ 可以由前面讲过的Type - Attention机制得到.</p><p>与之相似的, 对于Relation Type Learning中得到的关系类型增强表示$\mathbf{h}_{t}^{r}$, 以及实体类型相关的Key - Value对$\bar{\mathbf{K}}^{(t)}, \bar{\mathbf{V}}^{(t)}$, 实体 - 关系表示$\mathbf{c}_t^r$ 也可以由Type - Attention得到. 即:<br>$$<br>\begin{aligned}<br>\mathbf{c}_{t}^{e} &amp;=\operatorname{attention}\left(\mathbf{h}_{t}^{e}, \hat{\mathbf{K}}^{(t)}, \hat{\mathbf{V}}^{(t)}\right) \\<br>\mathbf{c}_{t}^{r} &amp;=\operatorname{attention}\left(\mathbf{h}_{t}^{r}, \bar{\mathbf{K}}^{(t)}, \bar{\mathbf{V}}^{(t)}\right)<br>\end{aligned}<br>$$</p><blockquote><p>注: 该Cross Attention形式绝非首次出现, 在<strong>多模态模型</strong><a href="https://arxiv.org/abs/1908.02265" target="_blank" rel="noopener">ViLBERT</a> 中早就已经有把两种跨模态信息互相作为Query的方法. 只不过这里是将两种模态换为两种包含相关性的任务而已, 这二者十分相似.</p></blockquote><p>然后仿照TA - LSTM unit的最后, 把两种表示相加作为新的实体类型增强表示和新的关系类型增强表示:<br>$$<br>\begin{aligned}<br>\tilde{\mathbf{h}}_{t}^{e} &amp;= \mathbf{c}_t^e + \mathbf{h}_t^e \\<br>\tilde{\mathbf{h}}_{t}^{r} &amp;= \mathbf{c}_t^r + \mathbf{h}_t^r<br>\end{aligned}<br>$$<br>这也就是处理NER和RE前的<strong>最终表示形式</strong>了.</p><h3 id="Joint-Entity-and-Relation-Extraction"><a href="#Joint-Entity-and-Relation-Extraction" class="headerlink" title="Joint Entity and Relation Extraction"></a>Joint Entity and Relation Extraction</h3><p>下面的内容才是针对实体关系联合抽取的模型设计, 这部分设计的非常简单, 因为本文主要侧重点在于前面.</p><p>首先把Entity Type Learning中得到的实体表示$\tilde{\mathbf{h}}_{t}^{e}$ 和Relation Type Learning关系表示$\tilde{\mathbf{h}}_{t}^{r}$ 拼接起来, 得到一个联合表示:</p><p>$$<br>\tilde{\mathbf{h}}_{t}=\tilde{\mathbf{h}}_{t}^{e} \oplus \tilde{\mathbf{h}}_{t}^{r}<br>$$</p><h4 id="Named-Entity-Recognition"><a href="#Named-Entity-Recognition" class="headerlink" title="Named Entity Recognition"></a>Named Entity Recognition</h4><p>在NER任务中, 使用BIESO标签, 用Softmax和一层线性层搞定:<br>$$<br>y_{t}=\operatorname{softmax}\left(\mathbf{W}_{e} \tilde{\mathbf{h}}_{t}+\mathbf{b}_{e}\right)<br>$$</p><p>用极大似然优化即可:<br>$$<br>\mathcal{L}_{E}=-\sum_{t=1}^{n} \log \left(y_{t}\right)<br>$$</p><h4 id="Relation-Extraction"><a href="#Relation-Extraction" class="headerlink" title="Relation Extraction"></a>Relation Extraction</h4><p>作者Follow了前人的做法, 因为RE是一个与<strong>实体对相关</strong>的多标签任务, 所以这里做了实体对穷举, 判断Token $i$ 和Token $j$ 之间的关系$r^\prime$:</p><p>$$<br>\begin{gathered}<br>\mathbf{m}=\phi\left(\mathbf{W}_{m}\left(\tilde{\mathbf{h}}_{i} \oplus \tilde{\mathbf{h}}_{j}\right)+\mathbf{b}_{m}\right) \\<br>y_{i, j}^{r^{\prime}}=\operatorname{sigmoid}\left(\mathbf{W}_{r^{\prime}} \mathbf{m}+\mathbf{b}_{r^{\prime}}\right)<br>\end{gathered}<br>$$</p><p>其中$\mathbf{W}_{m} , \mathbf{b}_{m}, \mathbf{W}_{r^{\prime}} , \mathbf{b}_{r^{\prime}}$ 为可学习参数, $\phi$ 为ReLU.</p><p>然后用二分类交叉熵做Loss:</p><p>$$<br>\mathcal{L}_{R}=-\sum_{r^{\prime}=1}^{M} \sum_{i, j=1}^{n}\{\log \left(y_{i, j}^{r^{\prime}}\right)^{\mathbb{I}\left\{\hat{y}_{i, j}^{r^{\prime}}=1\right\}}<br>\left.+\log \left(1-y_{i, j}^{r^{\prime}}\right)^{\mathbb{I}\left\{\hat{y}_{i, j}^{\prime}=0\right\}}\right\}<br>$$</p><p>其中$\hat{y}_{i,j}^{r\prime}$ 为关系的Golden Label.</p><p>至此, SDN的模型结构已经完全确定:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn4.jpg" style="zoom:50%"><p>其实就是用TA - LSTM和ETC提供的信息完成辅助任务Entity Type Prediction, 再由这部分信息和Cross Attention组合, 经过简单的变换处理NER. 关系侧则完全同理, 不再叙述.</p><h3 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h3><p>Training的Loss一共是五个, 最后加上一个L2正则化Loss:</p><p>$$<br>\mathcal{L}=\lambda^{t 1} \mathcal{L}_{E T}+\lambda^{t 2} \mathcal{L}_{R T}+\lambda^{e} \mathcal{L}_{E}+\lambda^{r} \mathcal{L}_{R}+\frac{\lambda}{2}|\Theta|^{2}<br>$$</p><p>$\lambda$ 为各个任务的权重系数, $\Theta$ 为模型参数.</p><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p>在推断时, 需要判断三元组是否正确.</p><p>对于NER抽取出的实体集$\mathcal{E}$ 中的实体, 有Subject $\mathbf{e}_{i}=\left[w_{\xi_{i}}, \ldots, w_{\zeta_{i}}\right]$, Object $e_{j}=\left[w_{\xi_{j}}, \ldots, w_{\zeta_{j}}\right]$, 关系$r$ 下的概率为$p_r$ 为:<br>$$<br>p_{r}=\frac{1}{\left|\mathbf{e}_{i}\right|} \frac{1}{\left|\mathbf{e}_{j}\right|} \sum_{f=\xi_{i}}^{\zeta_{i}} \sum_{s=\xi_{j}}^{\zeta_{j}} y_{f, s}^{r}<br>$$<br>$\left|\mathbf{e}_{i}\right|, \left|\mathbf{e}_{j}\right|$ 为$\mathbf{e}_i, \mathbf{e}_j$ 的长度, 仅当$p_r &gt; \theta$ 时三元组成立, $\theta$ 为阈值.</p><blockquote><p>这种计算方式确实比较特殊, 是<strong>将实体内所有Token对逐一求和平均</strong>来确定两实体之间是否存在指定关系.</p></blockquote><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>作者使用了RTE上最常用的两个Benchmark NYT和WebNLG, 统计信息如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn7.jpg" style="zoom:50%"><h3 id="Main-Results"><a href="#Main-Results" class="headerlink" title="Main Results"></a>Main Results</h3><p>作者将SDN分别与多任务类, Tagging类, 生成类放在一起对比, 结果如下(应该指的是<strong>精确匹配结果</strong>):</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn8.jpg" style="zoom:50%"><p>SDN在F1上是最好的.</p><h3 id="Ablation-Experiments"><a href="#Ablation-Experiments" class="headerlink" title="Ablation Experiments"></a>Ablation Experiments</h3><p>文中消融实验如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn9.jpg" style="zoom:50%"><p>Entity Type Learning和Relation Type Learning对模型性能均有相当大提升, 而且是对NER和RE任务都有影响, 并且能观察到NER和RE任务之间的关联性很强.</p><h3 id="Analysis-of-Inference-Threshold"><a href="#Analysis-of-Inference-Threshold" class="headerlink" title="Analysis of Inference Threshold"></a>Analysis of Inference Threshold</h3><p>作者做了不同阈值$\theta$ 和模型结果之间变化图:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn10.jpg" style="zoom:50%"><p>作者将阈值对性能的影响归因与WebNLG和NYT之间实体长度不一.</p><h3 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h3><p>作者做了Case Study, 如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/sdn11.jpg" style="zoom:50%"><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>作者从<strong>实体类型</strong>和<strong>关系类型</strong>的假设入手, 提出了一种基于TA - LSTM和Cross Type Attention的同步<strong>对偶</strong>网络, 通过强调对实体类型的感知, 关系类型的感知, 以及<strong>跨类型注意力</strong>解决了实体关系抽取问题.</p><p>但其实从文章中看出, 能把这个想法做Work是一件非常不容易的事情, 引入了额外的两个辅助任务, 除去正则外4个Loss属实难顶. 文章中的符号描述比较混乱, 尤其是两个辅助任务那部分, 但其实不复杂,</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">DaNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/879.html">https://ADAning.github.io/posts/879.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">DaNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/6682.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/14.jpg" class="responsive-img" alt="Hexo博客迁移"> <span class="card-title">Hexo博客迁移</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Hexo博客迁移本文记录一次带主题的Hexo博客迁移过程, 从Win上迁移到MacOS. 前置依赖首先, 需要在MacOS上装Node.js和Git的环境, 网上有大把大把的教程, 这里就不再多说了, 自行搜索即可. 必要文件把Window</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-03-17 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E5%8D%9A%E5%AE%A2/" class="post-category">博客</a></span></div></div><div class="card-action article-tags"><a href="/tags/Hexo/"><span class="chip bg-color">Hexo</span> </a><a href="/tags/Matery/"><span class="chip bg-color">Matery</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/27457.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/1.jpg" class="responsive-img" alt="PFN: A Partition Filter Network for Joint Entity and Relation Extraction"> <span class="card-title">PFN: A Partition Filter Network for Joint Entity and Relation Extraction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: RNN: 详见循环神经网络小结. A Partition Filter Network for Joint Entity and Relation Extraction本文是论文A Partition Filter</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-01-12 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">DaNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">406k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:andaning@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>