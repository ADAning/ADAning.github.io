<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="AcrE: Atrous Convolution and Residual Embedding, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>AcrE: Atrous Convolution and Residual Embedding | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/20.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">AcrE: Atrous Convolution and Residual Embedding</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF/"><span class="chip bg-color">空洞卷积</span> </a><a href="/tags/%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5/"><span class="chip bg-color">残差连接</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-10-27</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-03-27</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3.7k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 14 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><blockquote><p>本文前置知识:</p><ul><li>膨胀卷积(空洞卷积)</li><li>残差连接</li></ul></blockquote><h1 id="Knowledge-Graph-Embedding-with-Atrous-Convolution-and-Residual-Learning"><a href="#Knowledge-Graph-Embedding-with-Atrous-Convolution-and-Residual-Learning" class="headerlink" title="Knowledge Graph Embedding with Atrous Convolution and Residual Learning"></a>Knowledge Graph Embedding with Atrous Convolution and Residual Learning</h1><p>本文是论文<a href="https://arxiv.org/abs/2010.12121" target="_blank" rel="noopener">Knowledge Graph Embedding with Atrous Convolution and Residual Learning</a>的阅读笔记和个人理解. 由Pytorch实现的源代码已经放到上<a href="https://github.com/neukg/AcrE" target="_blank" rel="noopener">Github</a>, 这是NEU KG组的论文! 刚发我就看完了. 该论文已经被<strong>COLING</strong>收录. 该论文是一篇KGE方向的论文, 用极简结构实现了非常好的性能, 并在多个常用数据集上SOTA.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>在当今各类KGE模型大红大紫的情况下, 模型的<strong>复杂度</strong>和<strong>表达能力</strong>得不到很好的<strong>权衡</strong>. 最近流行的例如基于深度神经网络的嵌入模型, 基于图神经网络的嵌入模型, 都有非常高的<strong>耗时</strong>和模型<strong>复杂度</strong>, 导致不能在一些实时的场景下灵活运用. AcrE的目标就是实现<strong>简单</strong>, <strong>高效</strong>的知识嵌入, 同时兼具了参数量少, 计算量低的特征.</p><h2 id="ConvE"><a href="#ConvE" class="headerlink" title="ConvE"></a>ConvE</h2><p>本节作为背景知识为AcrE铺垫, 取自<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/17366/15884" target="_blank" rel="noopener">Convolutional 2D Knowledge Graph Embeddings</a>. 主要介绍KGE中的ConvE方法. ConvE只不过是将卷积使用在了KGE上, 有卷积基础的应该能够猜到使用方法, 所以不会细说.</p><p>得益于CNN的<strong>权重共享</strong>, 参数量非常少, 因此很高效, 并且很简单, 注意这个特点.</p><h3 id="1D-Convolution-VS-2D-Convolution"><a href="#1D-Convolution-VS-2D-Convolution" class="headerlink" title="1D Convolution VS 2D Convolution"></a>1D Convolution VS 2D Convolution</h3><p>作者指出, 相较于1维卷积, 2维卷积有更强的<strong>表达能力</strong>(其实从直觉来说也是这样).</p><p>在做1维卷积时, 卷积核最多只能与左侧或右侧离得比较近的元素<strong>交互</strong>:<br>$$<br>\left(\begin{array}{lll}<br>\left.\left[\begin{array}{lll}<br>a &amp; a &amp; a<br>\end{array}\right] ;\left[\begin{array}{lll}<br>b &amp; b &amp; b<br>\end{array}\right]\right)=\left[\begin{array}{llllll}<br>a &amp; a &amp; a &amp; b &amp; b &amp; b<br>\end{array}\right]<br>\end{array}\right.<br>$$<br>但2维卷积不一样, 除了能够与邻近的左右元素交互, 还能与上下元素进行交互:<br>$$<br>\left(\left[\begin{array}{lll}<br>a &amp; a &amp; a \\<br>a &amp; a &amp; a<br>\end{array}\right] ;\left[\begin{array}{lll}<br>b &amp; b &amp; b \\<br>b &amp; b &amp; b<br>\end{array}\right]\right)=\left[\begin{array}{lll}<br>a &amp; a &amp; a \\<br>a &amp; a &amp; a \\<br>b &amp; b &amp; b \\<br>b &amp; b &amp; b<br>\end{array}\right]<br>$$<br>如果两种元素代表的意义不同, 那么交换它们的拼接方式还能进一步的<strong>提升</strong>交互次数:<br>$$<br>\left[\begin{array}{lll}<br>a &amp; a &amp; a \\<br>b &amp; b &amp; b \\<br>a &amp; a &amp; a \\<br>b &amp; b &amp; b<br>\end{array}\right]<br>$$<br>由于交换了Concat方式, a和b交错, 能够实现更多次交互.</p><h3 id="ConvE-Architecture"><a href="#ConvE-Architecture" class="headerlink" title="ConvE Architecture"></a>ConvE Architecture</h3><p>直接看图:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/conve1.jpg" style="zoom:67%"><p>整体流程也是非常简单, 将头实体和关系先Embedding, 然后再Reshape到一个合适的尺寸, 然后就用卷积来提取特征, 用全连接将其投影到与Embedding大小相同的隐空间中, 最后将隐空间的映射和尾实体的Embedding做相似度比较.</p><p>按照描述, 打分函数为:<br>$$<br>\psi_{r}\left(\mathbf{e}_{s}, \mathbf{e}_{o}\right)=f\left(\operatorname{vec}\left(f\left(\left[\overline{\mathbf{e}_{s}} ; \overline{\mathbf{r}_{r}}\right] \ast \omega\right)\right) \mathbf{W}\right) \mathbf{e}_{o}<br>$$<br>其中$\mathbf{e}_{s}, \mathbf{e}_{o}$ 分别代表头实体和尾实体的Embedding, $\overline{\mathbf{e}_{s}}, \overline{\mathbf{r}_{r}}$ 分别代表Reshape后的头实体和关系向量. $\omega$代表卷积核, $\mathbf{W}$ 代表投影矩阵. 这种方式通过内积来比较所获向量与尾实体的<strong>相似度</strong>, 越相似得分越高.</p><p>然后将该得分经过$\sigma$ 函数, 得到每个实体的概率:<br>$$<br>p=\sigma(\psi_{r}\left(\mathbf{e}_{s}, \mathbf{e}_{o}\right))<br>$$<br>使用二分类交叉熵进行优化:<br>$$<br>\mathcal{L}(p, t)=-\frac{1}{N} \sum_{i}\left(t_{i} \cdot \log \left(p_{i}\right)+\left(1-t_{i}\right) \cdot \log \left(1-p_{i}\right)\right)<br>$$<br>$t$ 是尾实体的独热编码向量. 除此外还加入了Dropout, BatchNorm, 标签平滑等防止过拟合的手段.</p><h2 id="AcrE"><a href="#AcrE" class="headerlink" title="AcrE"></a>AcrE</h2><p>AcrE(<strong>A</strong>trous <strong>C</strong>onvolution and <strong>R</strong>esidual <strong>E</strong>mbedding), 在ConvE的基础上主要做了两点改动, 也就是我们开头所需的前置知识, 空洞卷积和残差连接.</p><h3 id="Atrous-Convolution"><a href="#Atrous-Convolution" class="headerlink" title="Atrous Convolution"></a>Atrous Convolution</h3><p>Atrous Convolution也称<strong>空洞卷积</strong>或<strong>膨胀卷积</strong>. 由于空洞卷积只是作为一种CNN的变体形式的卷积, 因此它的机制在此不做过多讨论.</p><p>空洞卷积相较于普通卷积, 有了一个新的参数”<strong>膨胀率</strong>“. 它指的是在卷积下, 每个卷积核元素之间的距离 - 1. 空洞卷积能在<strong>不引入额外参数</strong>的情况下获得更大的<strong>感受野</strong>, 如下图:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/dilatedconv.jpg" style="zoom:33%"><p>上图取自<a href="https://arxiv.org/abs/1511.07122" target="_blank" rel="noopener">Multi-Scale Context Aggregation by Dilated Convolutions</a>.</p><table><thead><tr><th align="center"></th><th align="center">最左侧</th><th align="center">正中间</th><th align="center">最右侧</th></tr></thead><tbody><tr><td align="center">卷积核</td><td align="center">(3, 3)</td><td align="center">(3, 3)</td><td align="center">(3, 3)</td></tr><tr><td align="center">感受野</td><td align="center">$3 \times 3$</td><td align="center">$7 \times 7$</td><td align="center">$15 \times 15$</td></tr><tr><td align="center">膨胀率</td><td align="center">1</td><td align="center">2</td><td align="center">4</td></tr></tbody></table><blockquote><p>空洞卷积常在语义分割和图像重建上使用, 与之相对的, 使用空洞卷积也会带来一些<strong>弊端</strong>, 如有需求请自行查询相关内容.</p></blockquote><p>在AcrE中, 它用来解决CNN在连续重复的下采样和池化而导致<strong>特征图分辨率丢失</strong>问题. 个人认为, 由于空洞卷积扩大了感受野, 能进一步增加实体和关系Embedding之间的交互, 以此将头实体和关系更<strong>紧密</strong>的联系到一起.</p><h3 id="Residual-Connection"><a href="#Residual-Connection" class="headerlink" title="Residual Connection"></a>Residual Connection</h3><p>引入残差连接主要的原因有两个:</p><ul><li><strong>梯度爆炸</strong>和<strong>梯度消失</strong>.</li><li>多次卷积导致的<strong>原始信息丢失</strong>问题.</li></ul><p>在ConvE中, 作者没有使用残差连接. 关于残差连接, 不懂可以去我之前写的<code>&lt;卷积神经网络发展史&gt;</code>中了解.</p><h3 id="AcrE-Architecture"><a href="#AcrE-Architecture" class="headerlink" title="AcrE Architecture"></a>AcrE Architecture</h3><p>AcrE有两种结构, 分别是<strong>串行</strong>(Serial)结构和<strong>并行</strong>(Parallel)结构. 无论哪种都使用了空洞卷积和残差连接. 但无论哪种结构都必须要有<strong>标准卷积</strong>的作用, 膨胀卷积虽然会提供更大的感受野, 但也有可能会因膨胀丧失局部信息.</p><h4 id="2D-Embedding-Representation"><a href="#2D-Embedding-Representation" class="headerlink" title="2D Embedding Representation"></a>2D Embedding Representation</h4><p>在ConvE中已经提到, 1D卷积没有2D卷积的表达能力强, 而且2D卷积能更多的增强头实体和关系间的交互, 所以都使用的是2D卷积. AcrE中, 首先要说一下KG中的三元组在2D中的表示方法, 可以视作是<strong>预处理</strong>. 对于三元组$&lt;h, r, t&gt;$, $\mathbf{h}, \mathbf{r}, \mathbf{t}$分别代表头实体, 关系和尾实体.</p><p>若$\tau$ 代表<strong>Reshape</strong>操作, $\mathbf{e}$ 代表实体的Embedding, $\mathbf{r}$ 代表关系的Embedding, $[;]$ 代表Concat, 则2D中的嵌入表示方法是$\tau([\mathbf{e};\mathbf{r}])$.</p><h4 id="Serial-AcrE-Model"><a href="#Serial-AcrE-Model" class="headerlink" title="Serial AcrE Model"></a>Serial AcrE Model</h4><p>在串行AcrE中, Embedding由一系列串行的卷积动作和最后的Flatten.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre1.jpg" alt=""></p><h5 id="Standard-Convolution-based-Learning"><a href="#Standard-Convolution-based-Learning" class="headerlink" title="Standard Convolution based Learning"></a>Standard Convolution based Learning</h5><p>在串行AcrE中, 将Reshape后的Embedding先经过标准卷积, 得到结果$\mathbf{C}_{0}$:<br>$$<br>\mathbf{C}_{0}^{i}=\omega_{0}^{i} \star \tau([\mathbf{e} ; \mathbf{r}])+\mathbf{b}_{0}^{i}<br>$$<br>其中$\star$ 代表卷及操作, $\omega_{0}^{i}$ 代表第i个卷积核, $b_0^i$ 代表第i个偏置. 假设有$F$ 个卷积核, 则$\mathbf{C}_{0}=\left[\mathbf{C}_{0}^{1}: \mathbf{C}_{0}^{2}: \mathbf{C}_{0}^{3}: \ldots: \mathbf{C}_{0}^{F}\right]$, 之后该卷积结果会经过一系列的空洞卷积.</p><blockquote><p>关于池化, 这里必须要提一下.</p><p>在CV任务中是卷积和池化交替使用, 因为其信息量通常是<strong>冗余</strong>的, 池化能够减小特征图的尺寸, 相当于求平均或最大值的效果, 池化有利于后面卷积抽取更关键的特征.</p><p>但目前在NLP相关的任务中, 信息非常复杂, 使用池化直接就导致了信息的<strong>损失</strong>. 并且, 因为我们是想将头实体和尾实体还有关系Embedding进一个同维度的空间下的, 如果使用池化会导致<strong>维度变化</strong>.</p><p>最后指出, 在实验中加入池化并没有很大程度的影响性能.</p></blockquote><h5 id="Atrous-Convolution-based-Learning"><a href="#Atrous-Convolution-based-Learning" class="headerlink" title="Atrous Convolution based Learning"></a>Atrous Convolution based Learning</h5><p>“空洞卷积大致是什么”这个问题在前面已经解决了, 其实就是在卷积核各元素之间插入一些小洞. 对于给定的输入向量$\mathbf{x}$, 长度为$K$的卷积核向量$\mathbf{w}$, 在空洞卷积下的输出$\mathbf{y}$ 由如下方式得来:<br>$$<br>y_{i}=\sum_{k=1}^{K} x_{i+l \times k} \times w_{k}<br>$$<br>其中$l$ 是膨胀率, 标准卷积的膨胀率为1.</p><p>在串行AcrE中, 卷积是一个接着一个<strong>串行</strong>的:<br>$$<br>\mathbf{C}_{\mathbf{t}}=\omega_{\mathbf{t}} \star \mathbf{C}_{t-1}+\mathbf{b}_{\mathbf{t}}<br>$$<br>$\mathbf{C}_{t-1}$ 代表上个卷积的输出结果, $\omega_{\mathbf{t}}$ 和$\mathbf{b}_{\mathbf{t}}$ 分别是卷积核和偏置向量.</p><h5 id="Feature-Vector-Generation"><a href="#Feature-Vector-Generation" class="headerlink" title="Feature Vector Generation"></a>Feature Vector Generation</h5><p>在串行的AcrE中, 不同种卷积一个接一个的执行, 每个卷积都能从之前抽取不同的实体和关系交互. 但越多的卷积使用, 就会导致越多的原始信息丢失, 这就导致了模型在学习时<strong>忘记</strong>了抽取出的特征到底有没有用. 同时, 为了缓解梯度爆炸和梯度消失, 在这使用残差连接来<strong>弥补</strong>原来丢失的信息. 在残差连接后, 紧接着使用<strong>ReLU</strong>做激活函数, 并做<strong>Flatten</strong>:<br>$$<br>\mathbf{o}=\text {Flatten}\left(\operatorname{ReLU}\left(\mathbf{C}_{T}+\tau([\mathbf{e} ; \mathbf{r}])\right)\right)<br>$$<br>其中$\mathbf{C}_{T}$ 是最后一个空洞卷积的输出, $T$ 是空洞卷积的次数.</p><h4 id="Parallel-AcrE-Model"><a href="#Parallel-AcrE-Model" class="headerlink" title="Parallel AcrE Model"></a>Parallel AcrE Model</h4><p>并行AcrE分别执行卷积后聚合.</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre2.jpg" alt=""></p><p>注意, 在并行结构图中所示的<strong>卷积类型</strong>是不同的! 使用不同膨胀率的卷积核.</p><h5 id="Results-Integration"><a href="#Results-Integration" class="headerlink" title="Results Integration"></a>Results Integration</h5><p>与串行形态的AcrE不一样, 并行形态下, 2D Embedding分别用不同形式的卷积计算, 最后以<strong>某种形式</strong>聚合到一起.<br>$$<br>\mathbf{C}=\mathbf{C}_{\mathbf{0}} \oplus \mathbf{C}_{\mathbf{1}} \oplus \ldots \oplus \mathbf{C}_{\mathbf{T}}<br>$$<br>其中$\mathbf{C}_{\mathbf{0}}$ 是标准卷积, $\mathbf{C}_{\mathbf{i}}$ 是第i个空洞卷积. $\oplus$ 意味着某种聚合操作, 可以是基于Concat的操作, 也可以是基于加的操作等等. 在<strong>实验</strong>中会比较这两种方式的性能差异.</p><h5 id="Feature-Vector-Generation-1"><a href="#Feature-Vector-Generation-1" class="headerlink" title="Feature Vector Generation"></a>Feature Vector Generation</h5><p>与串行AcrE相仿, 将每个卷积结果聚合, 再加上残差的信息, 然后用ReLU, 再经过一次变换, 最后Flatten.<br>$$<br>\mathbf{c}=\text {Flatten}\left(\mathbf{W}_{\mathbf{1}} \operatorname{ReLU}(\mathbf{C}+\tau([\mathbf{e} ; \mathbf{r}]))\right)<br>$$<br>其中$\mathbf{W_1}$ 是变化矩阵, 这是比串行结构多出来的地方.</p><blockquote><p>我个人认为并行结构下的AcrE与Inception(详见<a href="https://adaning.github.io/posts/38085.html">卷积神经网络发展史</a>)中的<strong>多尺度</strong>是相同的道理, 通过不同的<strong>膨胀率</strong>实现了对实体和关系向量多个角度的抽取, 最后Concat到一起, 每个不同感受野的膨胀卷积都能提供不同的信息.</p></blockquote><h3 id="Score-Function-and-Loss-Function"><a href="#Score-Function-and-Loss-Function" class="headerlink" title="Score Function and Loss Function"></a>Score Function and Loss Function</h3><h4 id="Score-Function"><a href="#Score-Function" class="headerlink" title="Score Function"></a>Score Function</h4><p>打分函数其实与ConvE相似, 将输出向量先经过变换矩阵加上偏置, 再用点积比较与尾实体的<strong>相似度</strong>:<br>$$<br>\psi(h, r, t)=(\mathbf{o} \mathbf{W}+\mathbf{b}) \mathbf{t}^{\top}<br>$$<br>其中$\mathbf{W}, \mathbf{b}$ 分别是变化矩阵和偏置向量. 接着用$\sigma$ 函数获得所有候选实体的概率:<br>$$<br>p(t \mid h, r)=\operatorname{sigmoid}(\psi(h, r, t))<br>$$</p><h4 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h4><p>这点和ConvE一样, 使用了交叉熵作为损失函数:<br>$$<br>\mathcal{L}=-\frac{1}{N} \sum_{i=1}^{N}\left[t_{i} \log p\left(t_{i} \mid h, r\right)+\left(1-t_{i}\right) \log \left(1-p\left(t_{i} \mid h, r\right)\right)\right]<br>$$<br>其中$\mathbf{t}$ 是尾实体的独热编码.</p><h3 id="Other-Details"><a href="#Other-Details" class="headerlink" title="Other Details"></a>Other Details</h3><p>和ConvE一样, BatchNorm和卷积的向性比较好, 所以也使用了BatchNorm. 包括标签平滑啊之类的trick也都从ConvE沿用了下来.</p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p>在实验的代码中, 只使用了三个卷积核. 有一个标准卷积核和两个不同膨胀率的膨胀卷积核.</p><h3 id="Settings"><a href="#Settings" class="headerlink" title="Settings"></a>Settings</h3><h4 id="DataSets"><a href="#DataSets" class="headerlink" title="DataSets"></a>DataSets</h4><p>我们将其他KGE方法在如下六个常用数据集中对比:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre3.jpg" style="zoom:50%"><h4 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h4><p>实验部分均采用<strong>Link Prediction</strong>的任务将其他KGE方法与AcrE进行对比. Link Prediction是基于已知的某端实体和关系对未知的另一端实体进行预测的任务. 即对于三元组$&lt;h,r,t&gt;$, 已知$&lt;h,r&gt;$ 预测$t$, 或已知$&lt;t,r&gt;$ 预测$h$. 并使用Hit@k, MRR作为指标进行对比.</p><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><h4 id="Benchmark-Datasets-Experiment"><a href="#Benchmark-Datasets-Experiment" class="headerlink" title="Benchmark Datasets Experiment"></a>Benchmark Datasets Experiment</h4><p>在DB100k中的实验结果, 上面的内容全部取自SEEK的论文<a href="https://arxiv.org/pdf/2005.00856.pdf" target="_blank" rel="noopener">SEEK: Segmented Embedding of Knowledge Graphs</a>:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre4.jpg" style="zoom:50%"><p>还有在其他五个数据集上的表现:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre5.jpg" style="zoom:67%"> <img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre6.jpg" style="zoom:67%"><p>只是在WN18RR上没有取得太好的效果, 在其他数据集上均SOTA或在平均性能上超过其他KGE方法.</p><p>实验的细节分了<strong>区分头尾</strong>的预测和<strong>按类别</strong>预测两种.</p><p>下面是<strong>区分头尾</strong>的预测:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre7.jpg" style="zoom:67%"><p>直接SOTA.</p><p>下面是<strong>按类别</strong>预测:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre8.jpg" style="zoom:67%"><h4 id="Ablation-Experiment"><a href="#Ablation-Experiment" class="headerlink" title="Ablation Experiment"></a>Ablation Experiment</h4><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre9.jpg" style="zoom:67%"><p>消融实验主要进行了如下工作:</p><ol><li>将<strong>串行</strong>和<strong>并行</strong>的AcrE对比, 发现一般情况下串行的AcrE都比并行AcrE性能要<strong>差</strong>.</li><li>将<strong>带有</strong>残差连接的AcrE和<strong>去掉</strong>残差连接的AcrE对比, 发现去掉后性能有<strong>明显下降</strong>, 说明了残差连接对AcrE非常重要.</li><li>将并行用Concat方式聚合的AcrE和并行用Add方式聚合的AcrE对比, 发现<strong>Concat</strong>效果要好一些.</li></ol><h4 id="Parameters-Comparison"><a href="#Parameters-Comparison" class="headerlink" title="Parameters Comparison"></a>Parameters Comparison</h4><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/acre10.jpg" style="zoom:67%"><p>ConvE的参数虽然比AcrE要少, 但在前面的对比实验中知道效果并没有AcrE好. AcrE的参数量要<strong>远少于</strong>除了ConvE的所有模型. 并且并行结构比串行结构的模型要稍大一些, 因为最后<strong>多一次变换</strong>.</p><p>另外, 调参的部分碍于篇幅问题, 没有在论文中贴出. 能够选择的参数范围非常小, 还是比较好调的, 参数在源码中都可以找到.</p><p>关于计算效率的优势, 因为涉及到其他训练的参数影响, 没法提供一个非常公平的环境去验证. 但作为ConvE的变体, 运行时间的复杂度应该与ConvE相仿.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>该论文简单易懂, 只看嵌入方式的<strong>图示</strong>和<strong>表格</strong>中给出的实验结果就能够把握文章重点. 尤其是最后的<strong>消融实验</strong>体现出了<strong>残差连接</strong>起到的作用. AcrE本身结构就简单到了<strong>令人发指</strong>的地步, 非常不可思议它甚至能达到一些高复杂度模型的结果…</p><p>在实验部分将那些没有在指定数据集上给出实验结果的论文的Embedding方法全都跑了一遍, 并做了<strong>大量的对比实验</strong>证明AcrE的有效性. 并且这是<strong>第一次</strong>将<strong>不同形式的卷积</strong>用到了<strong>KGE</strong>上的研究工作.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/59193.html">https://ADAning.github.io/posts/59193.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/%E7%A9%BA%E6%B4%9E%E5%8D%B7%E7%A7%AF/"><span class="chip bg-color">空洞卷积</span> </a><a href="/tags/%E6%AE%8B%E5%B7%AE%E8%BF%9E%E6%8E%A5/"><span class="chip bg-color">残差连接</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/28100.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/10.jpg" class="responsive-img" alt="CoLAKE: Contextualized Language and Knowledge Embedding"> <span class="card-title">CoLAKE: Contextualized Language and Knowledge Embedding</span></div></a><div class="card-content article-content"><div class="summary block-with-text">CoLAKE: Contextualized Language and Knowledge Embedding 本文前置知识: BERT Self - Attention 2020.11.11: 想通了CoLAKE在训练时最关键的部分.</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-10-29 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/" class="post-category">知识图谱</a></span></div></div><div class="card-action article-tags"><a href="/tags/KGE/"><span class="chip bg-color">KGE</span> </a><a href="/tags/BERT/"><span class="chip bg-color">BERT</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/35276.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/5.jpg" class="responsive-img" alt="Transformer-XL与XLNet"> <span class="card-title">Transformer-XL与XLNet</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文前置知识: Transformer(Masked Self - Attention和FFN) BERT(与XLNet做对比) Seq2Seq(AutoRegressive &amp; AutoEncoding) 2020.10.2</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-10-14 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/NLP/"><span class="chip bg-color">NLP</span> </a><a href="/tags/Transformer/"><span class="chip bg-color">Transformer</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">354.4k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>