<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/22.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2023-01-03</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2023-06-01</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 11 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="UniRel-Unified-Representation-and-Interaction-for-Joint-Relational-Triple-Extraction"><a href="#UniRel-Unified-Representation-and-Interaction-for-Joint-Relational-Triple-Extraction" class="headerlink" title="UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction"></a>UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction</h1><p>本文是论文<a href="http://arxiv.org/abs/2211.09039" target="_blank" rel="noopener">UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction</a> 的阅读笔记和个人理解, 论文来自<strong>EMNLP 2022</strong>.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>作者认为现有的RTE模型存在下述两个缺点:</p><ol><li>实体表示和关系表示是<strong>异质</strong>的.</li><li>异质的建模了<strong>实体 - 实体</strong>间交互和<strong>实体 - 关系</strong>间交互.</li></ol><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel1.png" style="zoom:33%"><p>因此, 作者尝试<strong>统一</strong>关系与实体的<strong>表示类型</strong>, 并同时对二者做<strong>同质交互建模</strong>.</p><h2 id="UniRel"><a href="#UniRel" class="headerlink" title="UniRel"></a>UniRel</h2><h3 id="Problem-Formulation"><a href="#Problem-Formulation" class="headerlink" title="Problem Formulation"></a>Problem Formulation</h3><p>对于给定的$N$ 个Token的句子$X=\set{x_1, x_2, \dots, x_N}$, 联合关系三元组抽取的目标是找到句子$X$ 中所有的三元组$T=[(s_l, r_l, o_l)]^L_{l=1}$, 其中$s_l, o_l, r_l$ 分别为Subject, Object和它们之间的关系, $L$ 为句子中的三元组总数.</p><p>关系来自于预定义好的集合$R=\set{R_1, R_2, \dots, R_M}$, $M$ 为关系类型数量.</p><h3 id="Unified-Representation"><a href="#Unified-Representation" class="headerlink" title="Unified Representation"></a>Unified Representation</h3><p>在作者的方法中, 将关系以它的<strong>实际语义Token</strong>引入进来, 比如说关系<code>/business/company/founders</code> 被手动的用<code>founders</code>代替.</p><p>然后以它们Embedding的形式当做关系表示:</p><p>$$<br>\begin{gathered}<br>T=\operatorname{Concat}\left(T_s, T_p\right) \\<br>H=E[T]<br>\end{gathered}<br>$$</p><p>其中$H \in \mathbb{R}^{(N+M) \times d_h}$ 为输入到BERT的向量, $d_h$ 为隐层维度, $T_s, T_p$ 分别为输入句子的Token ID和关系的Token ID.</p><blockquote><p>这种方法其实可以看做是一种Prompt的应用, 附录中有关于作者对手动选择关系Token(Prompt) 的分析.</p><p>另外, 这里其实有一个小细节, 作者用BERT中的Segment Embedding(也就是Token Type Embedding)来区分实体和关系的Token.</p></blockquote><p>接着用Self Attention来捕捉这些所有输入词之间的关系:</p><p>$$<br>\operatorname{Attention}(Q, K, V)=\operatorname{softmax}\left(\frac{Q K^T}{\sqrt{d_h}}\right) V<br>$$</p><p>其中$Q, K, V$ 分别是由$H$ 得到的Query, Key, Value向量.</p><h3 id="Unified-Interaction"><a href="#Unified-Interaction" class="headerlink" title="Unified Interaction"></a>Unified Interaction</h3><p>由于作者认为异质建模实体和关系, 以及它们之间的交互, 是存在问题的. 所以作者尝试将它们的建模完全统一, 可以用如下交互图概括:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel2.png" style="zoom:33%"><p>作者说明了表格中这三种区域表述的实际意义:</p><ul><li>红色区域: <code>Entity - Entity Interaction</code>.</li><li>绿色区域: <code>Subject - Relation Interaction</code>.</li><li>蓝色区域: <code>Relation - Object Interaction</code>.</li></ul><p>交互图上的1便是<strong>行Token与列Token应该发生交互</strong>.</p><blockquote><p>从直观上来看, 这种设计实际上是将关系三元组拆分为若干条边来进行解码.</p></blockquote><h4 id="Entity-Entity-Interaction"><a href="#Entity-Entity-Interaction" class="headerlink" title="Entity - Entity Interaction"></a>Entity - Entity Interaction</h4><p>对于句子$X$ 中的两实体$e_a, e_b$ 形成的实体对$(e_a, e_b)$ 而言, 当它们之间存在某种关系$r$ 时, 两实体之间才会产生交互.</p><p>形式上来说, 实体 - 实体间是否交互的符号函数为:</p><p>$$<br>I_e\left(e_a, e_b\right)= \begin{cases}\text { True } &amp; \left(e_a, r, e_b\right) \in T \text { or } \\\ &amp; \left(e_b, r, e_a\right) \in T, \exists r \in R \\\ \text { False } &amp; \text { otherwise }\end{cases}<br>$$</p><p>由于$I_e(e_b, e_a) = I_e(e_a, e_b)$, 所以它是<strong>对称</strong>的.</p><blockquote><p><code>Entity - Entity Interaction</code> 建模了实体之间的对齐关系(实体之间的成对关系).</p></blockquote><h4 id="Entity-Relation-Interaction"><a href="#Entity-Relation-Interaction" class="headerlink" title="Entity - Relation Interaction"></a>Entity - Relation Interaction</h4><p>实体 - 关系交互仅当<strong>实体存在某关系</strong>时才会发生. 即无论实体$e$ 拥有关系$r$ 时自身的角色是Subject $s$ 还是Object $o$ 都应该产生交互.</p><p>实体关系间是否产生交互的符号函数形式如下:</p><p>$$<br>\begin{aligned}<br>&amp; I_r(e, r)= \begin{cases}\text { True } &amp; (e, r, o) \in T, \exists o \in E \\<br>\text { False } &amp; \text { otherwise }\end{cases} \\<br>&amp; I_r(r, e)= \begin{cases}\text { True } &amp; (s, r, e) \in T, \exists s \in E \\<br>\text { False } &amp; \text { otherwise }\end{cases}<br>\end{aligned}<br>$$</p><p>由于关系是有向的, 所以实体 - 关系间交互是<strong>反对称</strong>的.</p><blockquote><p>这种实体关系间交互的建模方式将表填充中的空间复杂度由$O(N\times M \times N)$ 优化到了$O((N+M)^2)$.</p></blockquote><h4 id="Interaction-Discrimination"><a href="#Interaction-Discrimination" class="headerlink" title="Interaction Discrimination"></a>Interaction Discrimination</h4><p>将BERT最后一层每个头$t$所生成的$Q_t, K_t$ 缩放点积后的结果取平均, 然后直接用Sigmoid做激活作为最终结果:</p><p>$$<br>\mathbf{I}=\operatorname{sigmoid}\left(\frac{1}{T} \sum_t^T \frac{Q_t K_t^T}{\sqrt{d_h}}\right)<br>$$</p><p>其中$\mathbf{I} \in \mathbb{R}^{(N+M)(N+M)}$ 是交互图中的交互矩阵, $T$ 是Self Attention头的数量, $W_t^Q, W_t^K$ 是可训练权重, 当$\mathbf{I}(\cdot)$ 超过阈值$\sigma$ 时, 认为该位置对应的行列Token存在交互.</p><blockquote><p>在作者设计的交互图中, 只需要算个$Q, K$ 之间的相似度得分就可以了, 不需要重新获得表格表示, 索性丢掉后面的步骤, 用$Q, K$ 就行了.</p><p>另外, 其实从模型角度来看, 整个模型没有引入任何的额外参数… 对… <strong>没有引入任何的额外参数</strong>.</p></blockquote><h4 id="Training-and-Decoding"><a href="#Training-and-Decoding" class="headerlink" title="Training and Decoding"></a>Training and Decoding</h4><h5 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h5><p>作者的方法采用一张二元交互图就可以将三元组全部抽取出, 因此Loss采用<strong>二分类交叉熵</strong>即可:</p><p>$$<br>\begin{aligned}<br>\mathcal{L}=-\frac{1}{(N+M)^2} \sum_i^{N+M} \sum_j^{N+M}\left(\mathbf{I}_{i, j}^\ast \log \mathbf{I}_{i, j}\right.<br>\left.+\left(1-\mathbf{I}_{i, j}^\ast\right) \log \left(1-\mathbf{I}_{i, j}\right)\right)<br>\end{aligned}<br>$$</p><p>$\mathbf{I}^\ast$ 为交互图矩阵中的Ground Truth.</p><h5 id="Decoding"><a href="#Decoding" class="headerlink" title="Decoding"></a>Decoding</h5><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel3.png" style="zoom:33%"><p>咱们直接拿交互图中的例子来说明解码流程:</p><ol><li>根据右侧的<strong>绿色框框</strong>(Subj - Rel)和下面的<strong>蓝色框框</strong>(Rel - Obj)分别解码出每种关系$r$ 对应的Subject $e_i$ 和Object $e_j$. 即抽取出$(e_{i,}r), (r, e_j)$.</li><li>根据上一步找到的所有实体$e_i, e_j$, 穷举出所有的实体对$(e_{p}, e_q)$, 结合左上角的<strong>红色框框</strong>(Ent - Ent), 查看是否有对应的$(e_{p,}e_q)$ 为1.</li><li>如果在红色框框里有$(e_{p,}e_q)$ 为1, 则构成三元组$(e_{i},r, e_j)$. 即利用Subj - Rel $(e_{i},r)$, Ent - Ent $(e_{i,}e_j)$, Rel - Obj $(r, e_j)$ 共同形成三元组$(e_{i,}r, e_j)$.</li></ol><p>例如, 在图中给出了一个既含有EPO又含有SEO的例子(在这里关系均使用语义Token代替):</p><ol><li>首先从右侧的绿色框框拿到<strong>Subj - Rel</strong>, 有<code>(Holmes, Live)</code>, <code>(London, Capital)</code>, <code>(UK, Contain)</code>.</li><li>从下面的蓝色框框拿到<strong>Rel - Obj</strong>, 有<code>(Capital, London)</code>, <code>(Live, London)</code>, <code>(Capital, UK)</code>, <code>(Live, UK)</code>.</li><li>然后<strong>穷举</strong>出所有的<strong>实体对</strong>, 并结合红色框框<strong>Ent - Ent</strong>进行检查, 有效的有<code>(Holmes, London)</code>, <code>(Holmes, UK)</code>, <code>(UK, London)</code>, <code>(London, UK)</code> 这四个实体对.</li><li>结合<strong>Subj - Rel</strong>, <strong>Rel - Obj</strong>, <strong>Ent - Ent</strong>, 可以解码出关系三元组. 比如, Subj - Rel有<code>(Holmes, Live)</code>, Rel - Obj有<code>(Live, London)</code>, 同时Ent - Ent有<code>(Holmes, London)</code>, 那么就可以解码出三元组<code>(Holmes, Live, London)</code>. 与之类似的, 可以共同解码出<code>(Holmes, Live, UK)</code>, <code>(UK, Contain, London)</code>, <code>(London, Capital, UK)</code> 这其他三个三元组.</li></ol><h3 id="Extended-to-Multi-token-Entity-Setting"><a href="#Extended-to-Multi-token-Entity-Setting" class="headerlink" title="Extended to Multi - token Entity Setting"></a>Extended to Multi - token Entity Setting</h3><p>如果上述方法去打标签, 会产生一个严重问题: 面对<strong>多Token实体</strong>要怎么办? 起初, 我认为该方法仅能在NYT和WebNLG的部分匹配数据集上生效.</p><p>后来我发现作者在附录中写到, UniRel实际上可以扩展到多Token实体. 具体的方法是:</p><ol><li>将实体识别从<strong>单Token识别</strong>扩展为<strong>边界识别</strong>. 即先将一张交互图变为<strong>两张</strong>, 来分别完成<code>(Subject Head, Relation, Object Head)</code>以及<code>(Subject Tail, Relation, Object Head)</code>的抽取.</li><li>添加<strong>第三张</strong>关于每个实体的头尾交互图, 完成<code>(Head, Relation, Tail)</code>的抽取.</li><li>对于每个关系, 将实体的<strong>头尾Token链接</strong>起来, 作为一个实体, 然后像之前一样解码.</li></ol><p>所以作者使用了<strong>三张</strong>交互图完成了单Token实体到多Token实体的转化.</p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的参数设置请参照原论文.</p><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>本论文所采用的实验数据集是NYT和WebNLG, 主要是二者的<strong>部分匹配</strong>版本:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel4.png" style="zoom:25%"><h3 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h3><p>在NYT和WebNLG的部分匹配上结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel5.png" style="zoom:25%"><p>先全局的看一下结果, UniRel打败了<a href="https://adaning.github.io/posts/4754.html">OneRel</a>成为了SOTA, 甚至WebNLG冲着95去了, NYT部分匹配也快能到94了.</p><p>这里面有两种额外设置:</p><ul><li><strong>unused</strong>: 用BERT<code>[unused*]</code> Token来代替每种关系的语义Embedding, 也就是重新训练一个随机初始化的关系Embedding.</li><li><strong>separate</strong>: 用一个共享的BERT分别将输入的<strong>句子</strong>和<strong>关系语义Token</strong>编码, 然后用不同的两个Transformer Layer获得对应的Q和K, 再将Q, K分别拼接后做点积预测.</li></ul><p>能够看到, 当把关系换到随机初始化的Embedding, 而不是它们的语义Token的Embedding后在WebNLG上效果骤降.</p><p>在原论文的附录中其实也有<strong>精准匹配</strong>的结果(多Token设置):</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel6.png" style="zoom:25%"><p>总的来说也是SOTA, 但是可能对比没有部分匹配的结果提升明显, 并且它使用了三张交互图, 所以就没有放到正文中.</p><p>在NYT*上的复杂场景下UniRel结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel7.png" style="zoom:25%"><p>能够观察到比较明显的提升来自于识别<strong>Normal三元组</strong>(Normal三元组总体数量更多), 在更多三元组的句子中也有相较于别的模型比较大的提升.</p><blockquote><p>而且从交叉验证来看, 作者的算法是比较稳定的. 现在少有还在做交叉验证的算法, 做了比较严谨.</p></blockquote><h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><h4 id="Effect-of-the-Unified-Representation"><a href="#Effect-of-the-Unified-Representation" class="headerlink" title="Effect of the Unified Representation"></a>Effect of the Unified Representation</h4><p>为了证明作者的统一表示建模有效, 所以作者采用了<code>unused</code> 设置(详见主实验结果), 发现在WebNLG上效果下降的非常厉害. 所以作者怀疑是WebNLG的数据所致, WebNLG中有更多的关系, 但是却只有更少的数据.</p><p>为了验证这个猜想, 作者统计了不同数量样本的关系下预测三元组的情况, 如下所示:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel8.png" style="zoom:40%"><p>F1明显的在关系所对应的样本数量增大后提升, 但UniRel在融入了一定的语义信息后, 即使是在&gt;1000条样本的设置下, 比<code>unused</code> 自由学习结果还是要好一些.</p><h4 id="Effect-of-the-Unified-Interaction"><a href="#Effect-of-the-Unified-Interaction" class="headerlink" title="Effect of the Unified Interaction"></a>Effect of the Unified Interaction</h4><p>为了证实作者建模的统一交互形式有效, 作者采用了<code>sparate</code> 设置. 在去掉了实体间交互和实体关系交互后, 效果有所下降.</p><p>作者分别测试了在两个数据集上的实体间交互和实体关系交互预测的准确率:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel9.png" style="zoom:40%"><p>无论是哪个数据集, 分离的方式都不如同时交互的方式, 说明把它们都放在一个表下交互是有效的.</p><h4 id="Computational-Efficiency"><a href="#Computational-Efficiency" class="headerlink" title="Computational Efficiency"></a>Computational Efficiency</h4><p>作者对比了UniRel与前人方法中的训练时间和推理时间:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel10.png" style="zoom:25%"><p>在将关系表数量减少后, 训练速度和推理速度都有了明显的提升, 那么空间复杂度实际上也从表填充方法的$O(N \times M \times N)$ 优化到了$O((N + M)^2)$.</p><h4 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h4><p>作者的表填充设计非常有意思, 所以可以做一个句子和关系语义拼在一起的可视化:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unirel11.png" style="zoom:40%"><p>能看到图中的模型学的很好, 大多数置信度都非常高. 并且抽出了所有的六个三元组, 分别为<code>(Yunnan, country, China)</code>, <code>(China, administrative_divisions, Yunnan)</code>, <code>(Thailand, contains, Chiang Mai)</code>, <code>(Yunan, Contains, Jinghong)</code>, <code>(China, Contains, Jinghong)</code>, <code>(China, Contains, Yunnan)</code>.</p><blockquote><p>其实从图中也能看出一些表填充设计上的鲁棒性, <code>(China, Jinghong)</code> 之间的三元组成立是通过主对角线两侧有任意一个超过阈值即可. 即使主对角线下面标成0.34了, 但是上面是0.72挽救了这一问题, 这点作者没有在原文中提到.</p><p>在开源代码中, 分两次进行抽取, 分别抽取上三角和下三角, 所以在抽取上三角时, 0.72已经可以检测出<code>(China, Jinghong)</code> 存在关系, 不需要在意下三角是否抽取出.</p></blockquote><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>UniRel是一种表填充式的RTE方法, 通过将关系转化为<strong>语义Token</strong>, 把实体和关系变成了<strong>统一表示方法</strong>, 并且做<strong>完全同质建模</strong>, 效果达到了目前任务上真正的SOTA.</p><p>效率是非常高的, 从$O(N\times M \times N)$ 优化到了$O((N+M)^2)$, <strong>解决了表填充带来的关系表冗余的问题</strong>.</p><p>从实验上来看, 作者提出的算法还是比较<strong>稳定</strong>的, 并且具有一定的<strong>容错率</strong>.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/4431.html">https://ADAning.github.io/posts/4431.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/33099.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/17.jpg" class="responsive-img" alt="QIDN: Query-based Instance Discrimination Network for Relational Triple Extraction"> <span class="card-title">QIDN: Query-based Instance Discrimination Network for Relational Triple Extraction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Query-based Instance Discrimination Network for Relational Triple Extraction本文是论文Query-based Instance Discrimination Net</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2023-02-10 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span> </a><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/20020.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/23.jpg" class="responsive-img" alt="OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction"> <span class="card-title">OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction</span></div></a><div class="card-content article-content"><div class="summary block-with-text">OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction本文是论文OneEE: A One-Stage Framework for Fast</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-11-21 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/EE/"><span class="chip bg-color">EE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">362.2k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>