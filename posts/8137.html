<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="UniRE: A Unified Label Space for Entity Relation Extraction, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>UniRE: A Unified Label Space for Entity Relation Extraction | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/17.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">UniRE: A Unified Label Space for Entity Relation Extraction</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2022-09-22</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-10-15</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 4.4k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 17 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="UniRE-A-Unified-Label-Space-for-Entity-Relation-Extraction"><a href="#UniRE-A-Unified-Label-Space-for-Entity-Relation-Extraction" class="headerlink" title="UniRE: A Unified Label Space for Entity Relation Extraction"></a>UniRE: A Unified Label Space for Entity Relation Extraction</h1><p>本文是论文<a href="http://arxiv.org/abs/2107.04292" target="_blank" rel="noopener">UniRE: A Unified Label Space for Entity Relation Extraction</a> 的阅读笔记和个人理解, 论文来自<strong>ACL 2021</strong>.</p><h2 id="Basic-Idea"><a href="#Basic-Idea" class="headerlink" title="Basic Idea"></a>Basic Idea</h2><p>作者认为现有的ERE模型经常将标签空间分为实体检测和关系分类两个子空间, 这样做会<strong>缺失实体和关系的交互</strong>. 作者希望使用一个<strong>统一的标签空间</strong>来消除两个子空间之间的差别对待, 并通过<strong>填表法</strong>来在统一空间中将实体和关系同时抽取出来.</p><h2 id="UniRE"><a href="#UniRE" class="headerlink" title="UniRE"></a>UniRE</h2><h3 id="Task-Definition"><a href="#Task-Definition" class="headerlink" title="Task Definition"></a>Task Definition</h3><p>对于给定的句子$s=x_1, x_2, \ldots, x_{|s|}$, ERE的目标是抽取出所有的实体$\mathcal{E}$ 和实体之间存在的关系$\mathcal{R}$.</p><p>每个实体$e$ 对应着一种预定义好的实体类型$e.\text{type} \in \mathcal{Y}_e$, 例如<code>PER</code>, <code>GPE</code> 等, 由单个或多个<strong>连续Token</strong>构成.</p><p>每种关系是一个由两个实体$e_{1,}e_{2}$ 和预定义好的关系$l \in \mathcal{Y}_r$ 构成的三元组$(e_{1,}e_{2,} l)$,</p><p>作者将ERE视为一个表填充问题. 对于句子$s$, 作者尝试维护一个表$T^{|s| \times |s|}$, 在表$T$ 中的每个单元格$(i, j)$ 都应该被打上一个标签$y_{i, j} \in \mathcal{Y}$, $\mathcal{Y}=\mathcal{Y}_e \cup \mathcal{Y}_r \cup\{\perp\}$, $\perp$ 代表没有关系存在.</p><p>对于每个实体$e$, 它在表上对应的单元格$y_{i, j}\left(x_i \in e.\text{span}, x_{j \in} e.\text{span} \right)$ 都应该被填上它的实体类型$e.\text{type}$.</p><p>对于实体之间的每种关系$r=(e_{1,}e_{2,}l)$, 它们之间对应的单元格$y_{i, j}\left(x_i \in e.\text{span}, x_{j \in} e.\text{span} \right)$ 应该被填充上关系$l$. 其他的所有单元格应该被填上$\perp$.</p><p>上述标注策略如下所示:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire1.png" style="zoom:67%"><p>每个单元格都对应着一对Token. 作者注意到, 每个<strong>实体</strong>的标签都散落在<strong>对角线上</strong>, 并且是一个<strong>正方形</strong>, <strong>关系</strong>是散落在<strong>对角线两侧</strong>的<strong>长方形</strong>.</p><p>在例子中, <code>PER-SOC</code> 是无向关系, <code>PHYS</code> 和<code>ORG-AFF</code> 都是有向关系, 这意味着它们在表上的标签是<strong>反对称</strong>的. 同时, 由于表实质是Token Pair的优势, 存在<strong>关系重叠</strong>也可以轻松地解决(RTE之前的挑战主要就是解决重叠问题). 如例子中<code>David Perkins</code> 被<code>PHYS</code> 和<code>PER-SOC</code> 所共享(在RTE里叫Single Entity Overlap), 但是仍然可以通过<strong>同行的不同列</strong>将这两种关系标注出来.</p><p>在测试阶段, 对实体关系的解码就变成了一个<strong>寻找长方形</strong>问题.</p><blockquote><p>作者在这里简单的假设<strong>不存在重叠实体</strong>.</p></blockquote><h3 id="Biaffine-Model"><a href="#Biaffine-Model" class="headerlink" title="Biaffine Model"></a>Biaffine Model</h3><p>对于给定的输入句子$s$, 用BERT作为预训练语言模型PLM获得每个Token的上下文表示$\mathbf{h}_i$, 那么句子中所有的Token表示为:</p><p>$$<br>\left\{\mathbf{h}_1, \ldots, \mathbf{h}_{|s|}\right\}=\operatorname{PLM}\left(\left\{\mathbf{x}_1, \ldots, \mathbf{x}_{|s|}\right\}\right)<br>$$</p><p>其中$\mathbf{x}_i$ 为每个Token$x_i$ 的输入表示(Embedding).</p><p>接着, 使用两个MLP对头尾角色(也就是表的行和列)做区分:</p><p>$$<br>\begin{aligned}<br>\mathbf{h}_i^{\text {head }}&amp;=\operatorname{MLP}_{\text {head }}\left(\mathbf{h}_i\right)<br>\\<br>\quad \mathbf{h}_i^{\text {tail }}&amp;=\operatorname{MLP}_{\text {tail }}\left(\mathbf{h}_i\right)<br>\end{aligned}<br>$$</p><p>其中$\mathbf{h}_i^{\text {head }} \in \mathbb{R}^{d,}\mathbf{h}_i^{\text {tail }} \in \mathbb{R}^d$ 分别为头尾的投影表示.</p><p>接着, 使用双仿射来计算表中每个单元格(Token Pair)的得分$\mathbf{g}_{i, j} \in \mathbb{R}^{|\mathcal{Y}|}$:</p><p>$$<br>\begin{aligned}<br>\mathbf{g}_{i, j} &amp;=\operatorname{Biaff}\left(\mathbf{h}_i^{\text {head }}, \mathbf{h}_j^{\text {tail }}\right) \\<br>\operatorname{Biaff}\left(\mathbf{h}_1, \mathbf{h}_{\mathbf{2}}\right) &amp;=\mathbf{h}_1^T \mathbf{U}_1 \mathbf{h}_2+\mathbf{U}_2\left(\mathbf{h}_1 \oplus \mathbf{h}_2\right)+\mathbf{b}<br>\end{aligned}<br>$$</p><p>其中$\mathbf{U}_{1}\in {|\mathcal{Y}| \times d \times d}, \mathbf{U}_{2}\in \mathbb{R}^{|\mathcal{Y} \times 2d|}, \mathbf{b} \in \mathbb{R}^{|\mathcal{Y}|}$ 为可训练参数, $\oplus$ 为拼接操作.</p><blockquote><p>双仿射被认为是<strong>最深层次</strong>的Token Pair间交互方式, 最早用在依存分析里面, 现在基本上是NER SOTA的标配了.<br>虽然双仿射同时包含了<strong>加性</strong>和<strong>乘性</strong>, 但在Pytorch里仍然可以用<code>torch.einsum</code> 很简洁的实现, 如下:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">Biaffine</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_size<span class="token punctuation">,</span> out_size<span class="token punctuation">,</span> bias_x<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> bias_y<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
        super<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>  
        self<span class="token punctuation">.</span>in_size <span class="token operator">=</span> in_size  
        self<span class="token punctuation">.</span>out_size <span class="token operator">=</span> out_size  
        self<span class="token punctuation">.</span>bias_x <span class="token operator">=</span> bias_x  
        self<span class="token punctuation">.</span>bias_y <span class="token operator">=</span> bias_y  

        weight <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>in_size <span class="token operator">+</span> int<span class="token punctuation">(</span>bias_x<span class="token punctuation">)</span><span class="token punctuation">,</span> out_size<span class="token punctuation">,</span> in_size <span class="token operator">+</span> int<span class="token punctuation">(</span>bias_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>weight<span class="token punctuation">)</span>  
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>weight<span class="token punctuation">)</span>  

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>  
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>bias_x<span class="token punctuation">:</span>  
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>bias_y<span class="token punctuation">:</span>  
            y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>y<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  
        hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">"bxi,ioj,byj->bxyo"</span><span class="token punctuation">,</span> x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  
        <span class="token keyword">return</span> hidden<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>关于该代码的推导可以参照这里:</p><ul><li><a href="https://zhuanlan.zhihu.com/p/464138965" target="_blank" rel="noopener">Biaffine for NER：Named Entity Recognition as Dependency Parsing - 知乎</a></li></ul></blockquote><h3 id="Table-Filling"><a href="#Table-Filling" class="headerlink" title="Table Filling"></a>Table Filling</h3><p>在有了表内单元格的打分$\mathbf{g}_{i, j}$ 后, 直接使用Softmax对单元格做多分类, 获得单元格内标签的概率$P\left(\mathbf{y}_{i, j} \mid s\right)$:</p><p>$$<br>P\left(\mathbf{y}_{i, j} \mid s\right)=\operatorname{Softmax}\left(\mathrm{dropout}\left(\mathbf{g}_{i, j}\right)\right)<br>$$</p><blockquote><p>作者提到, 这里在Logits之前使用Dropout的技巧为模型性能带来了一点提升. 这种Trick称为Logits Dropout. 默认设为0.2.</p></blockquote><p>然后使用多分类交叉熵优化:</p><p>$$<br>\mathcal{L}_{\text {entry }}=-\frac{1}{|s|^2} \sum_{i=1}^{|s|} \sum_{j=1}^{|s|} \log P\left(\mathbf{y}_{i, j}=y_{i, j} \mid s\right)<br>$$</p><p>其中$y_{i, j}$ 为表内的Golden Label.</p><h3 id="Constraints"><a href="#Constraints" class="headerlink" title="Constraints"></a>Constraints</h3><p>作者观察到, 表内的单元格并不是互相独立的, 上述分类器直接用上去就忽视了表内标签位置上的关联. 比如实体和无向关系在表内的标签总是正方形和长方形, 根据这个特性就令$\mathcal{P} \in \mathbb{R}^{|s| \times|s| \times|\mathcal{Y}|}$ 为表内所有单元格对应的标签概率的堆叠, 结合直观上的特性, 作者很直觉上的为模型加了两个约束Loss来帮助模型学习.</p><h4 id="Symmetry"><a href="#Symmetry" class="headerlink" title="Symmetry"></a>Symmetry</h4><p>表内的<strong>实体标签和对称关系标签总是对称</strong>的. 所以对它们来说, 表格上的对称位置应该具有<strong>相同的标签概率分布</strong>. 添加一个表内的对称Loss$\mathcal{L}_{\mathrm{sym}}$:</p><p>$$<br>\mathcal{L}_{\mathrm{sym}}=\frac{1}{|s|^{2}} \sum_{i=1}^{|s|} \sum_{j=1}^{|s|} \sum_{t \in \mathcal{Y}_{\mathrm{sym}}}\mid \mathcal{P}_{i, j, t}-\mathcal{P}_{j, i, t}\mid<br>$$</p><p>$\mathcal{Y}_\text{sym}$ 代表对称的标签, 也就是实体类型标签和对称关系类型的集合.</p><p>在数据集中包含的对称标签如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire2.png" style="zoom:67%"><p>包含了所有的实体标签, 以及部分对称关系.</p><h4 id="Implication"><a href="#Implication" class="headerlink" title="Implication"></a>Implication</h4><p>因为<strong>关系是基于实体</strong>的, 所以作者认为<strong>关系存在的概率不应该比实体存在的概率更大</strong>.</p><p>更直观点, 因为第$i$ 行和第$i$ 列对应的是某个Token和其他Token之间存在的<strong>关系</strong>, 该Token对应的所有关系标签$l$ 的概率$\mathcal{P}_{i,:, l}, \mathcal{P}_{:, i, l}$ 都不应该大于它自身(位于主对角线上)实体标签$t$ 的概率$\mathcal{P}_{i, i, t}$, 因此添加下述辅助Loss:</p><p>$$<br>\mathcal{L}_{\mathrm{imp}}=\frac{1}{|s|} \sum_{i=1}^{|s|}\left[\max _{l \in \mathcal{Y}_r}\left\{\mathcal{P}_{i,:, l}, \mathcal{P}_{:, i, l}\right\}-\max _{t \in \mathcal{Y}_e}\left\{\mathcal{P}_{i, i, t}\right\}\right]_\ast<br>$$</p><p>其中$[u]_{\ast}= \max(u, 0)$ 为<strong>Hinge Loss</strong>, 由于概率之间的差值本身就比较小, 所以也就不用添加Margin了.</p><p>Hinge Loss可以最大化这两类概率之间的差值, 也就是让关系的概率更小些, 实体类型的概率更大些.</p><p>最后简单的将主Loss和两个约束Loss相加即可:</p><p>$$<br>\mathcal{L}=\mathcal{L}_{\text {entry }}+\mathcal{L}_{\text {sym }}+\mathcal{L}_{\mathrm{imp}}<br>$$</p><p>至此, 模型的大致运行过程可以由下图概括:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire3.png" style="zoom:67%"><p>由PLM先抽取特征, 然后用双仿射得到一张将实体关系统一在同一空间下的表, 同时使用一个主Loss和两个辅助约束Loss对模型进行优化, 再由一种解码算法得到实体和关系.</p><h3 id="Decoding"><a href="#Decoding" class="headerlink" title="Decoding"></a>Decoding</h3><p>测试阶段需要根据$\mathcal{P} \in \mathbb{R}^{|s| \times|s| \times|\mathcal{Y}|}$ 进行解码, 作者希望这个解码算法能够做到又快又强.</p><p>作者使用了一种三步解码算法:</p><ol><li>解码Span以识别实体边界.</li><li>解码实体的实体类型.</li><li>解码实体对的关系类型.</li></ol><h4 id="Span-Decoding"><a href="#Span-Decoding" class="headerlink" title="Span Decoding"></a>Span Decoding</h4><p>作者观察到, 任何一个实体, 它所对应的<strong>行之间或列之间是完全一致的</strong>.</p><blockquote><p>因为同一个实体所对应的多个行或多个列<strong>仍然归属于该实体本身</strong>, 所以它们对应的关系和实体标签是一致的.</p></blockquote><p>因此, <strong>当相邻行或相邻列不同时, 一定意味着有实体边界的产生</strong>.</p><p>基于上述观察, 作者将$\mathcal{P} \in \mathbb{R}^{|s| \times|s| \times|\mathcal{Y}|}$ 从<strong>行视角</strong>展平为二维矩阵$\mathcal{P}^\text{row} \in \mathbb{R}^{|s| \times (|s| \times|\mathcal{Y}|)}$, 计算相邻行之间的欧氏距离. 与行相对应的, 从<strong>列视角</strong>展平为二维矩阵$\mathcal{P}^\text{col} \in \mathbb{R}^{(|s| \times |\mathcal{Y}| ) \times |s| }$, 计算相邻列之间的欧氏距离. 最后将二个距离求平均, 作为最终距离, 当最终距离大于一个阈值$\alpha$ 的时候, 则判定该位置为切割点.</p><p>结合作者给出的示意图很好理解找实体边界(切割点)的思想:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire4.png" style="zoom:67%"><blockquote><p>这种对<strong>概率分布差求平均</strong>的解码方式很新颖啊, 也很取巧, 估计阈值$\alpha$ 的调整会对结果产生很大的影响(见后文实验).</p></blockquote><p>作者通过这种方式将解码时间复杂度缩减到了$\mathcal{O}(|s|)$.</p><blockquote><p>作者在脚注里偷偷写到, 在Inference阶段, 对于对称的标签$t \in \mathcal{Y}_{\text{sym}}$, 作者设置$\mathcal{P}_{i, j, t} = \mathcal{P}_{j, i, t} = (\mathcal{P}_{i, j, t} + \mathcal{P}_{j, i, t}) / 2$. 我认为这样做可以增大对称标签所对应的实体类型或关系类型的正确率, 对称关系或标签总是成对出现, 结合这种分割实体边界的分块思想, 更容易将块内实体或关系分类正确.</p></blockquote><h4 id="Entity-Type-Decoding"><a href="#Entity-Type-Decoding" class="headerlink" title="Entity Type Decoding"></a>Entity Type Decoding</h4><p>对于由Span Decoding给出的Span$(i, j)$, 实体类型$\hat{t}$ 由<strong>对角线</strong>上的对称的正方形中最大的实体类型概率得到:</p><p>$$<br>\hat{t}=\arg \max _{t \in \mathcal{Y}_e \cup\{\perp\}} \operatorname{Avg}\left(\mathcal{P}_{i: j, i: j, t}\right)<br>$$</p><p>若$\hat{t} \in \mathcal{Y}_e$, 则解码出实体, 若$\hat{t}=\perp$ 则认为Span$(i, j)$ 不是实体.</p><h4 id="Relation-Type-Decoding"><a href="#Relation-Type-Decoding" class="headerlink" title="Relation Type Decoding"></a>Relation Type Decoding</h4><p>类似于实体类型的得出, 在得到Span$(i,j)$ 存在的实体$e_1$ 和Span$(m, n)$ 存在的实体$e_2$ 后, 关系类型$\hat{l}$ 也由相应的实体构成的长方形得到:</p><p>$$<br>\hat{l}=\arg \max _{l \in \mathcal{Y}_r \cup\{\perp\}} \operatorname{Avg}\left(\mathcal{P}_{i: j, m: n, l}\right)<br>$$</p><p>若$\hat{t} \in \mathcal{Y}_r$, 则解码出关系三元组$(e1, e2, \hat{l})$, 若$\hat{t}=\perp$ 则认为$e_{1,}e_2$ 间没有关系.</p><p>上述三步解码可以归结为下图:</p><p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire5.png" alt=""></p><h2 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h2><p>详细的实验设置请参照原论文.</p><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><p>数据集是NER上常用的三个数据及ACE04 / 05和SciERC, 统计信息如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire6.png" style="zoom:75%"><h3 id="Performance-Comparison"><a href="#Performance-Comparison" class="headerlink" title="Performance Comparison"></a>Performance Comparison</h3><p>在这里关系预测使用的是<strong>严格评估</strong>, 也就是实体的边界, 类型, 以及它们之间的关系都正确时才算正确. 结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire7.png" style="zoom:67%"><p>Wang et al.和Zhong and Chen分别对应着20年ERE方法<a href="https://adaning.github.io/posts/37252.html">TSE</a>和<a href="https://adaning.github.io/posts/22256.html">PURE</a>. UniRE在ACE05上的表现并没有PURE好, 但在更困难的SciERC上效果略好于PURE. 在ACE04上的表现比Baseline好得多.</p><blockquote><p>由于关系预测使用的是<strong>严格标准</strong>, 所以关系预测任务难度要大得多, 整个ERE任务性能好不好应该看关系预测效果, 而不是实体抽取效果.</p></blockquote><p>当使用BERT - base做PLM的时候, 在所有数据集上UniRE都是略差于PURE的, 有些小尴尬. 我认为这可能证明了在困难任务上, Joint Model需要更大的PLM底层的知识作为驱动.</p><h3 id="Ablation-Study"><a href="#Ablation-Study" class="headerlink" title="Ablation Study"></a>Ablation Study</h3><p>在ACE05和SciERC上的消融实验结果如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire8.png" style="zoom:67%"><p>在没有辅助Loss约束的情况下, 其实UniRE已经可以作为一个比较好的Baseline了.</p><p>影响如下:</p><ul><li>Symmetry Loss: 在ACE05上实体识别稍微掉了一点, 但是在SciERC上有明显涨点. 它对实体分类有效, 在两个数据集上似乎对关系分类也很有帮助的.</li><li>Implication Loss: 在ACE05上移除会有害于关系预测, 发挥了不小作用, SciERC上则是稍稍一点副作用.</li><li>Logit Dropout: 在两个数据集上, 使用Logit Dropout带来了两个点的提升.</li><li>Cross - Sentence Context: 像PURE里面一样, 也使用一个跨句的窗口来捕捉长距离依赖. 使用更大的上下文有益于任务.</li><li>Hard Decoding: 直接使用概率分布硬解码, 而不使用作者提出的解码算法. 对于正方形 / 长方形, 对应的实体类型 / 关系类型均取最高频次者. 如果直接硬解码, 效果会非常差, 证明了作者的解码方法有效.</li></ul><h3 id="Inference-Speed"><a href="#Inference-Speed" class="headerlink" title="Inference Speed"></a>Inference Speed</h3><p>作者比较了UniRE与PURE在两个数据集上的性能和推理速度, 以及参数:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire9.png" style="zoom:75%"><p>PURE因为采用了两个独立的Encoder所以参数量是UniRE的两倍. 从结果中可以看出, UniRE比PURE的近似模型推理速度快不少. 性能上不相上下.</p><h3 id="Impact-of-Different-Threshold-α"><a href="#Impact-of-Different-Threshold-α" class="headerlink" title="Impact of Different Threshold α"></a>Impact of Different Threshold α</h3><p>在前文中提到过, 基于阈值的解码方法会因阈值大小而产生很大影响. 关于阈值的选取, 作者分析了ACE05验证集上的行距离分布, 如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire10.png" style="zoom:75%"><p>作者发现不是实体边界的地方几乎都集中在0附近, 也就是归于同一实体的不同行得到的概率分布是十分相似的, 而位于实体边界的行之间的欧氏距离位于1.4到1.5左右较多. 这大致可以说明作者的直觉是正确的.</p><p>光有直观的感觉还不太够, 还要具体的实验数据来论证, 在ACE05验证集上Span F1, Entity F1, Relation F1随阈值的变化如下:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire11.png" style="zoom:75%"><p>能够看到, 在阈值设定为1.4之前模型一直都有很稳定的表现, 而且表现得不错, 在将阈值设置为1.5时, Span F1和Entity F1直接有一个断崖式的下降. 也就是说当阈值大于1.5时边界将变得不再那么容易区分, 很多可以区分的实体都集中在1.4到1.5之间. Relation F1却下降的没有那么厉害, 作者认为是由于关系比较稀疏, 许多实体之间不存在关系, 所以关系受到的影响较小.</p><h3 id="Context-Window-and-Logit-Dropout-Rate"><a href="#Context-Window-and-Logit-Dropout-Rate" class="headerlink" title="Context Window and Logit Dropout Rate"></a>Context Window and Logit Dropout Rate</h3><p>作者探究了不同的上下文滑窗大小和Logits Dropout Rate对性能的影响:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire12.png" style="zoom:67%"><p>Logits Dropout对UniRE有一定帮助, 在Dropout概率为0.2时比较好.</p><h3 id="Error-Analysis"><a href="#Error-Analysis" class="headerlink" title="Error Analysis"></a>Error Analysis</h3><p>作者对预测结果做了错误分析, 将其分为五类错误:</p><ul><li>Span Splitting Error(SSE): Span划分错误.</li><li>Entity not Found(ENF): 实体没预测出来.</li><li>Entity Type Error(ETE): 实体预测出来了, 但是实体类型找错了.</li><li>Relation not Found(RNF): 关系没有预测出来.</li><li>Relation Type Error(RTE): 关系预测出来了, 但是关系类型找错了.</li></ul><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire13.png" style="zoom:75%"><p>能从图中看到, SSE占得比例其实比较小, 说明作者的Span解码算法是很有效的. 实体和关系没找到的比例远远比类型预测错误要多, 作者认为是因为表中的类别不平衡问题仍然存在(毕竟表内大多的地方的标签都为$\perp$).</p><p>在文章最后, 作者给出了两个关于解码算法<strong>鲁棒性</strong>的例子:</p><img src="https://cdn.jsdelivr.net/gh/ADAning/Image/MLDL/unire14.png" style="zoom:75%"><p>即使双仿射得出的模型预测Intermediate Table是有一部分错误的, 作者所提出的解码算法仍然能够抽取出正确的实体和关系.</p><p>第一个例子没太懂是怎么消除掉的, 第二个例子中, Intermediate Table的橘色部分虽然列视角第三列和第四列差异足够大, 但在行视角中四三行和第四行并没有差别, 所以没有被切割开, 因此解码后和Golden Label一致.</p><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>非常扎实而且有意思的一篇论文.</p><p>UniRE用一种<strong>统一标签</strong>, 尝试将<strong>ERE</strong>任务在<strong>一张实体关系统一表</strong>上用<strong>填表法</strong>解决, 理论上消除了实体空间和关系空间的偏差.</p><p>我认为无论是从<strong>表标签设计</strong>, <strong>解码设计</strong>, 还是最后文中作者对模型中的阈值选取的分析等, 都是很有深度的.</p><p>尤为亮眼的是Span解码的方式设计, 使用了一种非常新颖的, <strong>基于概率分布差再求平均的方式判断实体边界</strong>, 因为将实体和关系杂糅在一张表中, 所以本身UniRE的表内解码是非常容易出错的. 甚至可以说这个解码算法是驱动UniRE能做Work的源头.<br>作者在文末还展示出解码算法的鲁棒性打消读者的疑虑, 可以说是考虑的面面俱到了.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/8137.html">https://ADAning.github.io/posts/8137.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/ERE/"><span class="chip bg-color">ERE</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/37376.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/4.jpg" class="responsive-img" alt="W2NER: Unified Named Entity Recognition as Word-Word Relation Classification"> <span class="card-title">W2NER: Unified Named Entity Recognition as Word-Word Relation Classification</span></div></a><div class="card-content article-content"><div class="summary block-with-text">W2NER: Unified Named Entity Recognition as Word-Word Relation Classification本文是论文Unified Named Entity Recognition as Wor</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-10-16 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/NER/"><span class="chip bg-color">NER</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/61261.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/23.jpg" class="responsive-img" alt="DirectRel: Relational Triple Extraction - One Step is Enough"> <span class="card-title">DirectRel: Relational Triple Extraction - One Step is Enough</span></div></a><div class="card-content article-content"><div class="summary block-with-text">Relational Triple Extraction: One Step is Enough本文是论文Relational Triple Extraction: One Step is Enough 的阅读笔记和个人理解, 论文来自IJ</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2022-08-31 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/RTE/"><span class="chip bg-color">RTE</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">343.8k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>