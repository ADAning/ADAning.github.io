<!DOCTYPE HTML><html lang="zh-CN"><head><meta charset="utf-8"><meta name="keywords" content="Pytorch学习: 张量基础操作, DaNing的博客"><meta name="description" content="DaNing的个人博客."><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no"><meta name="renderer" content="webkit|ie-stand|ie-comp"><meta name="mobile-web-app-capable" content="yes"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><title>Pytorch学习: 张量基础操作 | DaNing的博客</title><link rel="icon" type="image/png" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/favicon.png"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/awesome/css/all.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/animate/animate.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/css/lightgallery.min.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/matery.css"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/css/my.css"><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/jquery/jquery.min.js"></script><meta name="generator" content="Hexo 4.2.1"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"><link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><header class="navbar-fixed"><nav id="headNav" class="bg-color nav-transparent"><div id="navContainer" class="nav-wrapper container"><div class="brand-logo"><a href="/" class="waves-effect waves-light"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img" alt="LOGO"> <span class="logo-span">DaNing的博客</span></a></div><a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a><ul class="right nav-menu"><li class="hide-on-med-and-down nav-item"><a href="/" class="waves-effect waves-light"><i class="fas fa-home" style="zoom:.6"></i> <span>首页</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fas fa-tags" style="zoom:.6"></i> <span>标签</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fas fa-bookmark" style="zoom:.6"></i> <span>分类</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fas fa-archive" style="zoom:.6"></i> <span>时间轴</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/about" class="waves-effect waves-light"><i class="fas fa-user-circle" style="zoom:.6"></i> <span>关于</span></a></li><li class="hide-on-med-and-down nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fas fa-comments" style="zoom:.6"></i> <span>留言板</span></a></li><li class="hide-on-med-and-down nav-item"><a href="" class="waves-effect waves-light"><i class="fas fa-tools" style="zoom:.6"></i> <span>工具</span> <i class="fas fa-chevron-down" aria-hidden="true" style="zoom:.6"></i></a><ul class="sub-nav menus_item_child"><li><a href="/shortcut"><i class="fas fa-rocket" style="margin-top:-20px;zoom:.6"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu"><i class="fas fa-wheelchair" style="margin-top:-20px;zoom:.6"></i> <span>帮你百度</span></a></li><li><a href="/markdown"><i class="fab fa-markdown" style="margin-top:-20px;zoom:.6"></i> <span>Markdown</span></a></li></ul></li><li><a href="#searchModal" class="modal-trigger waves-effect waves-light"><i id="searchIcon" class="fas fa-search" title="搜索" style="zoom:.85"></i></a></li></ul><div id="mobile-nav" class="side-nav sidenav"><div class="mobile-head bg-color"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/logo.png" class="logo-img circle responsive-img"><div class="logo-name">DaNing的博客</div><div class="logo-desc">DaNing的个人博客.</div></div><ul class="menu-list mobile-menu-list"><li class="m-nav-item"><a href="/" class="waves-effect waves-light"><i class="fa-fw fas fa-home"></i> 首页</a></li><li class="m-nav-item"><a href="/tags" class="waves-effect waves-light"><i class="fa-fw fas fa-tags"></i> 标签</a></li><li class="m-nav-item"><a href="/categories" class="waves-effect waves-light"><i class="fa-fw fas fa-bookmark"></i> 分类</a></li><li class="m-nav-item"><a href="/archives" class="waves-effect waves-light"><i class="fa-fw fas fa-archive"></i> 归档</a></li><li class="m-nav-item"><a href="/about" class="waves-effect waves-light"><i class="fa-fw fas fa-user-circle"></i> 关于</a></li><li class="m-nav-item"><a href="/contact" class="waves-effect waves-light"><i class="fa-fw fas fa-comments"></i> 留言板</a></li><li class="m-nav-item"><a href="javascript:;"><i class="fa-fw fas fa-tools"></i> 工具 <span class="m-icon"><i class="fas fa-chevron-right"></i></span></a><ul><li><a href="/shortcut" style="margin-left:75px"><i class="fa fas fa-rocket" style="position:absolute;left:50px"></i> <span>导航(待完善)</span></a></li><li><a href="/helpyoubaidu" style="margin-left:75px"><i class="fa fas fa-wheelchair" style="position:absolute;left:50px"></i> <span>帮你百度</span></a></li><li><a href="/markdown" style="margin-left:75px"><i class="fa fab fa-markdown" style="position:absolute;left:50px"></i> <span>Markdown</span></a></li></ul></li></ul></div></div></nav></header><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/cryptojs/crypto-js.min.js"></script><script></script><div class="bg-cover pd-header post-cover" style="background-image:url(https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/17.jpg)"><div class="container" style="right:0;left:0"><div class="row"><div class="col s12 m12 l12"><div class="brand"><h1 class="description center-align post-title">Pytorch学习: 张量基础操作</h1></div></div></div></div></div><main class="post-container content"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.css"><style>#articleContent h1::before,#articleContent h2::before,#articleContent h3::before,#articleContent h4::before,#articleContent h5::before,#articleContent h6::before{display:block;content:" ";height:100px;margin-top:-100px;visibility:hidden}#articleContent :focus{outline:0}.toc-fixed{position:fixed;top:64px}.toc-widget{width:345px;padding-left:20px}.toc-widget .toc-title{margin:35px 0 15px 0;padding-left:17px;font-size:1.5rem;font-weight:700;line-height:1.5rem}.toc-widget ol{padding:0;list-style:none}#toc-content{height:calc(100vh - 250px);overflow:auto}#toc-content ol{padding-left:10px}#toc-content ol li{padding-left:10px}#toc-content .toc-link:hover{color:#42b983;font-weight:700;text-decoration:underline}#toc-content .toc-link::before{background-color:transparent;max-height:25px;position:absolute;right:23.5vw;display:block}#toc-content .is-active-link{color:#42b983}#floating-toc-btn{position:fixed;right:15px;bottom:76px;padding-top:15px;margin-bottom:0;z-index:998}#floating-toc-btn .btn-floating{width:48px;height:48px}#floating-toc-btn .btn-floating i{line-height:48px;font-size:1.4rem}</style><div class="row"><div id="main-content" class="col s12 m12 l9"><div id="artDetail"><div class="card"><div class="card-content article-info"><div class="row tag-cate"><div class="col s7"><div class="article-tag"><a href="/tags/%E7%BC%96%E7%A8%8B/"><span class="chip bg-color">编程</span> </a><a href="/tags/Pytorch/"><span class="chip bg-color">Pytorch</span></a></div></div><div class="col s5 right-align"><div class="post-cate"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></div></div></div><div class="post-info"><div class="post-date info-break-policy"><i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp; 2020-10-02</div><div class="post-date info-break-policy"><i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp; 2022-04-05</div><div class="info-break-policy"><i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp; 3.7k</div><div class="info-break-policy"><i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp; 18 分</div></div></div><hr class="clearfix"><div class="card-content article-card-content"><div id="articleContent"><h1 id="Pytorch学习-张量基础操作"><a href="#Pytorch学习-张量基础操作" class="headerlink" title="Pytorch学习: 张量基础操作"></a>Pytorch学习: 张量基础操作</h1><p>整理内容顺序来自龙龙老师的<code>&lt;深度学习与PyTorch入门实战教程&gt;</code>, 根据个人所需情况进行删减或扩充. 如果想要自己创建新的模块, 这些操作都是基本功, 需要掌握扎实.</p><h2 id="张量数据类型"><a href="#张量数据类型" class="headerlink" title="张量数据类型"></a>张量数据类型</h2><p>下表摘自<a href="https://pytorch.org/docs/master/tensors.html#tensor-doc" target="_blank" rel="noopener">Pytorch官方文档</a>, 介绍了现在pytorch中所有涉及到的数据类型.</p><table><thead><tr><th>Data type</th><th>dtype</th><th>CPU tensor</th><th>GPU tensor</th></tr></thead><tbody><tr><td>32-bit floating point</td><td><code>torch.float32</code> or <code>torch.float</code></td><td><code>torch.FloatTensor</code></td><td><code>torch.cuda.FloatTensor</code></td></tr><tr><td>64-bit floating point</td><td><code>torch.float64</code> or <code>torch.double</code></td><td><code>torch.DoubleTensor</code></td><td><code>torch.cuda.DoubleTensor</code></td></tr><tr><td>16-bit floating point <a href="https://pytorch.org/docs/master/tensors.html#id3" target="_blank" rel="noopener">1</a></td><td><code>torch.float16</code> or <code>torch.half</code></td><td><code>torch.HalfTensor</code></td><td><code>torch.cuda.HalfTensor</code></td></tr><tr><td>16-bit floating point <a href="https://pytorch.org/docs/master/tensors.html#id4" target="_blank" rel="noopener">2</a></td><td><code>torch.bfloat16</code></td><td><code>torch.BFloat16Tensor</code></td><td><code>torch.cuda.BFloat16Tensor</code></td></tr><tr><td>32-bit complex</td><td><code>torch.complex32</code></td><td></td><td></td></tr><tr><td>64-bit complex</td><td><code>torch.complex64</code></td><td></td><td></td></tr><tr><td>128-bit complex</td><td><code>torch.complex128</code> or <code>torch.cdouble</code></td><td></td><td></td></tr><tr><td>8-bit integer (unsigned)</td><td><code>torch.uint8</code></td><td><code>torch.ByteTensor</code></td><td><code>torch.cuda.ByteTensor</code></td></tr><tr><td>8-bit integer (signed)</td><td><code>torch.int8</code></td><td><code>torch.CharTensor</code></td><td><code>torch.cuda.CharTensor</code></td></tr><tr><td>16-bit integer (signed)</td><td><code>torch.int16</code> or <code>torch.short</code></td><td><code>torch.ShortTensor</code></td><td><code>torch.cuda.ShortTensor</code></td></tr><tr><td>32-bit integer (signed)</td><td><code>torch.int32</code> or <code>torch.int</code></td><td><code>torch.IntTensor</code></td><td><code>torch.cuda.IntTensor</code></td></tr><tr><td>64-bit integer (signed)</td><td><code>torch.int64</code> or <code>torch.long</code></td><td><code>torch.LongTensor</code></td><td><code>torch.cuda.LongTensor</code></td></tr><tr><td>Boolean</td><td><code>torch.bool</code></td><td><a href="https://pytorch.org/docs/master/tensors.html#torch.BoolTensor" target="_blank" rel="noopener"><code>torch.BoolTensor</code></a></td><td><code>torch.cuda.BoolTensor</code></td></tr></tbody></table><p>一般情况下, 常用的tensor类型只有<strong>float</strong>, <strong>int</strong>, <strong>bool</strong>. 至于使用多少位精度需要结合实际情况而定, 毕竟精度高了训练时间就长了. 其他的类型基本不需要去关心, 需要时再查查文档就好.</p><p>在CPU和在GPU上的tensor是完全不同的, 它们甚至不属于同一个类. 在CPU和GPU上训练的两个tensor除非迁移到同一个位置上, 否则不能发生交互.</p><p><strong>为什么没有<code>String</code> 类型的tensor?</strong></p><p>因为在深度学习中, 文本不会直接输入到框架中. 虽然在pytorch中没有string直接的数据类型, 但是可以根据需要把string做embedding或者one-hot转换成张量输入.</p><h2 id="创建张量"><a href="#创建张量" class="headerlink" title="创建张量"></a>创建张量</h2><p>大多数张量的基本操作也会穿插在这一节里面.</p><h3 id="自动数据类型"><a href="#自动数据类型" class="headerlink" title="自动数据类型"></a>自动数据类型</h3><p>创建张量, 使用<code>torch.tensor()</code>. 它可以创建一个标量(dim=0)或者一个张量. 如果传入的对象是一个数, 那么则创建一个标量, 如果传入的对象是一个<code>list</code>, 则创建一个张量. 这种方式是不指定数据类型的, tensor会自动分配数据类型.</p><p>使用<code>Tensor.shape</code>或<code>Tensor.size()</code>可以查看张量的大小.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">import</span> torch
<span class="token comment" spellcheck="true"># 创建一个标量</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">925</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a.size():'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 创建一个张量</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">925</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b.size()'</span><span class="token punctuation">,</span> b<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># output:</span>
<span class="token comment" spellcheck="true"># a.size():  torch.Size([])</span>
<span class="token comment" spellcheck="true"># b.size(): torch.Size([1])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>标量和张量是不同的. 对于标量来说, 它本身就是一个单独的数, <strong>没有dim和size</strong>这一说. 使用<code>Tensor.dim()</code>和<code>len(Tensor.size())</code>是等价的, 对于标量来说, 结果应该是0.</p><p>同时, 对于标量来说, 使用<code>Tensor.item()</code>能获取标量的值.</p><p>可以通过<code>Tensor.type()</code>查看tensor的类型:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a.type():'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># output:</span>
<span class="token comment" spellcheck="true"># a.type(): torch.LongTensor</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>使用<code>torch.tensor()</code>创建张量会被自动分配数据类型, 对于浮点和整型是不一样的:</p><pre class="line-numbers language-python"><code class="language-python">c <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">925</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'c.type():'</span><span class="token punctuation">,</span> c<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># output:</span>
<span class="token comment" spellcheck="true"># c.type(): torch.FloatTensor</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p>在GPU上的tensor和CPU上的tensor完全不是一个类型:</p><pre class="line-numbers language-python"><code class="language-python">c <span class="token operator">=</span> c<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'c.type():'</span><span class="token punctuation">,</span> c<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># output:</span>
<span class="token comment" spellcheck="true"># c.type(): torch.cuda.FloatTensor</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p><code>Tensor.cuda()</code>可以返回一个tensor在cuda上的引用, 也就是将tensor移动到GPU上去.</p><h3 id="指定类型"><a href="#指定类型" class="headerlink" title="指定类型"></a>指定类型</h3><p>与<code>torch.tensor()</code>不同的是, 如果向指定数据类型的函数中传入一个数, 不再是创建一个指定类型的标量, 而是创建一个指定数据类型和指定dim和shape的tensor. 例如, <code>torch.FloatTensor(3)</code>是创建一个维度为1, shape为[3]的tensor. tensor中的数据<strong>全是随机</strong>的.</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a.shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
output
a: tensor([9.2196e-41, 0.0000e+00, 7.0295e+28])
a.shape: torch.Size([3])
"""</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b:'</span><span class="token punctuation">,</span> b<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b.shape:'</span><span class="token punctuation">,</span> b<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
output:
b: tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]])
b.shape: torch.Size([3, 4])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当然, 也可以传入<code>list</code>直接对tensor初始化:</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a.type():'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>type<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
output:
a: tensor([1., 2., 3.])
a.type(): torch.FloatTensor
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="通过nump创建"><a href="#通过nump创建" class="headerlink" title="通过nump创建"></a>通过nump创建</h3><p>也可以通过numpy创建tensor.</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> np<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'numpy.a:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'torch.a:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
numpy.a: [[1. 1. 1. 1.]
 [1. 1. 1. 1.]
 [1. 1. 1. 1.]]
torch.a: tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]], dtype=torch.float64)
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>当然创建好了以后是一个<code>float64</code>的tensor, 从numpy导入的float其实是double类型.</p><h3 id="其他创建方法"><a href="#其他创建方法" class="headerlink" title="其他创建方法"></a>其他创建方法</h3><p>大多函数与numpy相同, 有numpy基础的建议直接跳过.</p><h4 id="基本创建方法"><a href="#基本创建方法" class="headerlink" title="基本创建方法"></a>基本创建方法</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 均匀分布初始化</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'rand:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 空张量(全是随机数)</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'empty:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 随机整数</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'ranint:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
output:
rand: tensor([[0.5267, 0.8344, 0.6042],
        [0.1859, 0.3207, 0.1803]])
empty: tensor([[1.0561e-38, 1.0653e-38, 1.4013e-45],
        [0.0000e+00, 1.4013e-45, 0.0000e+00]])
ranint: tensor([[8, 7],
        [1, 8]])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>torch.randint(low, high, size)</code>是遵循切片规则的, 即生成的随机整数包含左侧不包含右侧.</p><h4 id="xx-like"><a href="#xx-like" class="headerlink" title="xx_like"></a>xx_like</h4><p>和numpy一样, 也有<code>xx_like()</code>这个函数, 能按传入的tensor的shape创建tensor:</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'b:'</span><span class="token punctuation">,</span> b<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># output:</span>
<span class="token comment" spellcheck="true"># b: tensor([[1., 1., 1.],</span>
<span class="token comment" spellcheck="true">#        [1., 1., 1.]])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>xx</code>可以替换成前面所说的任意初始化的函数名称.</p><h4 id="arange-range"><a href="#arange-range" class="headerlink" title="arange / range"></a>arange / range</h4><p>numpy老朋友了. <code>torch.arange()</code>生成遵循切片规则[min, max)的tensor, 支持步长. <code>torch.range()</code>与前者功能相同, 因为完全可以代替, 可能会被移除, 不建议使用.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[0, 6):'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[0, 6), 步长为2:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># ouput:</span>
<span class="token comment" spellcheck="true"># [0, 6): tensor([0, 1, 2, 3, 4, 5])</span>
<span class="token comment" spellcheck="true"># [0, 6), 步长为2: tensor([0, 2, 4])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="full"><a href="#full" class="headerlink" title="full"></a>full</h4><p>使用<code>torch.full()</code>创建一个指定shape的tensor并填满某个值.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'填满6:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'创建值为6的标量:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># output:</span>
<span class="token comment" spellcheck="true"># 填满6: tensor([[6., 6., 6.],</span>
<span class="token comment" spellcheck="true">#         [6., 6., 6.]])</span>
<span class="token comment" spellcheck="true"># 创建值为6的标量: tensor(6.)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="randn"><a href="#randn" class="headerlink" title="randn"></a>randn</h4><p>使用<code>torch.randn()</code>按照(0, 1)初始化, 使用<code>torch.normal()</code>按照指定均值和方差进行初始化.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 0, 1初始化</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'randn:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 指定均值和标准差</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>normal<span class="token punctuation">(</span>mean<span class="token operator">=</span>torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> std<span class="token operator">=</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'normal:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""
randn: tensor([[-1.1174,  0.8060,  0.1918],
        [-0.1511,  0.3734, -0.6192]])
normal: tensor([-2.1135e+00,  4.9261e-01, -9.9956e-01,  3.7895e-01, -4.1920e-01,
        -1.6493e-01,  3.6504e-01, -1.1884e-01, -1.1261e-03, -4.7203e-02])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="linspace-logspace"><a href="#linspace-logspace" class="headerlink" title="linspace / logspace"></a>linspace / logspace</h4><p><code>torch.linspace()</code>和<code>torch.arange()</code>非常相似, 只不过给出的是<strong>范围和所需的元素个数</strong>.</p><p><code>torch.logspace()</code>是<code>torch.linspace()</code>的对数版本.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[0, 10), 2:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'[0, 10), 3:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'log[0, 1), 3:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>logspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
[0, 10), 2: tensor([ 0., 10.])
[0, 10), 3: tensor([ 0.,  5., 10.])
log[0, 1), 3: tensor([ 1.0000,  3.1623, 10.0000])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="ones-zeros-eye"><a href="#ones-zeros-eye" class="headerlink" title="ones / zeros / eye"></a>ones / zeros / eye</h4><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'0阵:\n'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'1阵:\n'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'单位阵:\n'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
0阵:
 tensor([[0., 0., 0.],
        [0., 0., 0.]])
1阵:
 tensor([[1., 1., 1.],
        [1., 1., 1.]])
单位阵:
 tensor([[1., 0., 0.],
        [0., 1., 0.]])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="randperm"><a href="#randperm" class="headerlink" title="randperm"></a>randperm</h4><p>这个函数说一下功能就懂了, 是用来做<strong>shuffle</strong>的.</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a:'</span><span class="token punctuation">,</span> a<span class="token punctuation">)</span>
index <span class="token operator">=</span> torch<span class="token punctuation">.</span>randperm<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'index:'</span><span class="token punctuation">,</span> index<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[index]:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
a: tensor([[0.7391, 0.1663, 0.1362, 0.9353],
        [0.2951, 0.9289, 0.3369, 0.8836],
        [0.2730, 0.8966, 0.7737, 0.5760]])
index: tensor([0, 1])
a[index]: tensor([[0.7391, 0.1663, 0.1362, 0.9353],
        [0.2951, 0.9289, 0.3369, 0.8836]])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>顺带一提, <code>Tensor.numel()</code>能得到tensor中的所有参数个数.</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>empty<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'numel:'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># numel: 6</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><h3 id="默认数据类型"><a href="#默认数据类型" class="headerlink" title="默认数据类型"></a>默认数据类型</h3><p>在使用<code>torch.tensor()</code>创建的数据类型默认是<code>torch.FloatTensor</code>, 可以使用<code>torch.set_default_tensor_type(tensor_data_type)</code>来设置默认创建的tensor类型.</p><h2 id="索引和切片"><a href="#索引和切片" class="headerlink" title="索引和切片"></a>索引和切片</h2><p>索引访问与python基本一致, python的list用的比较熟的建议跳过索引访问. 多了一些其他的新东西.</p><h3 id="索引访问"><a href="#索引访问" class="headerlink" title="索引访问"></a>索引访问</h3><p>就是python中list的访问方法, 完全一致.</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a.shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[0].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[0][0].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[0][0][23][24].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[0][0][23][24]:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">23</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">24</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
a.shape: torch.Size([4, 3, 28, 28])
a[0].shape: torch.Size([3, 28, 28])
a[0][0].shape: torch.Size([28, 28])
a[0][0][23][24].shape: torch.Size([])
a[0][0][23][24]: tensor(0.4280)
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过切片访问多个元素:</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a.shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[:2].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[:2, :1, :, :].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[:2, 1:, :, :].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[:2, -1:, :, :].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
a.shape: torch.Size([4, 3, 28, 28])
a[:2].shape: torch.Size([2, 3, 28, 28])
a[:2, :1, :, :].shape: torch.Size([2, 1, 28, 28])
a[:2, 1:, :, :].shape: torch.Size([2, 2, 28, 28])
a[:2, -1:, :, :].shape: torch.Size([2, 1, 28, 28])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>通过步长:</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[:, :, 0:28:2, 0:28:2].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">28</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">28</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[:, :, ::2, ::2].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># a[:, :, 0:28:2, 0:28:2].shape: torch.Size([4, 3, 14, 14])</span>
<span class="token comment" spellcheck="true"># a[:, :, ::2, ::2].shape: torch.Size([4, 3, 14, 14])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><h3 id="特殊用法"><a href="#特殊用法" class="headerlink" title="特殊用法"></a>特殊用法</h3><h4 id="index-select"><a href="#index-select" class="headerlink" title="index_select"></a>index_select</h4><p>多了一个<code>Tensor.index_select(dim, index)</code>函数, 像是对切片的封装, 不知道速度有没有提升, 在python中函数好像比切片要快一些, 记不太清了. 反正这个函数用起来是比较麻烦, <code>index</code>还必须是tensor类型的.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># torch.Size([2, 3, 28, 28])</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h4 id="auto-filled"><a href="#auto-filled" class="headerlink" title="auto filled"></a>auto filled</h4><p><code>...</code>代表了任意多的维度, 能根据其他维度<strong>自动填充</strong>, 当维度能够根据其他值推断出来的时候特别方便.</p><pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a.shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[...].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[0, ...].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[:, 1, ...].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a[..., :2].shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
a.shape: torch.Size([4, 3, 28, 28])
a[...].shape: torch.Size([4, 3, 28, 28])
a[0, ...].shape: torch.Size([3, 28, 28])
a[:, 1, ...].shape: torch.Size([4, 28, 28])
a[..., :2].shape: torch.Size([4, 3, 28, 2])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h4 id="masked-select"><a href="#masked-select" class="headerlink" title="masked select"></a>masked select</h4><p>通过<code>torch.masked_select(x, mask)</code>能用Mask来筛选元素.</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x:'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
mask <span class="token operator">=</span> x<span class="token punctuation">.</span>ge<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'mask:'</span><span class="token punctuation">,</span> mask<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'masked_select:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>x<span class="token punctuation">,</span> mask<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
x: tensor([[-0.7403, -1.3733,  0.8203],
        [-0.0259,  0.4284,  0.7480]])
mask: tensor([[0, 0, 1],
        [0, 0, 1]], dtype=torch.uint8)
masked_select: tensor([0.8203, 0.7480])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>注意, 选择后的结果是<strong>Flatten</strong>的, 而非保持原来的shape.</p><h4 id="take"><a href="#take" class="headerlink" title="take"></a>take</h4><p>用的不是很多, 通过<code>torch.take(src, index_tensor)</code>能按照打平后的index进行访问.</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x:'</span><span class="token punctuation">,</span> x<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'第2和第4个元素:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>take<span class="token punctuation">(</span>x<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
x: tensor([[0, 1, 2],
        [3, 4, 5]])
第2和第4个元素: tensor([2, 4])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="维度变换"><a href="#维度变换" class="headerlink" title="维度变换"></a>维度变换</h2><p>很多函数也和numpy类似.</p><h3 id="view-reshape"><a href="#view-reshape" class="headerlink" title="view / reshape"></a>view / reshape</h3><p><code>Tensor.view(size)</code>能将tensor变形, 和reshape一样, 只要保证<strong>数据总数不变</strong>就能够进行shape变化.</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
a <span class="token operator">=</span> a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
a <span class="token operator">=</span> a<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
torch.Size([4, 1, 28, 28])
torch.Size([4, 28, 28])
torch.Size([4, 784])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>时刻注意每个dim所对应的含义, 否则在恢复时数据会失去原来的意义, 全部打乱掉. 最好是对数据的维度和意义进行<strong>追踪</strong>.</p></blockquote><p><code>Tensor.view(size)</code>和<code>Tensor.reshape(size)</code>的差别不是很大, 但仍有差别, 在后面说<code>transpose</code>的时候会提到.</p><h3 id="squeeze-unsqueeze"><a href="#squeeze-unsqueeze" class="headerlink" title="squeeze / unsqueeze"></a>squeeze / unsqueeze</h3><p>这一对函数主要是对维度进行提升或压缩.</p><p><code>Tensor.unsqueeze()</code>:</p><pre class="line-numbers language-python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
a <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
a <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
a <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
a <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
a <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># wrong</span>
<span class="token comment" spellcheck="true"># a = x.unsqueeze(5)</span>
<span class="token triple-quoted-string string">"""
torch.Size([4, 1, 28, 28])
torch.Size([1, 4, 1, 28, 28])
torch.Size([4, 1, 28, 28, 1])
torch.Size([4, 1, 28, 28, 1])
torch.Size([4, 1, 1, 28, 28])
torch.Size([1, 4, 1, 28, 28])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>提升的维度也是遵循切片规则的, 区间为[-dim - 1, dim + 1).</p><p>与<code>Tensor.unsqueeze()</code>相反, <code>Tensor.squeeze</code>用于无用维度压缩.</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
torch.Size([1, 32, 1, 1])
torch.Size([32])
torch.Size([32, 1, 1])
torch.Size([1, 32, 1])
torch.Size([1, 32, 1, 1])
torch.Size([32, 1, 1])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="expand-repeat"><a href="#expand-repeat" class="headerlink" title="expand / repeat"></a>expand / repeat</h3><p>这两个函数从最终效果来说完全等价, 但过程不同.</p><p><code>Tensor.expand(size)</code>实际上是在做<strong>BroadCasting</strong>, 被动复制数据, 只有在需要时候才复制. 而<code>Tensor.repeat(copy_times)</code>是直接复制. 建议使用前者减小内存压力.</p><blockquote><p>对broadcast不理解的可以查看<a href="https://www.runoob.com/numpy/numpy-broadcast.html" target="_blank" rel="noopener">NumPy 广播(Broadcast)</a>, 这是一个很重要的机制, 广播能减少内存消耗或减少我们的操作.</p></blockquote><p><code>Tensor.expand(size)</code>:</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> b<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>expand<span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>b<span class="token punctuation">.</span>expand<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
torch.Size([4, 32, 14, 14]) torch.Size([1, 32, 1, 1])
torch.Size([4, 32, 14, 14])
torch.Size([1, 32, 1, 1])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>此处填入-1代表维度<strong>保持不变</strong>.</p><p><code>Tensor.repeat(copy_times)</code>传入的是在每个dim上<strong>复制的次数</strong>:</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
torch.Size([1, 32, 1, 1])
torch.Size([4, 1024, 1, 1])
torch.Size([4, 32, 1, 1])
torch.Size([4, 32, 32, 32])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="transpose-t-permute"><a href="#transpose-t-permute" class="headerlink" title="transpose / t / permute"></a>transpose / t / permute</h3><p>这三个使用频率非常高.</p><p><code>Tensor.t()</code>就是转置, 只能对<strong>2d-tensor</strong>使用, 否则会报错:</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
torch.Size([2, 3])
torch.Size([3, 2])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><code>Tensor.transpose()</code>能任意交换2个维度之间的数据, 只进行一次交换时候建议使用它:</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a.shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'交换1, 3:'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
a.shape: torch.Size([4, 3, 32, 32])
交换1, 3: torch.Size([4, 32, 32, 3])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>但是请注意, 在使用<code>transpose</code>和<code>permute</code>后, 只是改变了访问的方式(数组的访问步长), 而不会改变底层数组的存储方式, 这也就是所谓的”<strong>不连续</strong>“.</p><p><strong>而<code>Tensor.view()</code>要求tensor必须是连续的, 所以在<code>view</code>前必须使用<code>contiguous()</code>让tensor变连续, 新版中直接使用<code>reshape</code>函数更方便, 它等价于前面的操作</strong>.</p><blockquote><p>关于连续与否更详细的解释可以看<a href="https://zhuanlan.zhihu.com/p/64551412" target="_blank" rel="noopener">PyTorch中的contiguous</a>.</p></blockquote><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 错误做法</span>
a1 <span class="token operator">=</span> a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token number">32</span> <span class="token operator">*</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 正确做法</span>
a2 <span class="token operator">=</span> a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token number">32</span> <span class="token operator">*</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 用reshape</span>
a3 <span class="token operator">=</span> a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span> <span class="token operator">*</span> <span class="token number">32</span> <span class="token operator">*</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a.shape:'</span><span class="token punctuation">,</span> a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a1.shape:'</span><span class="token punctuation">,</span> a1<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a2.shape:'</span><span class="token punctuation">,</span> a2<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a3.shape:'</span><span class="token punctuation">,</span> a3<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a == a1?:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>all<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token punctuation">,</span> a1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a == a2?:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>all<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token punctuation">,</span> a2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'a == a3?:'</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>all<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token punctuation">,</span> a3<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
a.shape: torch.Size([4, 3, 32, 32])
a1.shape: torch.Size([4, 3, 32, 32])
a2.shape: torch.Size([4, 3, 32, 32])
a3.shape: torch.Size([4, 3, 32, 32])
a == a1?: tensor(0, dtype=torch.uint8)
a == a2?: tensor(1, dtype=torch.uint8)
a == a3?: tensor(1, dtype=torch.uint8)
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>一定要先view交换后的shape, 再transpose回来.</p><p><code>Tensor.permute()</code>更加灵活, 能随意交换所有dim之间的位置, 如果交换多个维度最好使用这个函数:</p><pre class="line-numbers language-python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>a<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
torch.Size([4, 3, 28, 32])
torch.Size([4, 28, 32, 3])
torch.Size([4, 28, 3, 32])
torch.Size([4, 28, 3, 32])
"""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>也同时要注意, 使用后也是不连续的.</p></div><hr><div class="reprint" id="reprint-statement"><div class="reprint__author"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-user">文章作者: </i></span><span class="reprint-info"><a href="/about" rel="external nofollow noreferrer">AnNing</a></span></div><div class="reprint__type"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-link">文章链接: </i></span><span class="reprint-info"><a href="https://ADAning.github.io/posts/42255.html">https://ADAning.github.io/posts/42255.html</a></span></div><div class="reprint__notice"><span class="reprint-meta" style="font-weight:700"><i class="fas fa-copyright">版权声明: </i></span><span class="reprint-info">本博客所有文章除特別声明外，均采用 <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a> 许可协议。转载请注明来源 <a href="/about" target="_blank">AnNing</a> !</span></div></div><script async defer>function navToReprintStatement(){$("html, body").animate({scrollTop:$("#reprint-statement").offset().top-80},800)}document.addEventListener("copy",function(t){M.toast({html:'<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>'})})</script><div class="tag_share" style="display:block"><div class="post-meta__tag-list" style="display:inline-block"><div class="article-tag"><a href="/tags/%E7%BC%96%E7%A8%8B/"><span class="chip bg-color">编程</span> </a><a href="/tags/Pytorch/"><span class="chip bg-color">Pytorch</span></a></div></div><div class="post_share" style="zoom:80%;width:fit-content;display:inline-block;float:right;margin:-.15rem 0"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/css/share.min.css"><div id="article-share"><div class="social-share" data-sites="qq,wechat,weibo" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/share/js/social-share.min.js"></script></div></div></div></div></div><style>.mvaline-card{margin:1.5rem auto}.mvaline-card .card-content{padding:20px 20px 5px 20px}</style><div class="card mvaline-card" data-aos="fade-up"><div class="comment_headling" style="font-size:20px;font-weight:700;position:relative;padding-left:20px;top:15px;padding-bottom:5px"><i class="fas fa-comments fa-fw" aria-hidden="true"></i> <span>评论</span></div><div id="mvcomments" class="card-content" style="display:grid"></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/minivaline/MiniValine.min.js"></script><script>new MiniValine({el:"#mvcomments",appId:"M2K91TQqrwW698jR08LdugNz-gzGzoHsz",appKey:"b04G08nTf4B3kqCfOOY1urvC",mode:"xCss",placeholder:"评论暂不支持Latex公式, 但支持Markdown语法.",pathname:window.location.pathname,lang:"",adminEmailMd5:"ebbfbc84f11742e41a94a4e64b1d37ab",tagMeta:["管理员","小伙伴","访客"],master:["ebbfbc84f11742e41a94a4e64b1d37ab"],friends:["b5bd5d836c7a0091aa8473e79ed4c25e","adb7d1cd192658a55c0ad22a3309cecf","3ce1e6c77b4910f1871106cb30dc62b0","cfce8dc43725cc14ffcd9fb4892d5bfc"],math:!1,md:!0,enableQQ:!0,NoRecordIP:!1,visitor:!1,maxNest:6,pageSize:12,serverURLs:"",emoticonUrl:["https://cdn.jsdelivr.net/npm/alus@latest","https://cdn.jsdelivr.net/gh/MiniValine/qq@latest","https://cdn.jsdelivr.net/gh/MiniValine/Bilibilis@latest","https://cdn.jsdelivr.net/gh/MiniValine/tieba@latest","https://cdn.jsdelivr.net/gh/MiniValine/twemoji@latest","https://cdn.jsdelivr.net/gh/MiniValine/weibo@latest"]})</script><article id="prenext-posts" class="prev-next articles"><div class="row article-row"><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge left-badge text-color"><i class="fas fa-chevron-left"></i>&nbsp;上一篇</div><div class="card"><a href="/posts/1216.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/20.jpg" class="responsive-img" alt="Pytorch学习: 张量进阶操作"> <span class="card-title">Pytorch学习: 张量进阶操作</span></div></a><div class="card-content article-content"><div class="summary block-with-text">2020.10.03: 因torch版本更新, 对gather描述进行了修正. 2021.03.11: 更新了对gather的描述. Pytorch学习: 张量进阶操作整理内容顺序来自龙龙老师的&lt;深度学习与PyTorch入门实战教</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-10-03 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/%E7%BC%96%E7%A8%8B/"><span class="chip bg-color">编程</span> </a><a href="/tags/Pytorch/"><span class="chip bg-color">Pytorch</span></a></div></div></div><div class="article col s12 m6" data-aos="fade-up"><div class="article-badge right-badge text-color">下一篇&nbsp;<i class="fas fa-chevron-right"></i></div><div class="card"><a href="/posts/36009.html"><div class="card-image"><img src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/medias/featureimages/13.jpg" class="responsive-img" alt="指针网络家族"> <span class="card-title">指针网络家族</span></div></a><div class="card-content article-content"><div class="summary block-with-text">本文介绍了Pointer Network, CopyNet, Pointer-Generator Network以及Coverage机制在文本摘要与对话系统中的应用, 既可以作为知识点介绍, 也可以作为论文阅读笔记. 此外, 该部分内容为外</div><div class="publish-info"><span class="publish-date"><i class="far fa-clock fa-fw icon-date"></i>2020-09-28 </span><span class="publish-author"><i class="fas fa-bookmark fa-fw icon-category"></i> <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">深度学习</a></span></div></div><div class="card-action article-tags"><a href="/tags/NLP/"><span class="chip bg-color">NLP</span> </a><a href="/tags/Attention/"><span class="chip bg-color">Attention</span> </a><a href="/tags/%E6%91%98%E8%A6%81%E7%94%9F%E6%88%90/"><span class="chip bg-color">摘要生成</span></a></div></div></div></div></article></div><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeBlockFuction.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeLang.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeCopy.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/codeBlock/codeShrink.js"></script><style type="text/css">code[class*=language-],pre[class*=language-]{white-space:pre!important}</style></div><div id="toc-aside" class="expanded col l3 hide-on-med-and-down"><div class="toc-widget"><div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div><div id="toc-content"></div></div></div></div><div id="floating-toc-btn" class="hide-on-med-and-down"><a class="btn-floating btn-large bg-color"><i class="fas fa-list-ul"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/tocbot/tocbot.min.js"></script><script>$(function(){tocbot.init({tocSelector:"#toc-content",contentSelector:"#articleContent",headingsOffset:-(.4*$(window).height()-45),collapseDepth:Number("0"),headingSelector:"h2, h3, h4"});let t=0,e="toc-heading-",n=($("#toc-content a").each(function(){$(this).attr("href","#"+e+ ++t)}),t=0,$("#articleContent").children("h2, h3, h4").each(function(){$(this).attr("id",e+ ++t)}),parseInt(.4*$(window).height()-64)),o=$(".toc-widget");$(window).scroll(function(){$(window).scrollTop()>n?o.addClass("toc-fixed"):o.removeClass("toc-fixed")});const i="expanded";let c=$("#toc-aside"),a=$("#main-content");$("#floating-toc-btn .btn-floating").click(function(){c.hasClass(i)?(c.removeClass(i).hide(),a.removeClass("l9")):(c.addClass(i).show(),a.addClass("l9"));{let e=$("#artDetail");if(0!==e.length){let t=e.width();450<=t?t+=21:350<=t&&t<450?t+=18:300<=t&&t<350?t+=16:t+=14,$("#prenext-posts").width(t)}return}})})</script></main><footer class="page-footer bg-color"><div class="container row center-align" style="margin-bottom:0!important"><div class="col s12 m8 l8 copy-right">Copyright&nbsp;&copy; <span id="year">2020</span> <a href="/about" target="_blank">AnNing</a> |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a> |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a><br>&nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span class="white-color">336.3k</span>&nbsp;字 <span id="busuanzi_container_site_pv">|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv" class="white-color"></span>&nbsp;次 </span><span id="busuanzi_container_site_uv">|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv" class="white-color"></span>&nbsp;人</span><br><br></div><div class="col s12 m4 l4 social-link social-statis"><a href="https://github.com/ADAning" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50"><i class="fab fa-github"></i> </a><a href="mailto:695439722@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50"><i class="fas fa-envelope-open"></i> </a><a href="https://www.zhihu.com/people/nzhu-27" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/nzhu-27" data-position="top" data-delay="50"><i class="fab fa-zhihu1">知</i></a></div></div></footer><div class="progress-bar"></div><div id="searchModal" class="modal"><div class="modal-content"><div class="search-header"><span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span> <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字" class="search-input"></div><div id="searchResult"></div></div></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/search.js"></script><script type="text/javascript">$(function(){searchFunc("https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/search.xml","searchInput","searchResult")})</script><div id="backTop" class="top-scroll"><a class="btn-floating btn-large waves-effect waves-light" href="#!"><i class="fas fa-angle-double-up"></i></a></div><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/materialize/materialize.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/masonry/masonry.pkgd.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/aos/aos.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/scrollprogress/scrollProgress.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/lightGallery/js/lightgallery-all.min.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/js/matery.js"></script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",(e=document.getElementsByTagName("script")[0]).parentNode.insertBefore(t,e)}()</script><script async src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/others/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/gh/ADAning/ADAning.github.io/libs/instantpage/instantpage.js" type="module"></script></body></html>